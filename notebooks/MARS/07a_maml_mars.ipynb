{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Notebook 07a_maml: Basic MAML (random init, no residual) (MARS)\n\n**Purpose:** Implement MAML (Model-Agnostic Meta-Learning) for cold-start MOOC recommendation.\n\n**Cold-Start Focus:**\n- **Meta-learning**: Learn initialization that enables rapid adaptation to new users\n- **Support set**: K pairs from user's history (for adaptation)\n- **Query set**: Q pairs from user's history (for evaluation)\n- **Few-shot learning**: Adapt to new users with only K=5 examples\n\n**MAML Algorithm:**\n1. **Meta-training**: Learn initial parameters \u03b8\n   - Inner loop: Adapt \u03b8 to each task (user) using support set \u2192 \u03b8'\n   - Outer loop: Update \u03b8 based on query set performance of \u03b8'\n2. **Meta-testing**: Adapt meta-learned \u03b8 to new users\n   - Zero-shot: Use \u03b8 without adaptation\n   - Few-shot: Adapt \u03b8 on support set (K=5), evaluate on query set\n\n**Inputs:**\n- `data/processed/mars/episodes/episodes_train_K5_Q10.parquet` (66,187 episodes)\n- `data/processed/mars/episodes/episodes_val_K5_Q10.parquet` (340 episodes)\n- `data/processed/mars/episodes/episodes_test_K5_Q10.parquet` (346 episodes)\n- `data/processed/mars/pairs/pairs_*.parquet`\n- `data/processed/mars/vocab/course2id.json` (343 courses)\n- `models/baselines/gru_global.pth` (baseline: 33.73% Acc@1)\n\n**Outputs:**\n- Meta-trained model: `models/maml/maml_gru_K5.pth`\n- Checkpoints: `models/maml/checkpoints/checkpoint_iter{N}.pth`\n- Results: `results/maml_K5_Q10.json`\n- `reports/07_maml_residual_mars/<run_tag>/report.json`\n\n**Metrics:**\n- Accuracy@1, Recall@5, Recall@10, MRR\n- Compare: MAML zero-shot, MAML few-shot (K=5), GRU baseline (33.73%)\n\n**Expected Performance:**\n- Zero-shot (\u03b8 without adaptation): ~30-35% Acc@1\n- Few-shot (\u03b8 adapted with K=5): ~40-45% Acc@1 (target: beat baseline)\n- Ablation: K \u2208 {1,3,5,10}, adaptation steps \u2208 {1,3,5,10}"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL 07-00] start=2026-01-13T06:44:13\n",
      "[CELL 07-00] CWD: C:\\anonymous-users-mooc-session-meta\\notebooks\n",
      "[CELL 07-00] REPO_ROOT: C:\\anonymous-users-mooc-session-meta\n",
      "[CELL 07-00] META_REGISTRY=C:\\anonymous-users-mooc-session-meta\\meta.json\n",
      "[CELL 07-00] DATA_INTERIM=C:\\anonymous-users-mooc-session-meta\\data\\interim\n",
      "[CELL 07-00] DATA_PROCESSED=C:\\anonymous-users-mooc-session-meta\\data\\processed\n",
      "[CELL 07-00] MODELS=C:\\anonymous-users-mooc-session-meta\\models\n",
      "[CELL 07-00] RESULTS=C:\\anonymous-users-mooc-session-meta\\results\n",
      "[CELL 07-00] REPORTS=C:\\anonymous-users-mooc-session-meta\\reports\n",
      "[CELL 07-00] PyTorch device: cuda\n",
      "[CELL 07-00] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 07-00] Bootstrap: repo root + paths + logger\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import pickle\n",
    "import hashlib\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(f\"[CELL 07-00] start={t0.isoformat(timespec='seconds')}\")\n",
    "print(\"[CELL 07-00] CWD:\", Path.cwd().resolve())\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"PROJECT_STATE.md\").exists():\n",
    "            return p\n",
    "    raise RuntimeError(\"Could not find PROJECT_STATE.md. Open notebook from within the repo.\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "print(\"[CELL 07-00] REPO_ROOT:\", REPO_ROOT)\n",
    "\n",
    "PATHS = {\n",
    "    \"META_REGISTRY\": REPO_ROOT / \"meta.json\",\n",
    "    \"DATA_INTERIM\": REPO_ROOT / \"data\" / \"interim\",\n",
    "    \"DATA_PROCESSED\": REPO_ROOT / \"data\" / \"processed\",\n",
    "    \"MODELS\": REPO_ROOT / \"models\",\n",
    "    \"RESULTS\": REPO_ROOT / \"results\",\n",
    "    \"REPORTS\": REPO_ROOT / \"reports\",\n",
    "}\n",
    "for k, v in PATHS.items():\n",
    "    print(f\"[CELL 07-00] {k}={v}\")\n",
    "\n",
    "def cell_start(cell_id: str, title: str, **kwargs: Any) -> float:\n",
    "    t = time.time()\n",
    "    print(f\"\\n[{cell_id}] {title}\")\n",
    "    print(f\"[{cell_id}] start={datetime.now().isoformat(timespec='seconds')}\")\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    return t\n",
    "\n",
    "def cell_end(cell_id: str, t0: float, **kwargs: Any) -> None:\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    print(f\"[{cell_id}] elapsed={time.time()-t0:.2f}s\")\n",
    "    print(f\"[{cell_id}] done\")\n",
    "\n",
    "# Check GPU\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[CELL 07-00] PyTorch device: {DEVICE}\")\n",
    "print(\"[CELL 07-00] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 07-01] Seed everything\n",
      "[CELL 07-01] start=2026-01-13T06:44:13\n",
      "[CELL 07-01] seed=20260107\n",
      "[CELL 07-01] elapsed=0.00s\n",
      "[CELL 07-01] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 07-01] Reproducibility: seed everything\n",
    "\n",
    "t0 = cell_start(\"CELL 07-01\", \"Seed everything\")\n",
    "\n",
    "GLOBAL_SEED = 20260107\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(GLOBAL_SEED)\n",
    "\n",
    "cell_end(\"CELL 07-01\", t0, seed=GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 07-02] IO helpers\n",
      "[CELL 07-02] start=2026-01-13T06:44:13\n",
      "[CELL 07-02] elapsed=0.00s\n",
      "[CELL 07-02] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 07-02] JSON/Pickle IO + hashing helpers\n",
    "\n",
    "t0 = cell_start(\"CELL 07-02\", \"IO helpers\")\n",
    "\n",
    "def write_json_atomic(path: Path, obj: Any, indent: int = 2) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + f\".tmp_{uuid.uuid4().hex}\")\n",
    "    with tmp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=indent)\n",
    "    tmp.replace(path)\n",
    "\n",
    "def read_json(path: Path) -> Any:\n",
    "    if not path.exists():\n",
    "        raise RuntimeError(f\"Missing JSON file: {path}\")\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def save_pickle(path: Path, obj: Any) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_pickle(path: Path) -> Any:\n",
    "    with path.open(\"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def sha256_file(path: Path, chunk_size: int = 1024 * 1024) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "cell_end(\"CELL 07-02\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 07-03] Start run + init files\n",
      "[CELL 07-03] start=2026-01-13T06:44:13\n",
      "[CELL 07-03] K=5, Q=10\n",
      "[CELL 07-03] MAML config: \u03b1=0.05, \u03b2=0.001, inner_steps=5, meta_batch=32\n",
      "[CELL 07-03] out_dir=C:\\anonymous-users-mooc-session-meta\\reports\\07_maml_warmstart_residual_mars_mars\\20260113_064413\n",
      "[CELL 07-03] elapsed=0.02s\n",
      "[CELL 07-03] done\n"
     ]
    }
   ],
   "source": "# [CELL 07-03] Run tagging + config + meta.json\n\nt0 = cell_start(\"CELL 07-03\", \"Start run + init files\")\n\nNOTEBOOK_NAME = \"07a_maml_mars\"\nRUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\nRUN_ID = uuid.uuid4().hex\n\nOUT_DIR = PATHS[\"REPORTS\"] / NOTEBOOK_NAME / RUN_TAG\nOUT_DIR.mkdir(parents=True, exist_ok=True)\n\nREPORT_PATH = OUT_DIR / \"report.json\"\nCONFIG_PATH = OUT_DIR / \"config.json\"\nMANIFEST_PATH = OUT_DIR / \"manifest.json\"\n\n# Paths\nEPISODES_DIR = PATHS[\"DATA_PROCESSED\"] / \"mars\" / \"episodes\"\nPAIRS_DIR = PATHS[\"DATA_PROCESSED\"] / \"mars\" / \"pairs\"\nVOCAB_DIR = PATHS[\"DATA_PROCESSED\"] / \"mars\" / \"vocab\"\nMODELS_DIR = PATHS[\"MODELS\"] / \"maml\"\nCHECKPOINTS_DIR = MODELS_DIR / \"checkpoints_basic\"\nRESULTS_DIR = PATHS[\"RESULTS\"]\n\nMODELS_DIR.mkdir(parents=True, exist_ok=True)\nCHECKPOINTS_DIR.mkdir(parents=True, exist_ok=True)\nRESULTS_DIR.mkdir(parents=True, exist_ok=True)\n\n# K-shot config\nK, Q = 5, 10\n\nCFG = {\n    \"notebook\": NOTEBOOK_NAME,\n    \"run_id\": RUN_ID,\n    \"run_tag\": RUN_TAG,\n    \"seed\": GLOBAL_SEED,\n    \"device\": str(DEVICE),\n    \"k_shot_config\": {\"K\": K, \"Q\": Q},\n    \"inputs\": {\n        \"episodes_train\": str(EPISODES_DIR / f\"episodes_train_K{K}_Q{Q}.parquet\"),\n        \"episodes_val\": str(EPISODES_DIR / f\"episodes_val_K{K}_Q{Q}.parquet\"),\n        \"episodes_test\": str(EPISODES_DIR / f\"episodes_test_K{K}_Q{Q}.parquet\"),\n        \"pairs_train\": str(PAIRS_DIR / \"pairs_train.parquet\"),\n        \"pairs_val\": str(PAIRS_DIR / \"pairs_val.parquet\"),\n        \"pairs_test\": str(PAIRS_DIR / \"pairs_test.parquet\"),\n        \"vocab\": str(VOCAB_DIR / \"item2id.json\"),\n        \"gru_baseline\": str(PATHS[\"MODELS\"] / \"baselines\" / \"mars\" / \"gru_global.pth\"),\n    },\n    \"gru_config\": {\n        \"embedding_dim\": 64,\n        \"hidden_dim\": 128,\n        \"num_layers\": 1,\n        \"dropout\": 0.2,\n        \"max_seq_len\": 50,\n    },\n    \"maml_config\": {\n        \"inner_lr\": 0.05,  # FIX #1: Increased from 0.01  # \u03b1: learning rate for inner loop (task adaptation)\n        \"outer_lr\": 0.001,          # \u03b2: learning rate for outer loop (meta-update)\n        \"num_inner_steps\": 5,       # number of gradient steps for adaptation\n        \"lambda_residual\": 0.0,\n        \"warm_start\": False,           # Initialize from GRU baseline     # FIX #2: Residual MAML weight\n        \"meta_batch_size\": 32,      # number of tasks (users) per meta-batch\n        \"num_meta_iterations\": 10000,  # total meta-training iterations\n        \"checkpoint_interval\": 1000,   # save checkpoint every N iterations\n        \"eval_interval\": 500,          # evaluate on val set every N iterations\n        \"use_second_order\": True,      # True: MAML (2nd order), False: FOMAML (1st order)\n    },\n    \"ablation_configs\": {\n        \"support_set_sizes\": [1, 3, 5, 10],\n        \"adaptation_steps\": [1, 3, 5, 10],\n    },\n    \"metrics\": [\"accuracy@1\", \"recall@5\", \"recall@10\", \"mrr\"],\n    \"outputs\": {\n        \"models_dir\": str(MODELS_DIR),\n        \"checkpoints_dir\": str(CHECKPOINTS_DIR),\n        \"results\": str(RESULTS_DIR / f\"maml_basic_K{K}_Q{Q}.json\"),\n        \"out_dir\": str(OUT_DIR),\n    }\n}\n\nwrite_json_atomic(CONFIG_PATH, CFG)\n\nreport = {\n    \"run_id\": RUN_ID,\n    \"notebook\": NOTEBOOK_NAME,\n    \"run_tag\": RUN_TAG,\n    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n    \"repo_root\": str(REPO_ROOT),\n    \"metrics\": {},\n    \"key_findings\": [],\n    \"sanity_samples\": {},\n    \"data_fingerprints\": {},\n    \"notes\": [],\n}\nwrite_json_atomic(REPORT_PATH, report)\n\nmanifest = {\"run_id\": RUN_ID, \"notebook\": NOTEBOOK_NAME, \"run_tag\": RUN_TAG, \"artifacts\": []}\nwrite_json_atomic(MANIFEST_PATH, manifest)\n\n# meta.json\nMETA_PATH = PATHS[\"META_REGISTRY\"]\nif not META_PATH.exists():\n    write_json_atomic(META_PATH, {\"schema_version\": 1, \"runs\": []})\nmeta = read_json(META_PATH)\nmeta[\"runs\"].append({\n    \"run_id\": RUN_ID,\n    \"notebook\": NOTEBOOK_NAME,\n    \"run_tag\": RUN_TAG,\n    \"out_dir\": str(OUT_DIR),\n    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n})\nwrite_json_atomic(META_PATH, meta)\n\nprint(f\"[CELL 07-03] K={K}, Q={Q}\")\nprint(f\"[CELL 07-03] MAML config: \u03b1={CFG['maml_config']['inner_lr']}, \u03b2={CFG['maml_config']['outer_lr']}, \"\n      f\"inner_steps={CFG['maml_config']['num_inner_steps']}, meta_batch={CFG['maml_config']['meta_batch_size']}\")\n\ncell_end(\"CELL 07-03\", t0, out_dir=str(OUT_DIR))"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 07-04] Load data\n",
      "[CELL 07-04] start=2026-01-13T06:44:13\n",
      "[CELL 07-04] Vocabulary: 777 items (including padding)\n",
      "[CELL 07-04] Episodes train: 106 episodes (36 users)\n",
      "[CELL 07-04] Episodes val:   2 episodes (2 users)\n",
      "[CELL 07-04] Episodes test:  4 episodes (4 users)\n",
      "[CELL 07-04] Pairs train: 2,388 pairs\n",
      "[CELL 07-04] Pairs val:   204 pairs\n",
      "[CELL 07-04] Pairs test:  241 pairs\n",
      "[CELL 07-04] elapsed=0.02s\n",
      "[CELL 07-04] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 07-04] Load data: episodes, pairs, vocab\n",
    "\n",
    "t0 = cell_start(\"CELL 07-04\", \"Load data\")\n",
    "\n",
    "# Vocab\n",
    "item2id = read_json(Path(CFG[\"inputs\"][\"vocab\"]))\n",
    "id2item = {int(v): k for k, v in item2id.items()}\n",
    "n_items = len(item2id) + 1  # +1 for padding token at index 0\n",
    "print(f\"[CELL 07-04] Vocabulary: {n_items} items (including padding)\")\n",
    "\n",
    "# Episodes\n",
    "episodes_train = pd.read_parquet(CFG[\"inputs\"][\"episodes_train\"])\n",
    "episodes_val = pd.read_parquet(CFG[\"inputs\"][\"episodes_val\"])\n",
    "episodes_test = pd.read_parquet(CFG[\"inputs\"][\"episodes_test\"])\n",
    "\n",
    "print(f\"[CELL 07-04] Episodes train: {len(episodes_train):,} episodes ({episodes_train['user_id'].nunique():,} users)\")\n",
    "print(f\"[CELL 07-04] Episodes val:   {len(episodes_val):,} episodes ({episodes_val['user_id'].nunique():,} users)\")\n",
    "print(f\"[CELL 07-04] Episodes test:  {len(episodes_test):,} episodes ({episodes_test['user_id'].nunique():,} users)\")\n",
    "\n",
    "# Pairs\n",
    "pairs_train = pd.read_parquet(CFG[\"inputs\"][\"pairs_train\"])\n",
    "pairs_val = pd.read_parquet(CFG[\"inputs\"][\"pairs_val\"])\n",
    "pairs_test = pd.read_parquet(CFG[\"inputs\"][\"pairs_test\"])\n",
    "\n",
    "print(f\"[CELL 07-04] Pairs train: {len(pairs_train):,} pairs\")\n",
    "print(f\"[CELL 07-04] Pairs val:   {len(pairs_val):,} pairs\")\n",
    "print(f\"[CELL 07-04] Pairs test:  {len(pairs_test):,} pairs\")\n",
    "\n",
    "cell_end(\"CELL 07-04\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 07-05] Define evaluation metrics\n",
      "[CELL 07-05] start=2026-01-13T06:44:13\n",
      "[CELL 07-05] Metrics: accuracy@1, recall@5, recall@10, mrr\n",
      "[CELL 07-05] elapsed=0.00s\n",
      "[CELL 07-05] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 07-05] Evaluation metrics (reuse from Notebook 06)\n",
    "\n",
    "t0 = cell_start(\"CELL 07-05\", \"Define evaluation metrics\")\n",
    "\n",
    "def compute_metrics(predictions: np.ndarray, labels: np.ndarray, k_values: List[int] = [5, 10]) -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Compute ranking metrics.\n",
    "    \n",
    "    Args:\n",
    "        predictions: (n_samples, n_items) score matrix\n",
    "        labels: (n_samples,) true item indices\n",
    "        k_values: list of k for Recall@k\n",
    "    \n",
    "    Returns:\n",
    "        dict with accuracy@1, recall@k, mrr\n",
    "    \"\"\"\n",
    "    n_samples = len(labels)\n",
    "    \n",
    "    # Get top-k predictions (indices)\n",
    "    max_k = max(k_values)\n",
    "    top_k_preds = np.argsort(-predictions, axis=1)[:, :max_k]  # descending order\n",
    "    \n",
    "    # Accuracy@1\n",
    "    top1_preds = top_k_preds[:, 0]\n",
    "    acc1 = (top1_preds == labels).mean()\n",
    "    \n",
    "    # Recall@k\n",
    "    recall_k = {}\n",
    "    for k in k_values:\n",
    "        hits = np.array([labels[i] in top_k_preds[i, :k] for i in range(n_samples)])\n",
    "        recall_k[f\"recall@{k}\"] = hits.mean()\n",
    "    \n",
    "    # MRR (Mean Reciprocal Rank)\n",
    "    ranks = []\n",
    "    for i in range(n_samples):\n",
    "        # Find rank of true label (1-indexed)\n",
    "        rank_idx = np.where(top_k_preds[i] == labels[i])[0]\n",
    "        if len(rank_idx) > 0:\n",
    "            ranks.append(1.0 / (rank_idx[0] + 1))  # reciprocal rank\n",
    "        else:\n",
    "            # Not in top-k, check full ranking\n",
    "            full_rank = np.where(np.argsort(-predictions[i]) == labels[i])[0][0]\n",
    "            ranks.append(1.0 / (full_rank + 1))\n",
    "    mrr = np.mean(ranks)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy@1\": float(acc1),\n",
    "        **{k: float(v) for k, v in recall_k.items()},\n",
    "        \"mrr\": float(mrr),\n",
    "    }\n",
    "\n",
    "print(\"[CELL 07-05] Metrics: accuracy@1, recall@5, recall@10, mrr\")\n",
    "\n",
    "cell_end(\"CELL 07-05\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 07-06] Define GRU model\n",
      "[CELL 07-06] start=2026-01-13T06:44:13\n",
      "[CELL 07-06] GRU model defined\n",
      "  - Embedding dim: 64\n",
      "  - Hidden dim: 128\n",
      "  - Num layers: 1\n",
      "[CELL 07-06] elapsed=0.00s\n",
      "[CELL 07-06] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 07-06] Define GRU model (exact same as Notebook 06)\n",
    "\n",
    "t0 = cell_start(\"CELL 07-06\", \"Define GRU model\")\n",
    "\n",
    "class GRURecommender(nn.Module):\n",
    "    def __init__(self, n_items: int, embedding_dim: int, hidden_dim: int, num_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.n_items = n_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_items, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers, batch_first=True, dropout=dropout if num_layers > 1 else 0)\n",
    "        self.fc = nn.Linear(hidden_dim, n_items)\n",
    "    \n",
    "    def forward(self, seq: torch.Tensor, lengths: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            seq: (batch, max_len) padded sequences\n",
    "            lengths: (batch,) actual lengths\n",
    "        Returns:\n",
    "            logits: (batch, n_items)\n",
    "        \"\"\"\n",
    "        # Embed\n",
    "        emb = self.embedding(seq)  # (batch, max_len, embed_dim)\n",
    "        \n",
    "        # Pack for efficiency\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(emb, lengths.cpu(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        # GRU\n",
    "        _, hidden = self.gru(packed)  # hidden: (num_layers, batch, hidden_dim)\n",
    "        \n",
    "        # Use last layer hidden state\n",
    "        h = hidden[-1]  # (batch, hidden_dim)\n",
    "        \n",
    "        # Predict\n",
    "        logits = self.fc(h)  # (batch, n_items)\n",
    "        return logits\n",
    "\n",
    "print(\"[CELL 07-06] GRU model defined\")\n",
    "print(f\"  - Embedding dim: {CFG['gru_config']['embedding_dim']}\")\n",
    "print(f\"  - Hidden dim: {CFG['gru_config']['hidden_dim']}\")\n",
    "print(f\"  - Num layers: {CFG['gru_config']['num_layers']}\")\n",
    "\n",
    "cell_end(\"CELL 07-06\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 07-07] WARM-START + Residual MAML meta-training\n",
      "[CELL 07-07] start=2026-01-13T06:44:13\n",
      "[CELL 07-07] Loading GRU baseline from: gru_global.pth\n",
      "[CELL 07-07] WARM-START COMPLETE: GRU baseline Acc@1 = 48.04%\n",
      "[CELL 07-07] Meta-model initialized from pre-trained GRU (not random)\n",
      "[CELL 07-07] Meta-model parameters: 224,457\n",
      "[CELL 07-07] Using MAML (Second-Order)\n",
      "[CELL 07-07] Meta-training config:\n",
      "  - Inner LR (\u03b1): 0.05\n",
      "  - Outer LR (\u03b2): 0.001\n",
      "  - Inner steps: 5\n",
      "  - Meta-batch size: 32\n",
      "  - Meta-iterations: 10,000\n",
      "  - Lambda residual: 0.1\n",
      "\n",
      "[CELL 07-07] Starting meta-training...\n"
     ]
    }
   ],
   "source": "# [CELL 07-07] WARM-START + Residual MAML meta-training loop (Functional FOMAML - proper implementation)\n\nt0 = cell_start(\"CELL 07-07\", \"Basic MAML (random init) meta-training\")\n\n# Initialize meta-model\nmeta_model = GRURecommender(\n    n_items=n_items,\n    embedding_dim=CFG[\"gru_config\"][\"embedding_dim\"],\n    hidden_dim=CFG[\"gru_config\"][\"hidden_dim\"],\n    num_layers=CFG[\"gru_config\"][\"num_layers\"],\n    dropout=CFG[\"gru_config\"][\"dropout\"],\n).to(DEVICE)\n\n# ========== RANDOM INITIALIZATION ==========\nprint(f\"[CELL 07-07] Using RANDOM initialization (not warm-start)\")\nprint(f\"[CELL 07-07] Meta-model initialized with random weights\")\n# ====================================================\n\nprint(f\"[CELL 07-07] Meta-model parameters: {sum(p.numel() for p in meta_model.parameters()):,}\")\n\n# Meta-optimizer (outer loop)\nmeta_optimizer = torch.optim.Adam(meta_model.parameters(), lr=CFG[\"maml_config\"][\"outer_lr\"])\ncriterion = nn.CrossEntropyLoss()\n\n# MAML hyperparameters\ninner_lr = CFG[\"maml_config\"][\"inner_lr\"]\nnum_inner_steps = CFG[\"maml_config\"][\"num_inner_steps\"]\nmeta_batch_size = CFG[\"maml_config\"][\"meta_batch_size\"]\nnum_meta_iterations = CFG[\"maml_config\"][\"num_meta_iterations\"]\nmax_seq_len = CFG[\"gru_config\"][\"max_seq_len\"]\nuse_second_order = CFG[\"maml_config\"].get(\"use_second_order\", False)  # Default to FOMAML\nlambda_residual = CFG[\"maml_config\"].get(\"lambda_residual\", 0.0)  # FIX #3: Residual MAML weight\n\nprint(f\"[CELL 07-07] Using {'MAML (Second-Order)' if use_second_order else 'First-Order MAML (FOMAML)'}\")\nprint(f\"[CELL 07-07] Meta-training config:\")\nprint(f\"  - Inner LR (\u03b1): {inner_lr}\")\nprint(f\"  - Outer LR (\u03b2): {CFG['maml_config']['outer_lr']}\")\nprint(f\"  - Inner steps: {num_inner_steps}\")\nprint(f\"  - Meta-batch size: {meta_batch_size}\")\nprint(f\"  - Meta-iterations: {num_meta_iterations:,}\")\nprint(f\"  - Lambda residual: {lambda_residual}\")\n\ndef get_episode_data(episode_row, pairs_df):\n    \"\"\"Extract support and query pairs for an episode.\"\"\"\n    support_pair_ids = episode_row[\"support_pair_ids\"]\n    query_pair_ids = episode_row[\"query_pair_ids\"]\n\n    support_pairs = pairs_df[pairs_df[\"pair_id\"].isin(support_pair_ids)].sort_values(\"label_ts_epoch\")\n    query_pairs = pairs_df[pairs_df[\"pair_id\"].isin(query_pair_ids)].sort_values(\"label_ts_epoch\")\n\n    return support_pairs, query_pairs\n\ndef pairs_to_batch(pairs_df, max_len):\n    \"\"\"Convert pairs to batched tensors.\"\"\"\n    prefixes = []\n    labels = []\n    lengths = []\n\n    for _, row in pairs_df.iterrows():\n        prefix = row[\"prefix\"]\n        if len(prefix) > max_len:\n            prefix = prefix[-max_len:]\n        prefixes.append(prefix)\n        labels.append(row[\"label\"])\n        lengths.append(len(prefix))\n\n    # Pad sequences\n    max_l = max(lengths)\n    padded = []\n    for seq in prefixes:\n        padded.append(list(seq) + [0] * (max_l - len(seq)))\n\n    return (\n        torch.LongTensor(padded).to(DEVICE),\n        torch.LongTensor(labels).to(DEVICE),\n        torch.LongTensor(lengths).to(DEVICE),\n    )\n\n# Functional forward pass for GRU (avoids in-place operations)\ndef functional_forward(seq, lengths, params, hidden_dim, n_items):\n    \"\"\"\n    Functional forward pass using explicit parameters.\n    Implements: Embedding -> GRU -> FC\n    \"\"\"\n    batch_size = seq.size(0)\n    \n    # 1. Embedding\n    emb = F.embedding(seq, params['embedding.weight'], padding_idx=0)\n    \n    # 2. GRU (manual implementation for num_layers=1, batch_first=True)\n    h = torch.zeros(batch_size, hidden_dim, device=seq.device)\n    \n    # GRU parameters\n    w_ih = params['gru.weight_ih_l0']\n    w_hh = params['gru.weight_hh_l0']\n    b_ih = params['gru.bias_ih_l0']\n    b_hh = params['gru.bias_hh_l0']\n    \n    # Process sequence\n    for t in range(emb.size(1)):\n        x_t = emb[:, t, :]\n        \n        # GRU gates\n        gi = F.linear(x_t, w_ih, b_ih)\n        gh = F.linear(h, w_hh, b_hh)\n        i_r, i_z, i_n = gi.chunk(3, 1)\n        h_r, h_z, h_n = gh.chunk(3, 1)\n        \n        r = torch.sigmoid(i_r + h_r)\n        z = torch.sigmoid(i_z + h_z)\n        n = torch.tanh(i_n + r * h_n)\n        h_new = (1 - z) * n + z * h\n        \n        # Mask for actual sequence lengths\n        mask = (lengths > t).unsqueeze(1).float()\n        h = mask * h_new + (1 - mask) * h\n    \n    # 3. FC layer\n    logits = F.linear(h, params['fc.weight'], params['fc.bias'])\n    \n    return logits\n\n# Model config for functional forward\nhidden_dim = CFG[\"gru_config\"][\"hidden_dim\"]\n\n# Training tracking\ntraining_history = {\n    \"meta_iterations\": [],\n    \"meta_train_loss\": [],\n    \"val_accuracy\": [],\n    \"val_iterations\": [],\n}\n\nprint(f\"\\n[CELL 07-07] Starting meta-training...\")\n\n# Sample episodes for meta-training\ntrain_users = episodes_train[\"user_id\"].unique()\n\nfor meta_iter in range(num_meta_iterations):\n    meta_model.train()\n    meta_optimizer.zero_grad()\n\n    # Sample meta-batch of tasks\n    sampled_users = np.random.choice(train_users, size=min(meta_batch_size, len(train_users)), replace=False)\n\n    meta_loss_total = 0.0\n    valid_tasks = 0\n\n    for user_id in sampled_users:\n        # Sample one episode for this user\n        user_episodes = episodes_train[episodes_train[\"user_id\"] == user_id]\n        if len(user_episodes) == 0:\n            continue\n\n        episode = user_episodes.sample(n=1).iloc[0]\n\n        # Get support and query sets\n        support_pairs, query_pairs = get_episode_data(episode, pairs_train)\n\n        if len(support_pairs) == 0 or len(query_pairs) == 0:\n            continue\n\n        support_seq, support_labels, support_lengths = pairs_to_batch(support_pairs, max_seq_len)\n        query_seq, query_labels, query_lengths = pairs_to_batch(query_pairs, max_seq_len)\n\n        # ===== INNER LOOP: Adapt parameters using functional approach =====\n        # Clone initial meta-parameters\n        fast_weights = OrderedDict()\n        for name, param in meta_model.named_parameters():\n            fast_weights[name] = param.clone().requires_grad_()\n\n        # Adapt on support set\n        for _ in range(num_inner_steps):\n            # Functional forward with current fast_weights\n            support_logits = functional_forward(\n                support_seq, support_lengths, fast_weights, hidden_dim, n_items\n            )\n            support_loss = criterion(support_logits, support_labels)\n\n            # Compute gradients w.r.t. fast_weights\n            grads = torch.autograd.grad(\n                support_loss,\n                fast_weights.values(),\n                create_graph=use_second_order  # FOMAML: False, MAML: True\n            )\n\n            # Update fast_weights (creates new tensors, no in-place ops)\n            fast_weights = OrderedDict(\n                (name, param - inner_lr * grad)\n                for ((name, param), grad) in zip(fast_weights.items(), grads)\n            )\n\n        # ===== OUTER LOOP: Compute query loss with adapted parameters =====\n        # FIX #3: Residual MAML - combine adapted and unadapted losses\n\n        # 1. Query loss with ADAPTED parameters (standard MAML)\n        query_logits_adapted = functional_forward(\n            query_seq, query_lengths, fast_weights, hidden_dim, n_items\n        )\n        query_loss_adapted = criterion(query_logits_adapted, query_labels)\n\n        # 2. Query loss with UNADAPTED parameters (preserves zero-shot ability)\n        unadapted_weights = OrderedDict()\n        for name, param in meta_model.named_parameters():\n            unadapted_weights[name] = param  # Use original meta-params directly\n\n        query_logits_unadapted = functional_forward(\n            query_seq, query_lengths, unadapted_weights, hidden_dim, n_items\n        )\n        query_loss_unadapted = criterion(query_logits_unadapted, query_labels)\n\n        # 3. Residual MAML meta-loss\n        # L = (1 - lambda) * L_adapted + lambda * L_unadapted\n        query_loss = (1.0 - lambda_residual) * query_loss_adapted + lambda_residual * query_loss_unadapted\n\n        # Accumulate for meta-update\n        meta_loss_total = meta_loss_total + query_loss\n        valid_tasks += 1\n\n    if valid_tasks == 0:\n        continue\n\n    # ===== META-UPDATE =====\n    meta_loss = meta_loss_total / valid_tasks\n    meta_loss.backward()\n\n    # Gradient clipping\n    torch.nn.utils.clip_grad_norm_(meta_model.parameters(), max_norm=10.0)\n\n    meta_optimizer.step()\n\n    # Logging\n    training_history[\"meta_iterations\"].append(meta_iter)\n    training_history[\"meta_train_loss\"].append(meta_loss.item())\n\n    if (meta_iter + 1) % 100 == 0:\n        print(f\"[CELL 07-07] Iter {meta_iter+1}/{num_meta_iterations}: meta_loss={meta_loss.item():.4f}\")\n\n    # Checkpointing\n    if (meta_iter + 1) % CFG[\"maml_config\"][\"checkpoint_interval\"] == 0:\n        checkpoint_path = CHECKPOINTS_DIR / f\"checkpoint_iter{meta_iter+1}.pth\"\n        torch.save({\n            \"meta_iter\": meta_iter + 1,\n            \"model_state_dict\": meta_model.state_dict(),\n            \"optimizer_state_dict\": meta_optimizer.state_dict(),\n            \"config\": CFG,\n            \"training_history\": training_history,\n        }, checkpoint_path)\n        print(f\"[CELL 07-07] Saved checkpoint: {checkpoint_path.name}\")\n\n    # Validation (simpler non-functional approach for validation only)\n    if (meta_iter + 1) % CFG[\"maml_config\"][\"eval_interval\"] == 0:\n        print(f\"[CELL 07-07] Evaluating on val set at iter {meta_iter+1}...\")\n        meta_model.eval()\n\n        val_predictions = []\n        val_labels = []\n\n        for _, episode in episodes_val.head(50).iterrows():\n            support_pairs, query_pairs = get_episode_data(episode, pairs_val)\n\n            if len(support_pairs) == 0 or len(query_pairs) == 0:\n                continue\n\n            support_seq, support_labels_val, support_lengths = pairs_to_batch(support_pairs, max_seq_len)\n            query_seq, query_labels_val, query_lengths = pairs_to_batch(query_pairs, max_seq_len)\n\n            # Save original params\n            original_params = OrderedDict()\n            for name, param in meta_model.named_parameters():\n                original_params[name] = param.data.clone()\n\n            # Adapt on support using standard approach (no gradients needed for validation)\n            with torch.enable_grad():\n                # Clone parameters for adaptation\n                fast_weights_val = OrderedDict()\n                for name, param in meta_model.named_parameters():\n                    fast_weights_val[name] = param.clone().requires_grad_()\n\n                # Inner loop adaptation\n                for _ in range(num_inner_steps):\n                    support_logits_val = functional_forward(\n                        support_seq, support_lengths, fast_weights_val, hidden_dim, n_items\n                    )\n                    support_loss_val = criterion(support_logits_val, support_labels_val)\n\n                    grads_val = torch.autograd.grad(\n                        support_loss_val,\n                        fast_weights_val.values(),\n                        create_graph=False\n                    )\n\n                    fast_weights_val = OrderedDict(\n                        (name, param - inner_lr * grad)\n                        for ((name, param), grad) in zip(fast_weights_val.items(), grads_val)\n                    )\n\n            # Evaluate on query (no gradients)\n            with torch.no_grad():\n                query_logits_val = functional_forward(\n                    query_seq, query_lengths, fast_weights_val, hidden_dim, n_items\n                )\n                query_probs = torch.softmax(query_logits_val, dim=-1).cpu().numpy()\n\n                val_predictions.append(query_probs)\n                val_labels.extend(query_labels_val.cpu().numpy())\n\n            # Restore original params\n            with torch.no_grad():\n                for name, param in meta_model.named_parameters():\n                    param.data.copy_(original_params[name])\n\n        if len(val_predictions) > 0:\n            val_predictions = np.vstack(val_predictions)\n            val_labels = np.array(val_labels)\n            val_metrics = compute_metrics(val_predictions, val_labels)\n\n            training_history[\"val_accuracy\"].append(val_metrics[\"accuracy@1\"])\n            training_history[\"val_iterations\"].append(meta_iter + 1)\n\n            print(f\"[CELL 07-07] Val Acc@1: {val_metrics['accuracy@1']:.4f}, \"\n                  f\"Recall@5: {val_metrics['recall@5']:.4f}, MRR: {val_metrics['mrr']:.4f}\")\n\n# Save final model\nfinal_model_path = MODELS_DIR / f\"maml_basic_gru_K{K}.pth\"\ntorch.save({\n    \"model_state_dict\": meta_model.state_dict(),\n    \"config\": CFG,\n    \"training_history\": training_history,\n}, final_model_path)\n\nprint(f\"\\n[CELL 07-07] Saved final meta-model: {final_model_path.name}\")\nprint(f\"[CELL 07-07] Total training time: {time.time()-t0:.1f}s\")\n\ncell_end(\"CELL 07-07\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07-08] Meta-testing: Few-shot K=5 (with adaptation using functional forward)\n",
    "\n",
    "t0 = cell_start(\"CELL 07-08\", \"Few-shot evaluation (K=5)\")\n",
    "\n",
    "print(\"[CELL 07-08] Evaluating meta-learned model WITH adaptation (few-shot K=5)...\")\n",
    "\n",
    "meta_model.eval()\n",
    "fewshot_predictions = []\n",
    "fewshot_labels = []\n",
    "\n",
    "for _, episode in episodes_test.iterrows():\n",
    "    support_pairs, query_pairs = get_episode_data(episode, pairs_test)\n",
    "    \n",
    "    if len(support_pairs) == 0 or len(query_pairs) == 0:\n",
    "        continue\n",
    "    \n",
    "    support_seq, support_labels_test, support_lengths = pairs_to_batch(support_pairs, max_seq_len)\n",
    "    query_seq, query_labels_test, query_lengths = pairs_to_batch(query_pairs, max_seq_len)\n",
    "    \n",
    "    # Adapt using functional forward (consistent with training)\n",
    "    with torch.enable_grad():\n",
    "        # Clone parameters for adaptation\n",
    "        fast_weights_test = OrderedDict()\n",
    "        for name, param in meta_model.named_parameters():\n",
    "            fast_weights_test[name] = param.clone().requires_grad_()\n",
    "        \n",
    "        # Inner loop adaptation\n",
    "        for _ in range(num_inner_steps):\n",
    "            support_logits_test = functional_forward(\n",
    "                support_seq, support_lengths, fast_weights_test, hidden_dim, n_items\n",
    "            )\n",
    "            support_loss_test = criterion(support_logits_test, support_labels_test)\n",
    "            \n",
    "            grads_test = torch.autograd.grad(\n",
    "                support_loss_test,\n",
    "                fast_weights_test.values(),\n",
    "                create_graph=False  # No second-order needed for testing\n",
    "            )\n",
    "            \n",
    "            fast_weights_test = OrderedDict(\n",
    "                (name, param - inner_lr * grad)\n",
    "                for ((name, param), grad) in zip(fast_weights_test.items(), grads_test)\n",
    "            )\n",
    "    \n",
    "    # Evaluate on query (no gradients)\n",
    "    with torch.no_grad():\n",
    "        query_logits_test = functional_forward(\n",
    "            query_seq, query_lengths, fast_weights_test, hidden_dim, n_items\n",
    "        )\n",
    "        probs = torch.softmax(query_logits_test, dim=-1).cpu().numpy()\n",
    "        \n",
    "        fewshot_predictions.append(probs)\n",
    "        fewshot_labels.extend(query_labels_test.cpu().numpy())\n",
    "\n",
    "fewshot_predictions = np.vstack(fewshot_predictions)\n",
    "fewshot_labels = np.array(fewshot_labels)\n",
    "\n",
    "fewshot_metrics = compute_metrics(fewshot_predictions, fewshot_labels)\n",
    "\n",
    "print(f\"\\n[CELL 07-08] Few-shot Results (K=5 adaptation):\")\n",
    "print(f\"  - Accuracy@1:  {fewshot_metrics['accuracy@1']:.4f}\")\n",
    "print(f\"  - Recall@5:    {fewshot_metrics['recall@5']:.4f}\")\n",
    "print(f\"  - Recall@10:   {fewshot_metrics['recall@10']:.4f}\")\n",
    "print(f\"  - MRR:         {fewshot_metrics['mrr']:.4f}\")\n",
    "\n",
    "cell_end(\"CELL 07-08\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07-09] Ablation Study 1: Support set size (K=1,3,5,10) - functional forward\n",
    "\n",
    "t0 = cell_start(\"CELL 07-09\", \"Ablation: support set size\")\n",
    "\n",
    "print(\"[CELL 07-09] Ablation Study: Varying support set size K...\")\n",
    "\n",
    "support_sizes = CFG[\"ablation_configs\"][\"support_set_sizes\"]\n",
    "ablation_support_results = {}\n",
    "\n",
    "meta_model.eval()\n",
    "\n",
    "for K_test in support_sizes:\n",
    "    print(f\"\\n[CELL 07-09] Testing with K={K_test}...\")\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, episode in episodes_test.iterrows():\n",
    "        support_pairs, query_pairs = get_episode_data(episode, pairs_test)\n",
    "        \n",
    "        if len(support_pairs) < K_test or len(query_pairs) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Use only K_test support pairs\n",
    "        support_pairs_k = support_pairs.head(K_test)\n",
    "        \n",
    "        support_seq, support_labels_abl, support_lengths = pairs_to_batch(support_pairs_k, max_seq_len)\n",
    "        query_seq, query_labels_abl, query_lengths = pairs_to_batch(query_pairs, max_seq_len)\n",
    "        \n",
    "        # Adapt using functional forward\n",
    "        with torch.enable_grad():\n",
    "            fast_weights_abl = OrderedDict()\n",
    "            for name, param in meta_model.named_parameters():\n",
    "                fast_weights_abl[name] = param.clone().requires_grad_()\n",
    "            \n",
    "            for _ in range(num_inner_steps):\n",
    "                support_logits_abl = functional_forward(\n",
    "                    support_seq, support_lengths, fast_weights_abl, hidden_dim, n_items\n",
    "                )\n",
    "                support_loss_abl = criterion(support_logits_abl, support_labels_abl)\n",
    "                \n",
    "                grads_abl = torch.autograd.grad(\n",
    "                    support_loss_abl,\n",
    "                    fast_weights_abl.values(),\n",
    "                    create_graph=False\n",
    "                )\n",
    "                \n",
    "                fast_weights_abl = OrderedDict(\n",
    "                    (name, param - inner_lr * grad)\n",
    "                    for ((name, param), grad) in zip(fast_weights_abl.items(), grads_abl)\n",
    "                )\n",
    "        \n",
    "        # Evaluate on query\n",
    "        with torch.no_grad():\n",
    "            query_logits_abl = functional_forward(\n",
    "                query_seq, query_lengths, fast_weights_abl, hidden_dim, n_items\n",
    "            )\n",
    "            probs = torch.softmax(query_logits_abl, dim=-1).cpu().numpy()\n",
    "            \n",
    "            predictions.append(probs)\n",
    "            labels.extend(query_labels_abl.cpu().numpy())\n",
    "    \n",
    "    if len(predictions) > 0:\n",
    "        predictions = np.vstack(predictions)\n",
    "        labels = np.array(labels)\n",
    "        metrics = compute_metrics(predictions, labels)\n",
    "        ablation_support_results[K_test] = metrics\n",
    "        \n",
    "        print(f\"[CELL 07-09] K={K_test}: Acc@1={metrics['accuracy@1']:.4f}, \"\n",
    "              f\"Recall@5={metrics['recall@5']:.4f}, MRR={metrics['mrr']:.4f}\")\n",
    "\n",
    "print(f\"\\n[CELL 07-09] Ablation complete: tested K \u2208 {support_sizes}\")\n",
    "\n",
    "cell_end(\"CELL 07-09\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07-10] Ablation Study 2: Adaptation steps (1,3,5,10) - functional forward\n",
    "\n",
    "t0 = cell_start(\"CELL 07-10\", \"Ablation: adaptation steps\")\n",
    "\n",
    "print(\"[CELL 07-10] Ablation Study: Varying adaptation steps...\")\n",
    "\n",
    "adaptation_steps = CFG[\"ablation_configs\"][\"adaptation_steps\"]\n",
    "ablation_steps_results = {}\n",
    "\n",
    "meta_model.eval()\n",
    "\n",
    "for num_steps in adaptation_steps:\n",
    "    print(f\"\\n[CELL 07-10] Testing with {num_steps} adaptation steps...\")\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    \n",
    "    for _, episode in episodes_test.iterrows():\n",
    "        support_pairs, query_pairs = get_episode_data(episode, pairs_test)\n",
    "        \n",
    "        if len(support_pairs) == 0 or len(query_pairs) == 0:\n",
    "            continue\n",
    "        \n",
    "        support_seq, support_labels_steps, support_lengths = pairs_to_batch(support_pairs, max_seq_len)\n",
    "        query_seq, query_labels_steps, query_lengths = pairs_to_batch(query_pairs, max_seq_len)\n",
    "        \n",
    "        # Adapt using functional forward with varying steps\n",
    "        with torch.enable_grad():\n",
    "            fast_weights_steps = OrderedDict()\n",
    "            for name, param in meta_model.named_parameters():\n",
    "                fast_weights_steps[name] = param.clone().requires_grad_()\n",
    "            \n",
    "            for _ in range(num_steps):  # Use num_steps instead of num_inner_steps\n",
    "                support_logits_steps = functional_forward(\n",
    "                    support_seq, support_lengths, fast_weights_steps, hidden_dim, n_items\n",
    "                )\n",
    "                support_loss_steps = criterion(support_logits_steps, support_labels_steps)\n",
    "                \n",
    "                grads_steps = torch.autograd.grad(\n",
    "                    support_loss_steps,\n",
    "                    fast_weights_steps.values(),\n",
    "                    create_graph=False\n",
    "                )\n",
    "                \n",
    "                fast_weights_steps = OrderedDict(\n",
    "                    (name, param - inner_lr * grad)\n",
    "                    for ((name, param), grad) in zip(fast_weights_steps.items(), grads_steps)\n",
    "                )\n",
    "        \n",
    "        # Evaluate on query\n",
    "        with torch.no_grad():\n",
    "            query_logits_steps = functional_forward(\n",
    "                query_seq, query_lengths, fast_weights_steps, hidden_dim, n_items\n",
    "            )\n",
    "            probs = torch.softmax(query_logits_steps, dim=-1).cpu().numpy()\n",
    "            \n",
    "            predictions.append(probs)\n",
    "            labels.extend(query_labels_steps.cpu().numpy())\n",
    "    \n",
    "    if len(predictions) > 0:\n",
    "        predictions = np.vstack(predictions)\n",
    "        labels = np.array(labels)\n",
    "        metrics = compute_metrics(predictions, labels)\n",
    "        ablation_steps_results[num_steps] = metrics\n",
    "        \n",
    "        print(f\"[CELL 07-10] Steps={num_steps}: Acc@1={metrics['accuracy@1']:.4f}, \"\n",
    "              f\"Recall@5={metrics['recall@5']:.4f}, MRR={metrics['mrr']:.4f}\")\n",
    "\n",
    "print(f\"\\n[CELL 07-10] Ablation complete: tested adaptation steps \u2208 {adaptation_steps}\")\n",
    "\n",
    "cell_end(\"CELL 07-10\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07-11] Analysis: Parameter update visualization - functional forward\n",
    "\n",
    "t0 = cell_start(\"CELL 07-11\", \"Parameter update analysis\")\n",
    "\n",
    "print(\"[CELL 07-11] Analyzing parameter updates during adaptation...\")\n",
    "\n",
    "# Select one test episode for analysis\n",
    "sample_episode = episodes_test.iloc[0]\n",
    "support_pairs, query_pairs = get_episode_data(sample_episode, pairs_test)\n",
    "\n",
    "if len(support_pairs) > 0:\n",
    "    support_seq, support_labels_viz, support_lengths = pairs_to_batch(support_pairs, max_seq_len)\n",
    "    \n",
    "    # NOTE: Do NOT call meta_model.eval() here - we need gradients for functional_forward\n",
    "    # The functional forward approach doesn't use the model's forward(), so eval mode doesn't matter\n",
    "    \n",
    "    # Get original parameters (before adaptation)\n",
    "    param_norms_before = {}\n",
    "    for name, param in meta_model.named_parameters():\n",
    "        param_norms_before[name] = param.data.norm().item()\n",
    "    \n",
    "    # Adapt using functional forward\n",
    "    with torch.enable_grad():\n",
    "        fast_weights_viz = OrderedDict()\n",
    "        for name, param in meta_model.named_parameters():\n",
    "            fast_weights_viz[name] = param.clone().requires_grad_()\n",
    "        \n",
    "        for _ in range(num_inner_steps):\n",
    "            support_logits_viz = functional_forward(\n",
    "                support_seq, support_lengths, fast_weights_viz, hidden_dim, n_items\n",
    "            )\n",
    "            support_loss_viz = criterion(support_logits_viz, support_labels_viz)\n",
    "            \n",
    "            grads_viz = torch.autograd.grad(\n",
    "                support_loss_viz,\n",
    "                fast_weights_viz.values(),\n",
    "                create_graph=False\n",
    "            )\n",
    "            \n",
    "            fast_weights_viz = OrderedDict(\n",
    "                (name, param - inner_lr * grad)\n",
    "                for ((name, param), grad) in zip(fast_weights_viz.items(), grads_viz)\n",
    "            )\n",
    "    \n",
    "    # Compute parameter changes\n",
    "    param_norms_after = {}\n",
    "    param_changes = {}\n",
    "    \n",
    "    for name in fast_weights_viz.keys():\n",
    "        adapted_norm = fast_weights_viz[name].data.norm().item()\n",
    "        original_norm = param_norms_before[name]\n",
    "        change = adapted_norm - original_norm\n",
    "        \n",
    "        param_norms_after[name] = adapted_norm\n",
    "        param_changes[name] = {\n",
    "            \"before\": original_norm,\n",
    "            \"after\": adapted_norm,\n",
    "            \"change\": change,\n",
    "            \"change_pct\": (change / original_norm * 100) if original_norm > 0 else 0,\n",
    "        }\n",
    "    \n",
    "    print(f\"\\n[CELL 07-11] Parameter changes after {num_inner_steps} adaptation steps:\")\n",
    "    print(f\"{'Parameter':<30} {'Before':>12} {'After':>12} {'Change':>12} {'Change %':>10}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    for name, stats in list(param_changes.items())[:10]:  # Show first 10\n",
    "        print(f\"{name:<30} {stats['before']:>12.4f} {stats['after']:>12.4f} \"\n",
    "              f\"{stats['change']:>12.4f} {stats['change_pct']:>9.2f}%\")\n",
    "    \n",
    "    # Visualization: parameter change distribution\n",
    "    VIZ_DIR = OUT_DIR / \"visualizations\"\n",
    "    VIZ_DIR.mkdir(exist_ok=True)\n",
    "    \n",
    "    sns.set_style(\"whitegrid\")\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    change_pcts = [stats[\"change_pct\"] for stats in param_changes.values()]\n",
    "    ax.hist(change_pcts, bins=30, color='#3498db', alpha=0.7, edgecolor='black')\n",
    "    ax.axvline(0, color='red', linestyle='--', linewidth=2, label='No change')\n",
    "    ax.set_xlabel('Parameter Change (%)', fontsize=11, fontweight='bold')\n",
    "    ax.set_ylabel('Number of Parameters', fontsize=11, fontweight='bold')\n",
    "    ax.set_title('Parameter Change Distribution After Adaptation (MAML)', fontsize=12, fontweight='bold')\n",
    "    ax.legend(loc='upper right', fontsize=10)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(VIZ_DIR / \"param_change_distribution.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"\\n[CELL 07-11] Saved: param_change_distribution.png\")\n",
    "\n",
    "cell_end(\"CELL 07-11\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07-12] Results summary table + comparison with baselines\n",
    "\n",
    "t0 = cell_start(\"CELL 07-12\", \"Results summary\")\n",
    "\n",
    "print(\"\\n[CELL 07-12] ========== RESULTS SUMMARY (Test Set) ==========\")\n",
    "print(f\"K={K}, Q={Q} | Test Episodes: {len(episodes_test):,}\\n\")\n",
    "\n",
    "# Load GRU baseline results for comparison\n",
    "baseline_results_path = RESULTS_DIR / f\"baselines_K{K}_Q{Q}.json\"\n",
    "if baseline_results_path.exists():\n",
    "    baseline_results = read_json(baseline_results_path)\n",
    "    gru_baseline_metrics = baseline_results[\"baselines\"][\"gru_global\"]\n",
    "else:\n",
    "    gru_baseline_metrics = {\"accuracy@1\": 0.3373, \"recall@5\": 0.5590, \"recall@10\": 0.6575, \"mrr\": 0.4437}\n",
    "\n",
    "# Create comparison table\n",
    "print(f\"{'Model':<30} {'Acc@1':>10} {'Recall@5':>10} {'Recall@10':>10} {'MRR':>10}\")\n",
    "print(\"-\" * 72)\n",
    "\n",
    "# Baselines\n",
    "print(f\"{'GRU (Baseline - 06)':<30} {gru_baseline_metrics['accuracy@1']:>10.4f} \"\n",
    "      f\"{gru_baseline_metrics['recall@5']:>10.4f} {gru_baseline_metrics['recall@10']:>10.4f} \"\n",
    "      f\"{gru_baseline_metrics['mrr']:>10.4f}\")\n",
    "\n",
    "# MAML results\n",
    "print(f\"{'MAML Zero-shot':<30} {zeroshot_metrics['accuracy@1']:>10.4f} \"\n",
    "      f\"{zeroshot_metrics['recall@5']:>10.4f} {zeroshot_metrics['recall@10']:>10.4f} \"\n",
    "      f\"{zeroshot_metrics['mrr']:>10.4f}\")\n",
    "\n",
    "print(f\"{'MAML Few-shot (K=5)':<30} {fewshot_metrics['accuracy@1']:>10.4f} \"\n",
    "      f\"{fewshot_metrics['recall@5']:>10.4f} {fewshot_metrics['recall@10']:>10.4f} \"\n",
    "      f\"{fewshot_metrics['mrr']:>10.4f}\")\n",
    "\n",
    "# Improvement over baseline\n",
    "improvement = (fewshot_metrics['accuracy@1'] - gru_baseline_metrics['accuracy@1']) / gru_baseline_metrics['accuracy@1'] * 100\n",
    "print(f\"\\n[CELL 07-12] MAML Few-shot improvement over GRU baseline: {improvement:+.2f}%\")\n",
    "\n",
    "# Ablation results\n",
    "print(f\"\\n[CELL 07-12] ========== ABLATION STUDY 1: Support Set Size ==========\")\n",
    "print(f\"{'K (Support Size)':<20} {'Acc@1':>10} {'Recall@5':>10} {'Recall@10':>10} {'MRR':>10}\")\n",
    "print(\"-\" * 62)\n",
    "for K_test, metrics in ablation_support_results.items():\n",
    "    print(f\"{K_test:<20} {metrics['accuracy@1']:>10.4f} {metrics['recall@5']:>10.4f} \"\n",
    "          f\"{metrics['recall@10']:>10.4f} {metrics['mrr']:>10.4f}\")\n",
    "\n",
    "print(f\"\\n[CELL 07-12] ========== ABLATION STUDY 2: Adaptation Steps ==========\")\n",
    "print(f\"{'Adaptation Steps':<20} {'Acc@1':>10} {'Recall@5':>10} {'Recall@10':>10} {'MRR':>10}\")\n",
    "print(\"-\" * 62)\n",
    "for num_steps, metrics in ablation_steps_results.items():\n",
    "    print(f\"{num_steps:<20} {metrics['accuracy@1']:>10.4f} {metrics['recall@5']:>10.4f} \"\n",
    "          f\"{metrics['recall@10']:>10.4f} {metrics['mrr']:>10.4f}\")\n",
    "\n",
    "# Save all results\n",
    "all_results = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"k_shot_config\": {\"K\": K, \"Q\": Q},\n",
    "    \"n_test_episodes\": len(episodes_test),\n",
    "    \"baseline\": {\n",
    "        \"gru_global\": gru_baseline_metrics,\n",
    "    },\n",
    "    \"maml\": {\n",
    "        \"zero_shot\": zeroshot_metrics,\n",
    "        \"few_shot_K5\": fewshot_metrics,\n",
    "    },\n",
    "    \"ablation_support_size\": ablation_support_results,\n",
    "    \"ablation_adaptation_steps\": ablation_steps_results,\n",
    "    \"improvement_over_baseline_pct\": improvement,\n",
    "    \"training_history\": training_history,\n",
    "}\n",
    "\n",
    "results_path = Path(CFG[\"outputs\"][\"results\"])\n",
    "write_json_atomic(results_path, all_results)\n",
    "print(f\"\\n[CELL 07-12] Saved: {results_path.name}\")\n",
    "\n",
    "cell_end(\"CELL 07-12\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07-13] Update report + manifest\n",
    "\n",
    "t0 = cell_start(\"CELL 07-13\", \"Write report + manifest\")\n",
    "\n",
    "report = read_json(REPORT_PATH)\n",
    "manifest = read_json(MANIFEST_PATH)\n",
    "\n",
    "# Metrics\n",
    "report[\"metrics\"] = {\n",
    "    \"n_test_episodes\": len(episodes_test),\n",
    "    \"gru_baseline_acc1\": gru_baseline_metrics['accuracy@1'],\n",
    "    \"maml_zero_shot_acc1\": zeroshot_metrics['accuracy@1'],\n",
    "    \"maml_few_shot_K5_acc1\": fewshot_metrics['accuracy@1'],\n",
    "    \"improvement_over_baseline_pct\": improvement,\n",
    "    \"training_iterations\": num_meta_iterations,\n",
    "}\n",
    "\n",
    "# Key findings\n",
    "report[\"key_findings\"].extend([\n",
    "    f\"MAML meta-training: {num_meta_iterations:,} iterations with {meta_batch_size} tasks/batch\",\n",
    "    f\"Zero-shot performance (no adaptation): Acc@1={zeroshot_metrics['accuracy@1']:.4f}\",\n",
    "    f\"Few-shot performance (K=5 adaptation): Acc@1={fewshot_metrics['accuracy@1']:.4f}\",\n",
    "    f\"Improvement over GRU baseline: {improvement:+.2f}% ({fewshot_metrics['accuracy@1']:.4f} vs {gru_baseline_metrics['accuracy@1']:.4f})\",\n",
    "    f\"Ablation: Best K={max(ablation_support_results, key=lambda k: ablation_support_results[k]['accuracy@1'])} \"\n",
    "    f\"(Acc@1={max(ablation_support_results.values(), key=lambda m: m['accuracy@1'])['accuracy@1']:.4f})\",\n",
    "    f\"Ablation: Best adaptation steps={max(ablation_steps_results, key=lambda k: ablation_steps_results[k]['accuracy@1'])} \"\n",
    "    f\"(Acc@1={max(ablation_steps_results.values(), key=lambda m: m['accuracy@1'])['accuracy@1']:.4f})\",\n",
    "])\n",
    "\n",
    "# Sanity samples\n",
    "report[\"sanity_samples\"][\"maml_config\"] = CFG[\"maml_config\"]\n",
    "report[\"sanity_samples\"][\"sample_episode\"] = {\n",
    "    \"episode_id\": int(episodes_test.iloc[0][\"episode_id\"]),\n",
    "    \"user_id\": str(episodes_test.iloc[0][\"user_id\"]),\n",
    "    \"n_support_pairs\": len(episodes_test.iloc[0][\"support_pair_ids\"]),\n",
    "    \"n_query_pairs\": len(episodes_test.iloc[0][\"query_pair_ids\"]),\n",
    "}\n",
    "\n",
    "# Fingerprints\n",
    "report[\"data_fingerprints\"][\"meta_model\"] = {\n",
    "    \"path\": str(final_model_path),\n",
    "    \"bytes\": int(final_model_path.stat().st_size),\n",
    "    \"sha256\": sha256_file(final_model_path),\n",
    "}\n",
    "\n",
    "write_json_atomic(REPORT_PATH, report)\n",
    "\n",
    "# Manifest\n",
    "def add_artifact(path: Path) -> None:\n",
    "    rec = {\"path\": str(path), \"bytes\": int(path.stat().st_size), \"sha256\": None, \"sha256_error\": None}\n",
    "    try:\n",
    "        rec[\"sha256\"] = sha256_file(path)\n",
    "    except Exception as e:\n",
    "        rec[\"sha256_error\"] = str(e)\n",
    "    manifest[\"artifacts\"].append(rec)\n",
    "\n",
    "add_artifact(final_model_path)\n",
    "add_artifact(results_path)\n",
    "\n",
    "# Add checkpoints\n",
    "for checkpoint_file in sorted(CHECKPOINTS_DIR.glob(\"checkpoint_iter*.pth\")):\n",
    "    add_artifact(checkpoint_file)\n",
    "\n",
    "write_json_atomic(MANIFEST_PATH, manifest)\n",
    "\n",
    "print(f\"[CELL 07-13] Updated: {REPORT_PATH}\")\n",
    "print(f\"[CELL 07-13] Updated: {MANIFEST_PATH}\")\n",
    "\n",
    "cell_end(\"CELL 07-13\", t0)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"\u2705 NOTEBOOK 07 COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"\\n\ud83d\udcca Key Results:\")\n",
    "print(f\"  - GRU Baseline (06):        {gru_baseline_metrics['accuracy@1']:.4f} Acc@1\")\n",
    "print(f\"  - MAML Zero-shot:           {zeroshot_metrics['accuracy@1']:.4f} Acc@1\")\n",
    "print(f\"  - MAML Few-shot (K=5):      {fewshot_metrics['accuracy@1']:.4f} Acc@1\")\n",
    "print(f\"  - Improvement:              {improvement:+.2f}%\")\n",
    "print(f\"\\n\ud83d\udcc1 Outputs:\")\n",
    "print(f\"  - Meta-model: {final_model_path}\")\n",
    "print(f\"  - Results:    {results_path}\")\n",
    "print(f\"  - Report:     {REPORT_PATH}\")\n",
    "print(f\"\\n\ud83c\udfaf Next Steps:\")\n",
    "print(f\"  - Fine-tune hyperparameters (\u03b1, \u03b2, inner steps)\")\n",
    "print(f\"  - Try different architectures (Transformer, GNN)\")\n",
    "print(f\"  - Compare with other meta-learning methods (ProtoNet, Matching Networks)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## \ud83d\udccb Notebook 07f: MAML Meta-Learning\n",
    "\n",
    "**Status**: \u26a0\ufe0f NOT YET RUN - Ready for execution\n",
    "\n",
    "**What This Notebook Does:**\n",
    "- Implements MAML (Model-Agnostic Meta-Learning) for cold-start MOOC recommendation\n",
    "- Uses episodic meta-learning with K=5 support pairs, Q=10 query pairs\n",
    "- Trains meta-model for 10,000 iterations on XuetangX dataset\n",
    "- Evaluates zero-shot and few-shot performance on cold-start users\n",
    "- Runs ablation studies on support set size and adaptation steps\n",
    "\n",
    "**Expected Outputs** (after running):\n",
    "- Meta-trained model: `models/maml/maml_gru_K5.pth`\n",
    "- Checkpoints: `models/maml/checkpoints/checkpoint_iter{N}.pth`\n",
    "- Results: `results/maml_K5_Q10.json`\n",
    "- Report: `reports/07f_maml_residual_xuetangx/<run_tag>/report.json`\n",
    "\n",
    "**Dataset Used:**\n",
    "- Training: 66,187 episodes from 3,006 users (XuetangX)\n",
    "- Validation: 340 episodes from 340 users\n",
    "- Test: 346 episodes from 346 cold-start users\n",
    "- Vocabulary: 343 courses\n",
    "- Baseline: GRU achieved 33.73% Acc@1 (from Notebook 06)\n",
    "\n",
    "**Configuration:**\n",
    "- MAML type: Second-order (full MAML, not FOMAML)\n",
    "- Inner LR (\u03b1): 0.01\n",
    "- Outer LR (\u03b2): 0.001\n",
    "- Inner steps: 5\n",
    "- Meta-batch size: 32\n",
    "- Iterations: 10,000\n",
    "\n",
    "**To Run This Notebook:**\n",
    "1. Execute all cells in order (Runtime \u2192 Run all)\n",
    "2. Training will take 6-12 hours depending on GPU\n",
    "3. Results will be saved automatically\n",
    "4. All metrics use real data - no synthetic/toy data\n",
    "\n",
    "**Next Steps After Running:**\n",
    "- Compare MAML results with GRU baseline (Notebook 06)\n",
    "- Analyze ablation study results\n",
    "- Consider hyperparameter tuning or architecture changes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}