{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 03: Build Vocabulary and Pairs (MARS)\n",
    "\n",
    "**Purpose:** Build item vocabulary and create prefix->label pairs for next-item prediction.\n",
    "\n",
    "**Input:** `data/processed/mars/sessions/sessions.parquet`\n",
    "\n",
    "**Output:**\n",
    "- `data/processed/mars/vocab/item2id.json`\n",
    "- `data/processed/mars/pairs/pairs_all.parquet`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL 03-00] start=2026-01-12T22:20:17\n",
      "[CELL 03-00] REPO_ROOT: C:\\anonymous-users-mooc-session-meta\n",
      "[CELL 03-00] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 03-00] Bootstrap\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(f\"[CELL 03-00] start={t0.isoformat(timespec='seconds')}\")\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"PROJECT_STATE.md\").exists():\n",
    "            return p\n",
    "    raise RuntimeError(\"Could not find PROJECT_STATE.md\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "print(\"[CELL 03-00] REPO_ROOT:\", REPO_ROOT)\n",
    "\n",
    "PATHS = {\n",
    "    \"DATA_PROCESSED\": REPO_ROOT / \"data\" / \"processed\",\n",
    "    \"REPORTS\": REPO_ROOT / \"reports\",\n",
    "}\n",
    "\n",
    "def cell_start(cell_id: str, title: str, **kwargs) -> float:\n",
    "    t = time.time()\n",
    "    print(f\"\\n[{cell_id}] {title}\")\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    return t\n",
    "\n",
    "def cell_end(cell_id: str, t0: float, **kwargs) -> None:\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    print(f\"[{cell_id}] elapsed={time.time()-t0:.2f}s\")\n",
    "\n",
    "def write_json_atomic(path: Path, obj: Any, indent: int = 2) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + f\".tmp_{uuid.uuid4().hex}\")\n",
    "    with tmp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=indent)\n",
    "    tmp.replace(path)\n",
    "\n",
    "NOTEBOOK_NAME = \"03_build_vocab_and_pairs_mars\"\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_ID = uuid.uuid4().hex\n",
    "\n",
    "OUT_DIR = PATHS[\"REPORTS\"] / NOTEBOOK_NAME / RUN_TAG\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "REPORT_PATH = OUT_DIR / \"report.json\"\n",
    "\n",
    "report = {\"run_id\": RUN_ID, \"notebook\": NOTEBOOK_NAME, \"metrics\": {}, \"key_findings\": []}\n",
    "\n",
    "print(\"[CELL 03-00] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 03-01] Load sessionized data\n",
      "[CELL 03-01] Loaded: C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\sessions\\sessions.parquet\n",
      "[CELL 03-01] Shape: (3655, 6)\n",
      "[CELL 03-01] Users: 822\n",
      "[CELL 03-01] Items: 776\n",
      "[CELL 03-01] elapsed=0.05s\n"
     ]
    }
   ],
   "source": [
    "# [CELL 03-01] Load sessionized data\n",
    "\n",
    "t0 = cell_start(\"CELL 03-01\", \"Load sessionized data\")\n",
    "\n",
    "INPUT_PATH = PATHS[\"DATA_PROCESSED\"] / \"mars\" / \"sessions\" / \"sessions.parquet\"\n",
    "df = pd.read_parquet(INPUT_PATH)\n",
    "\n",
    "print(f\"[CELL 03-01] Loaded: {INPUT_PATH}\")\n",
    "print(f\"[CELL 03-01] Shape: {df.shape}\")\n",
    "print(f\"[CELL 03-01] Users: {df['user_id'].nunique():,}\")\n",
    "print(f\"[CELL 03-01] Items: {df['item_id'].nunique():,}\")\n",
    "\n",
    "cell_end(\"CELL 03-01\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 03-02] Build vocabulary\n",
      "[CELL 03-02] Vocabulary size: 777 (including padding)\n",
      "[CELL 03-02] Unique items: 776\n",
      "[CELL 03-02] Saved: C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\vocab\\item2id.json\n",
      "[CELL 03-02] elapsed=0.01s\n"
     ]
    }
   ],
   "source": [
    "# [CELL 03-02] Build vocabulary (item2id mapping)\n",
    "\n",
    "t0 = cell_start(\"CELL 03-02\", \"Build vocabulary\")\n",
    "\n",
    "# Count item frequencies\n",
    "item_counts = Counter(df[\"item_id\"])\n",
    "\n",
    "# Create mapping (0 reserved for padding)\n",
    "sorted_items = sorted(item_counts.keys())\n",
    "item2id = {item: idx + 1 for idx, item in enumerate(sorted_items)}  # 0 = padding\n",
    "id2item = {idx: item for item, idx in item2id.items()}\n",
    "\n",
    "n_items = len(item2id) + 1  # +1 for padding\n",
    "\n",
    "print(f\"[CELL 03-02] Vocabulary size: {n_items} (including padding)\")\n",
    "print(f\"[CELL 03-02] Unique items: {len(item2id)}\")\n",
    "\n",
    "# Save vocabulary\n",
    "VOCAB_DIR = PATHS[\"DATA_PROCESSED\"] / \"mars\" / \"vocab\"\n",
    "VOCAB_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "write_json_atomic(VOCAB_DIR / \"item2id.json\", item2id)\n",
    "write_json_atomic(VOCAB_DIR / \"id2item.json\", {str(k): v for k, v in id2item.items()})\n",
    "\n",
    "print(f\"[CELL 03-02] Saved: {VOCAB_DIR / 'item2id.json'}\")\n",
    "\n",
    "report[\"metrics\"][\"vocab_size\"] = n_items\n",
    "\n",
    "cell_end(\"CELL 03-02\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 03-03] Create prefix->label pairs\n",
      "[CELL 03-03] Total pairs: 2,833\n",
      "[CELL 03-03] Prefix length distribution:\n",
      "count    2833.000000\n",
      "mean       18.144370\n",
      "std        24.546638\n",
      "min         1.000000\n",
      "25%         2.000000\n",
      "50%         8.000000\n",
      "75%        24.000000\n",
      "max       133.000000\n",
      "Name: prefix_len, dtype: float64\n",
      "[CELL 03-03] elapsed=0.32s\n"
     ]
    }
   ],
   "source": [
    "# [CELL 03-03] Create prefix->label pairs\n",
    "\n",
    "t0 = cell_start(\"CELL 03-03\", \"Create prefix->label pairs\")\n",
    "\n",
    "# Map items to IDs\n",
    "df[\"item_idx\"] = df[\"item_id\"].map(item2id)\n",
    "\n",
    "# Group by user and create pairs\n",
    "pairs = []\n",
    "pair_id = 0\n",
    "\n",
    "for user_id, user_df in df.groupby(\"user_id\"):\n",
    "    user_df = user_df.sort_values(\"ts_epoch\")\n",
    "    items = user_df[\"item_idx\"].tolist()\n",
    "    timestamps = user_df[\"ts_epoch\"].tolist()\n",
    "    \n",
    "    # Create pairs: prefix -> next item\n",
    "    for i in range(1, len(items)):\n",
    "        prefix = items[:i]\n",
    "        label = items[i]\n",
    "        label_ts = timestamps[i]\n",
    "        \n",
    "        pairs.append({\n",
    "            \"pair_id\": pair_id,\n",
    "            \"user_id\": user_id,\n",
    "            \"prefix\": prefix,\n",
    "            \"label\": label,\n",
    "            \"label_ts_epoch\": label_ts,\n",
    "            \"prefix_len\": len(prefix),\n",
    "        })\n",
    "        pair_id += 1\n",
    "\n",
    "df_pairs = pd.DataFrame(pairs)\n",
    "\n",
    "print(f\"[CELL 03-03] Total pairs: {len(df_pairs):,}\")\n",
    "print(f\"[CELL 03-03] Prefix length distribution:\")\n",
    "print(df_pairs[\"prefix_len\"].describe())\n",
    "\n",
    "report[\"metrics\"][\"n_pairs\"] = len(df_pairs)\n",
    "\n",
    "cell_end(\"CELL 03-03\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 03-04] Save pairs\n",
      "[CELL 03-04] Saved: C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\pairs\\pairs_all.parquet\n",
      "\n",
      "============================================================\n",
      "NOTEBOOK 03 COMPLETE: MARS Vocab & Pairs\n",
      "============================================================\n",
      "Vocabulary: 777 items\n",
      "Pairs: 2,833\n",
      "[CELL 03-04] elapsed=0.03s\n"
     ]
    }
   ],
   "source": [
    "# [CELL 03-04] Save pairs\n",
    "\n",
    "t0 = cell_start(\"CELL 03-04\", \"Save pairs\")\n",
    "\n",
    "PAIRS_DIR = PATHS[\"DATA_PROCESSED\"] / \"mars\" / \"pairs\"\n",
    "PAIRS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_file = PAIRS_DIR / \"pairs_all.parquet\"\n",
    "df_pairs.to_parquet(out_file, index=False)\n",
    "\n",
    "print(f\"[CELL 03-04] Saved: {out_file}\")\n",
    "\n",
    "write_json_atomic(REPORT_PATH, report)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NOTEBOOK 03 COMPLETE: MARS Vocab & Pairs\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Vocabulary: {n_items} items\")\n",
    "print(f\"Pairs: {len(df_pairs):,}\")\n",
    "\n",
    "cell_end(\"CELL 03-04\", t0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
