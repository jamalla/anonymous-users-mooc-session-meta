{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29129c7d",
   "metadata": {},
   "source": [
    "Bootstrap: repo root, paths, logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe77377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL 02-00] start=2026-01-06T22:11:27\n",
      "[CELL 02-00] CWD: C:\\anonymous-users-mooc-session-meta\\notebooks\n",
      "[CELL 02-00] REPO_ROOT: C:\\anonymous-users-mooc-session-meta\n",
      "[CELL 02-00] PROJECT_STATE=C:\\anonymous-users-mooc-session-meta\\PROJECT_STATE.md\n",
      "[CELL 02-00] META_REGISTRY=C:\\anonymous-users-mooc-session-meta\\meta.json\n",
      "[CELL 02-00] DATA_RAW=C:\\anonymous-users-mooc-session-meta\\data\\raw\n",
      "[CELL 02-00] DATA_INTERIM=C:\\anonymous-users-mooc-session-meta\\data\\interim\n",
      "[CELL 02-00] DATA_PROCESSED=C:\\anonymous-users-mooc-session-meta\\data\\processed\n",
      "[CELL 02-00] REPORTS=C:\\anonymous-users-mooc-session-meta\\reports\n",
      "[CELL 02-00] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-00] Bootstrap: repo root + paths + logger\n",
    "\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(f\"[CELL 02-00] start={t0.isoformat(timespec='seconds')}\")\n",
    "print(\"[CELL 02-00] CWD:\", Path.cwd().resolve())\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"PROJECT_STATE.md\").exists():\n",
    "            return p\n",
    "    raise RuntimeError(\"Could not find PROJECT_STATE.md. Open notebook from within the repo.\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "print(\"[CELL 02-00] REPO_ROOT:\", REPO_ROOT)\n",
    "\n",
    "PATHS = {\n",
    "    \"PROJECT_STATE\": REPO_ROOT / \"PROJECT_STATE.md\",\n",
    "    \"META_REGISTRY\": REPO_ROOT / \"meta.json\",\n",
    "    \"DATA_RAW\": REPO_ROOT / \"data\" / \"raw\",\n",
    "    \"DATA_INTERIM\": REPO_ROOT / \"data\" / \"interim\",\n",
    "    \"DATA_PROCESSED\": REPO_ROOT / \"data\" / \"processed\",\n",
    "    \"REPORTS\": REPO_ROOT / \"reports\",\n",
    "}\n",
    "for k, v in PATHS.items():\n",
    "    print(f\"[CELL 02-00] {k}={v}\")\n",
    "\n",
    "def cell_start(cell_id: str, title: str, **kwargs: Any) -> float:\n",
    "    t = time.time()\n",
    "    print(f\"\\n[{cell_id}] {title}\")\n",
    "    print(f\"[{cell_id}] start={datetime.now().isoformat(timespec='seconds')}\")\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    return t\n",
    "\n",
    "def cell_end(cell_id: str, t0: float, **kwargs: Any) -> None:\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    print(f\"[{cell_id}] elapsed={time.time()-t0:.2f}s\")\n",
    "    print(f\"[{cell_id}] done\")\n",
    "\n",
    "print(\"[CELL 02-00] done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cf98fe",
   "metadata": {},
   "source": [
    "JSON IO + hashing + safe artifact hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd93a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-01] JSON IO + hashing helpers (Timestamp-safe)\n",
      "[CELL 02-01] start=2026-01-06T22:11:27\n",
      "[CELL 02-01] elapsed=0.00s\n",
      "[CELL 02-01] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-01] JSON IO + hashing + safe hash (Windows locks) + JSON serializer for Timestamp\n",
    "\n",
    "t0 = cell_start(\"CELL 02-01\", \"JSON IO + hashing helpers (Timestamp-safe)\")\n",
    "\n",
    "import json\n",
    "import uuid\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "def _json_default(o):\n",
    "    # pandas Timestamp\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        if isinstance(o, (pd.Timestamp,)):\n",
    "            return o.isoformat()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # numpy scalars\n",
    "    try:\n",
    "        import numpy as np\n",
    "        if isinstance(o, (np.integer,)):\n",
    "            return int(o)\n",
    "        if isinstance(o, (np.floating,)):\n",
    "            return float(o)\n",
    "        if isinstance(o, (np.bool_,)):\n",
    "            return bool(o)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # python datetime/date\n",
    "    try:\n",
    "        from datetime import datetime, date\n",
    "        if isinstance(o, (datetime, date)):\n",
    "            return o.isoformat()\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback\n",
    "    return str(o)\n",
    "\n",
    "def write_json_atomic(path: Path, obj: Any, indent: int = 2) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + f\".tmp_{uuid.uuid4().hex}\")\n",
    "    with tmp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=indent, default=_json_default)\n",
    "    tmp.replace(path)\n",
    "\n",
    "def read_json(path: Path) -> Any:\n",
    "    if not path.exists():\n",
    "        raise RuntimeError(f\"Missing JSON file: {path}\")\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def sha256_file(path: Path, chunk_size: int = 1024 * 1024) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def safe_artifact_record(path: Path) -> Dict[str, Any]:\n",
    "    rec = {\"path\": str(path), \"bytes\": int(path.stat().st_size), \"sha256\": None, \"sha256_error\": None}\n",
    "    try:\n",
    "        rec[\"sha256\"] = sha256_file(path)\n",
    "    except PermissionError as e:\n",
    "        rec[\"sha256_error\"] = f\"PermissionError: {e}\"\n",
    "        print(\"[CELL 02-01] WARN: locked, cannot hash now:\", path)\n",
    "    return rec\n",
    "\n",
    "cell_end(\"CELL 02-01\", t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724b81ad",
   "metadata": {},
   "source": [
    "Start run + init report/config/manifest + meta.json append"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb0b07ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-02] Start run\n",
      "[CELL 02-02] start=2026-01-06T22:11:27\n",
      "[CELL 02-02] out_dir=C:\\anonymous-users-mooc-session-meta\\reports\\02_sessionize_mars\\20260106_221127\n",
      "[CELL 02-02] report=C:\\anonymous-users-mooc-session-meta\\reports\\02_sessionize_mars\\20260106_221127\\report.json\n",
      "[CELL 02-02] elapsed=0.02s\n",
      "[CELL 02-02] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-02] Start run + init files + meta.json append-only\n",
    "\n",
    "t0 = cell_start(\"CELL 02-02\", \"Start run\")\n",
    "\n",
    "NOTEBOOK_NAME = \"02_sessionize_mars\"\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_ID = uuid.uuid4().hex\n",
    "\n",
    "OUT_DIR = PATHS[\"REPORTS\"] / NOTEBOOK_NAME / RUN_TAG\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REPORT_PATH = OUT_DIR / \"report.json\"\n",
    "CONFIG_PATH = OUT_DIR / \"config.json\"\n",
    "MANIFEST_PATH = OUT_DIR / \"manifest.json\"\n",
    "\n",
    "# Inputs from Notebook 01 outputs (fixed)\n",
    "DUCKDB_PATH = PATHS[\"DATA_INTERIM\"] / \"mars.duckdb\"\n",
    "RAW_VIEW = \"mars_events_raw\"  # created in Notebook 01\n",
    "\n",
    "# Outputs (fixed structure)\n",
    "SESS_DIR = PATHS[\"DATA_PROCESSED\"] / \"mars\" / \"sessions\"\n",
    "SESS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CFG = {\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"inputs\": {\"duckdb_path\": str(DUCKDB_PATH), \"raw_view\": RAW_VIEW},\n",
    "    \"outputs\": {\"sessions_dir\": str(SESS_DIR), \"reports_out_dir\": str(OUT_DIR)},\n",
    "    \"sessionization\": {\n",
    "        \"gap_candidates_minutes\": [5, 10, 30, 60],\n",
    "        \"chosen_gap_minutes\": 30,  # default; we will justify using stats in this notebook\n",
    "    }\n",
    "}\n",
    "\n",
    "write_json_atomic(CONFIG_PATH, CFG)\n",
    "\n",
    "report = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"repo_root\": str(REPO_ROOT),\n",
    "    \"metrics\": {},\n",
    "    \"key_findings\": [],\n",
    "    \"sanity_samples\": {},\n",
    "    \"data_fingerprints\": {},\n",
    "    \"notes\": [],\n",
    "}\n",
    "write_json_atomic(REPORT_PATH, report)\n",
    "\n",
    "manifest = {\"run_id\": RUN_ID, \"notebook\": NOTEBOOK_NAME, \"run_tag\": RUN_TAG, \"artifacts\": []}\n",
    "write_json_atomic(MANIFEST_PATH, manifest)\n",
    "\n",
    "# meta.json append-only\n",
    "META_PATH = PATHS[\"META_REGISTRY\"]\n",
    "if not META_PATH.exists():\n",
    "    write_json_atomic(META_PATH, {\"schema_version\": 1, \"runs\": []})\n",
    "meta = read_json(META_PATH)\n",
    "meta[\"runs\"].append({\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"out_dir\": str(OUT_DIR),\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "})\n",
    "write_json_atomic(META_PATH, meta)\n",
    "\n",
    "cell_end(\"CELL 02-02\", t0, out_dir=str(OUT_DIR), report=str(REPORT_PATH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49713699",
   "metadata": {},
   "source": [
    "DuckDB open + verify raw view exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcb17879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-03] Open DuckDB + verify view (read_only=False)\n",
      "[CELL 02-03] start=2026-01-06T22:11:27\n",
      "[CELL 02-03] duckdb=C:\\anonymous-users-mooc-session-meta\\data\\interim\\mars.duckdb\n",
      "[CELL 02-03] view=mars_events_raw\n",
      "[CELL 02-03] rows: 3659\n",
      "[CELL 02-03] schema head:\n",
      "     column_name column_type null  key default extra\n",
      "         user_id      BIGINT  YES None    None  None\n",
      "         item_id      BIGINT  YES None    None  None\n",
      "watch_percentage      BIGINT  YES None    None  None\n",
      "      created_at     VARCHAR  YES None    None  None\n",
      "          rating      BIGINT  YES None    None  None\n",
      "   __source_file     VARCHAR  YES None    None  None\n",
      "[CELL 02-03] rows=3659\n",
      "[CELL 02-03] n_cols=6\n",
      "[CELL 02-03] elapsed=0.06s\n",
      "[CELL 02-03] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-03] DuckDB open + verify raw view exists (writeable for CREATE VIEW later)\n",
    "\n",
    "t0 = cell_start(\"CELL 02-03\", \"Open DuckDB + verify view (read_only=False)\", duckdb=str(DUCKDB_PATH), view=RAW_VIEW)\n",
    "\n",
    "import duckdb\n",
    "\n",
    "if not DUCKDB_PATH.exists():\n",
    "    raise RuntimeError(f\"Missing DuckDB file: {DUCKDB_PATH}. Run Notebook 01 first.\")\n",
    "\n",
    "con = duckdb.connect(str(DUCKDB_PATH), read_only=False)\n",
    "\n",
    "# Verify view exists and count rows\n",
    "n = con.execute(f\"SELECT COUNT(*) FROM {RAW_VIEW}\").fetchone()[0]\n",
    "schema_df = con.execute(f\"DESCRIBE {RAW_VIEW}\").fetchdf()\n",
    "\n",
    "print(\"[CELL 02-03] rows:\", int(n))\n",
    "print(\"[CELL 02-03] schema head:\")\n",
    "print(schema_df.head(40).to_string(index=False))\n",
    "\n",
    "cell_end(\"CELL 02-03\", t0, rows=int(n), n_cols=int(schema_df.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20adcc06",
   "metadata": {},
   "source": [
    "Auto-detect user/item/timestamp/rating columns (no assumptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7178763a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-04] Detect user/item/timestamp/rating columns\n",
      "[CELL 02-04] start=2026-01-06T22:11:27\n",
      "[CELL 02-04] guessed: {'user': 'user_id', 'item': 'item_id', 'rating': 'rating', 'ts': 'created_at'}\n",
      "[CELL 02-04] USER_COL: user_id\n",
      "[CELL 02-04] ITEM_COL: item_id\n",
      "[CELL 02-04] TS_COL: created_at\n",
      "[CELL 02-04] RATING_COL: rating\n",
      "[CELL 02-04] elapsed=0.00s\n",
      "[CELL 02-04] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-04] Auto-detect key columns (user/item/timestamp/rating)\n",
    "\n",
    "t0 = cell_start(\"CELL 02-04\", \"Detect user/item/timestamp/rating columns\")\n",
    "\n",
    "cols = schema_df[\"column_name\"].tolist()\n",
    "\n",
    "def guess_col(candidates):\n",
    "    for pat in candidates:\n",
    "        for c in cols:\n",
    "            if pat in c.lower():\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "guess = {\n",
    "    \"user\": guess_col([\"user\", \"learner\", \"student\", \"uid\"]),\n",
    "    \"item\": guess_col([\"item\", \"course\", \"resource\", \"content\", \"cid\", \"iid\"]),\n",
    "    \"rating\": guess_col([\"rating\", \"rate\", \"score\", \"stars\"]),\n",
    "    \"ts\": guess_col([\"timestamp\", \"time\", \"date\", \"created\", \"ts\"]),\n",
    "}\n",
    "\n",
    "print(\"[CELL 02-04] guessed:\", guess)\n",
    "\n",
    "missing = [k for k in [\"user\", \"item\", \"ts\"] if guess[k] is None]\n",
    "if missing:\n",
    "    raise RuntimeError(f\"Cannot sessionize: missing required columns {missing}. Columns={cols}\")\n",
    "\n",
    "USER_COL = guess[\"user\"]\n",
    "ITEM_COL = guess[\"item\"]\n",
    "TS_COL = guess[\"ts\"]\n",
    "RATING_COL = guess[\"rating\"]  # optional\n",
    "\n",
    "print(\"[CELL 02-04] USER_COL:\", USER_COL)\n",
    "print(\"[CELL 02-04] ITEM_COL:\", ITEM_COL)\n",
    "print(\"[CELL 02-04] TS_COL:\", TS_COL)\n",
    "print(\"[CELL 02-04] RATING_COL:\", RATING_COL)\n",
    "\n",
    "cell_end(\"CELL 02-04\", t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626da467",
   "metadata": {},
   "source": [
    "Normalize timestamps into a reliable ts (TIMESTAMP) + validate parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c5c4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-05] Timestamp normalization + parse validation\n",
      "[CELL 02-05] start=2026-01-06T22:11:27\n",
      "[CELL 02-05] parse_stats: {'n': 3659, 'n_ts_null': 0, 'n_user_null': 0, 'n_item_null': 0}\n",
      "[CELL 02-05] ts_minmax: {'min_ts': Timestamp('2018-09-28 14:38:15+0800', tz='Asia/Singapore'), 'max_ts': Timestamp('2021-09-20 16:26:06+0800', tz='Asia/Singapore')}\n",
      "[CELL 02-05] min_ts=2018-09-28 14:38:15+08:00\n",
      "[CELL 02-05] max_ts=2021-09-20 16:26:06+08:00\n",
      "[CELL 02-05] elapsed=0.11s\n",
      "[CELL 02-05] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-05] Normalize timestamps -> ts (TIMESTAMP) + validate parse\n",
    "\n",
    "t0 = cell_start(\"CELL 02-05\", \"Timestamp normalization + parse validation\")\n",
    "\n",
    "# DuckDB normalization strategy (tries multiple paths):\n",
    "# 1) TRY_CAST to TIMESTAMP\n",
    "# 2) If string digits -> TRY_CAST BIGINT -> to_timestamp (sec or ms)\n",
    "# 3) If numeric -> treat as sec or ms\n",
    "\n",
    "norm_view = \"mars_events_norm\"\n",
    "\n",
    "con.close()\n",
    "con = duckdb.connect(str(DUCKDB_PATH), read_only=False)\n",
    "con.execute(f\"DROP VIEW IF EXISTS {norm_view};\")\n",
    "\n",
    "ts_expr = f\"\"\"\n",
    "CASE\n",
    "  -- already timestamp-ish\n",
    "  WHEN TRY_CAST({TS_COL} AS TIMESTAMP) IS NOT NULL THEN TRY_CAST({TS_COL} AS TIMESTAMP)\n",
    "\n",
    "  -- string digits -> epoch sec/ms\n",
    "  WHEN TRY_CAST({TS_COL} AS BIGINT) IS NOT NULL THEN\n",
    "    CASE\n",
    "      WHEN TRY_CAST({TS_COL} AS BIGINT) > 1000000000000 THEN to_timestamp(TRY_CAST({TS_COL} AS BIGINT) / 1000)\n",
    "      ELSE to_timestamp(TRY_CAST({TS_COL} AS BIGINT))\n",
    "    END\n",
    "\n",
    "  -- fallback: NULL\n",
    "  ELSE NULL\n",
    "END\n",
    "\"\"\"\n",
    "\n",
    "rating_select = f\", {RATING_COL} AS rating\" if RATING_COL is not None else \"\"\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW {norm_view} AS\n",
    "SELECT\n",
    "  {USER_COL} AS user_id,\n",
    "  {ITEM_COL} AS item_id\n",
    "  {rating_select},\n",
    "  {TS_COL} AS ts_raw,\n",
    "  {ts_expr} AS ts\n",
    "FROM {RAW_VIEW}\n",
    "\"\"\")\n",
    "\n",
    "parse_stats = con.execute(f\"\"\"\n",
    "SELECT\n",
    "  COUNT(*) AS n,\n",
    "  SUM(CASE WHEN ts IS NULL THEN 1 ELSE 0 END) AS n_ts_null,\n",
    "  SUM(CASE WHEN user_id IS NULL THEN 1 ELSE 0 END) AS n_user_null,\n",
    "  SUM(CASE WHEN item_id IS NULL THEN 1 ELSE 0 END) AS n_item_null\n",
    "FROM {norm_view}\n",
    "\"\"\").fetchdf().iloc[0].to_dict()\n",
    "\n",
    "print(\"[CELL 02-05] parse_stats:\", {k:int(v) for k,v in parse_stats.items()})\n",
    "\n",
    "if int(parse_stats[\"n_user_null\"]) > 0 or int(parse_stats[\"n_item_null\"]) > 0:\n",
    "    raise RuntimeError(\"Found NULL user_id or item_id. Cannot proceed safely.\")\n",
    "\n",
    "# We require timestamp to sessionize; if failures exist, show examples and stop.\n",
    "n_ts_null = int(parse_stats[\"n_ts_null\"])\n",
    "if n_ts_null > 0:\n",
    "    bad = con.execute(f\"\"\"\n",
    "    SELECT user_id, item_id, ts_raw\n",
    "    FROM {norm_view}\n",
    "    WHERE ts IS NULL\n",
    "    LIMIT 20\n",
    "    \"\"\").fetchdf()\n",
    "    print(\"[CELL 02-05] ts_parse_failed_examples (first 20):\")\n",
    "    print(bad.to_string(index=False))\n",
    "    raise RuntimeError(f\"Timestamp parse failed for {n_ts_null} rows. Fix TS parsing before sessionization.\")\n",
    "\n",
    "minmax = con.execute(f\"SELECT MIN(ts) AS min_ts, MAX(ts) AS max_ts FROM {norm_view}\").fetchdf().iloc[0].to_dict()\n",
    "print(\"[CELL 02-05] ts_minmax:\", minmax)\n",
    "\n",
    "cell_end(\"CELL 02-05\", t0, min_ts=str(minmax[\"min_ts\"]), max_ts=str(minmax[\"max_ts\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2dc8f5",
   "metadata": {},
   "source": [
    "Gap sensitivity (5/10/30/60m): sessions + mean length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c4fdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-06] Gap sensitivity analysis (5/10/30/60m)\n",
      "[CELL 02-06] start=2026-01-06T22:11:27\n",
      "[CELL 02-06] gap_min 5 -> n_sessions=1836.0, avg=1.9929, p50=1.0, p90=4.0\n",
      "[CELL 02-06] gap_min 10 -> n_sessions=1523.0, avg=2.4025, p50=1.0, p90=5.0\n",
      "[CELL 02-06] gap_min 30 -> n_sessions=1322.0, avg=2.7678, p50=1.0, p90=6.0\n",
      "[CELL 02-06] gap_min 60 -> n_sessions=1275.0, avg=2.8698, p50=1.0, p90=6.0\n",
      "\n",
      "[CELL 02-06] sensitivity table (correct n_events):\n",
      " gap_min  n_events  n_users  n_sessions  avg_events_per_session  p50_events_per_session  p90_events_per_session  p99_events_per_session\n",
      "     5.0    3659.0    822.0      1836.0                1.992919                     1.0                     4.0                    13.0\n",
      "    10.0    3659.0    822.0      1523.0                2.402495                     1.0                     5.0                    18.0\n",
      "    30.0    3659.0    822.0      1322.0                2.767776                     1.0                     6.0                    26.0\n",
      "    60.0    3659.0    822.0      1275.0                2.869804                     1.0                     6.0                    27.0\n",
      "\n",
      "[CELL 02-06] deltas:\n",
      " gap_min  n_sessions  delta_sessions_vs_prev  rel_drop_vs_prev\n",
      "     5.0      1836.0                     NaN               NaN\n",
      "    10.0      1523.0                  -313.0          0.170479\n",
      "    30.0      1322.0                  -201.0          0.131976\n",
      "    60.0      1275.0                   -47.0          0.035552\n",
      "\n",
      "[CELL 02-06] recommended_gap_minutes=30 (stable region beyond 30m)\n",
      "[CELL 02-06] recommended_gap_minutes=30\n",
      "[CELL 02-06] elapsed=0.09s\n",
      "[CELL 02-06] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-06] Gap sensitivity analysis (correct n_events + session stats)\n",
    "\n",
    "t0 = cell_start(\"CELL 02-06\", \"Gap sensitivity analysis (5/10/30/60m)\")\n",
    "\n",
    "\n",
    "\n",
    "gap_minutes_list = CFG[\"sessionization\"][\"gap_candidates_minutes\"]\n",
    "rows = []\n",
    "\n",
    "for gm in gap_minutes_list:\n",
    "    gap_sec = int(gm * 60)\n",
    "\n",
    "    q = f\"\"\"\n",
    "    WITH ordered AS (\n",
    "      SELECT\n",
    "        user_id, item_id, ts,\n",
    "        LAG(ts) OVER (PARTITION BY user_id ORDER BY ts, item_id) AS prev_ts\n",
    "      FROM {norm_view}\n",
    "    ),\n",
    "    flags AS (\n",
    "      SELECT\n",
    "        user_id, item_id, ts,\n",
    "        CASE\n",
    "          WHEN prev_ts IS NULL THEN 1\n",
    "          WHEN EXTRACT(EPOCH FROM (ts - prev_ts)) > {gap_sec} THEN 1\n",
    "          ELSE 0\n",
    "        END AS new_sess\n",
    "      FROM ordered\n",
    "    ),\n",
    "    sess AS (\n",
    "      SELECT\n",
    "        user_id,\n",
    "        item_id,\n",
    "        ts,\n",
    "        SUM(new_sess) OVER (PARTITION BY user_id ORDER BY ts, item_id ROWS UNBOUNDED PRECEDING) AS sess_num\n",
    "      FROM flags\n",
    "    ),\n",
    "    sess_sizes AS (\n",
    "      SELECT user_id, sess_num, COUNT(*) AS cnt\n",
    "      FROM sess\n",
    "      GROUP BY 1,2\n",
    "    )\n",
    "    SELECT\n",
    "      {gm} AS gap_min,\n",
    "      (SELECT COUNT(*) FROM sess) AS n_events,\n",
    "      (SELECT COUNT(DISTINCT user_id) FROM sess) AS n_users,\n",
    "      (SELECT COUNT(*) FROM sess_sizes) AS n_sessions,\n",
    "      AVG(cnt) AS avg_events_per_session,\n",
    "      approx_quantile(cnt, 0.50) AS p50_events_per_session,\n",
    "      approx_quantile(cnt, 0.90) AS p90_events_per_session,\n",
    "      approx_quantile(cnt, 0.99) AS p99_events_per_session\n",
    "    FROM sess_sizes\n",
    "    \"\"\"\n",
    "    out = con.execute(q).fetchdf().iloc[0].to_dict()\n",
    "    rows.append(out)\n",
    "\n",
    "    print(f\"[CELL 02-06] gap_min {gm} -> \"\n",
    "          f\"n_sessions={out['n_sessions']}, avg={out['avg_events_per_session']:.4f}, \"\n",
    "          f\"p50={out['p50_events_per_session']}, p90={out['p90_events_per_session']}\")\n",
    "\n",
    "sens = pd.DataFrame(rows).sort_values(\"gap_min\").reset_index(drop=True)\n",
    "\n",
    "# Sanity: n_events should be constant across gaps\n",
    "if sens[\"n_events\"].nunique() != 1:\n",
    "    raise RuntimeError(f\"n_events differs across gaps (unexpected). Values={sens['n_events'].tolist()}\")\n",
    "\n",
    "print(\"\\n[CELL 02-06] sensitivity table (correct n_events):\")\n",
    "print(sens.to_string(index=False))\n",
    "\n",
    "# Decision rule (elbow/plateau heuristic)\n",
    "# We choose the smallest gap where further increases yield small session-count reduction.\n",
    "sens2 = sens.copy()\n",
    "sens2[\"delta_sessions_vs_prev\"] = sens2[\"n_sessions\"].diff()\n",
    "sens2[\"rel_drop_vs_prev\"] = (sens2[\"n_sessions\"].diff() / sens2[\"n_sessions\"].shift(1)).abs()\n",
    "print(\"\\n[CELL 02-06] deltas:\")\n",
    "print(sens2[[\"gap_min\", \"n_sessions\", \"delta_sessions_vs_prev\", \"rel_drop_vs_prev\"]].to_string(index=False))\n",
    "\n",
    "# Default decision: 30m (config will be updated later if you decide otherwise)\n",
    "GAP_RECOMMENDED = 30\n",
    "print(f\"\\n[CELL 02-06] recommended_gap_minutes={GAP_RECOMMENDED} (stable region beyond 30m)\")\n",
    "\n",
    "cell_end(\"CELL 02-06\", t0, recommended_gap_minutes=GAP_RECOMMENDED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ef7280",
   "metadata": {},
   "source": [
    "Report cell: write Gap Sensitivity analysis into report.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78094769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-06A] Write Gap sensitivity analysis section to report.json\n",
      "[CELL 02-06A] start=2026-01-06T22:11:28\n",
      "[CELL 02-06A] updated_report: C:\\anonymous-users-mooc-session-meta\\reports\\02_sessionize_mars\\20260106_221127\\report.json\n",
      "[CELL 02-06A] elapsed=0.01s\n",
      "[CELL 02-06A] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-06A] Report: Gap sensitivity analysis (write rationale + table)\n",
    "\n",
    "t0 = cell_start(\"CELL 02-06A\", \"Write Gap sensitivity analysis section to report.json\")\n",
    "\n",
    "report = read_json(REPORT_PATH)\n",
    "\n",
    "# Convert to plain python types for JSON\n",
    "sens_records = sens.copy()\n",
    "for c in sens_records.columns:\n",
    "    # ensure JSON-serializable\n",
    "    if sens_records[c].dtype.kind in [\"i\", \"u\"]:\n",
    "        sens_records[c] = sens_records[c].astype(int)\n",
    "    elif sens_records[c].dtype.kind == \"f\":\n",
    "        sens_records[c] = sens_records[c].astype(float)\n",
    "\n",
    "gap_section = {\n",
    "    \"what_we_tested\": \"Inactivity-gap sessionization sensitivity on MARS (user-level) using candidate gaps in minutes.\",\n",
    "    \"candidates_minutes\": CFG[\"sessionization\"][\"gap_candidates_minutes\"],\n",
    "    \"table\": sens_records.to_dict(orient=\"records\"),\n",
    "    \"interpretation\": (\n",
    "        \"We examine how the number of inferred sessions and session-length statistics change with the gap threshold. \"\n",
    "        \"A very small gap fragments behavior into many micro-sessions; a very large gap risks merging separate intents. \"\n",
    "        \"We choose a gap in the stable/plateau region where increasing the gap further yields only small reductions in \"\n",
    "        \"session count and similar session-length quantiles.\"\n",
    "    ),\n",
    "    \"decision\": {\n",
    "        \"recommended_gap_minutes\": 30,\n",
    "        \"reasoning\": (\n",
    "            \"The session count drops substantially from 5→10 minutes, and still decreases from 10→30, \"\n",
    "            \"but changes only slightly from 30→60 minutes (near-plateau). \"\n",
    "            \"Therefore 30 minutes is a defensible default that avoids excessive fragmentation (5/10m) \"\n",
    "            \"and avoids unnecessary over-merging (60m).\"\n",
    "        ),\n",
    "        \"reporting_commitment\": \"We will use 30m as primary and report sensitivity at 10m and 60m.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "report[\"sanity_samples\"][\"mars_gap_sensitivity\"] = gap_section\n",
    "report[\"key_findings\"].append(\"Completed gap sensitivity analysis; recommend 30-minute inactivity threshold for MARS sessionization (with sensitivity reporting).\")\n",
    "\n",
    "write_json_atomic(REPORT_PATH, report)\n",
    "print(\"[CELL 02-06A] updated_report:\", REPORT_PATH)\n",
    "\n",
    "cell_end(\"CELL 02-06A\", t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603d65cc",
   "metadata": {},
   "source": [
    "Choose gap (default 30m) and sessionize events + sessions tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b106c666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-07] Sessionize using recommended gap (lock + persist)\n",
      "[CELL 02-07] start=2026-01-06T22:14:00\n",
      "[CELL 02-07] Updated config.json chosen_gap_minutes: 30\n",
      "[CELL 02-07] wrote: C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\sessions\\events_gap30m.parquet\n",
      "[CELL 02-07] wrote: C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\sessions\\sessions_gap30m.parquet\n",
      "[CELL 02-07] n_events: 3659\n",
      "[CELL 02-07] n_sessions: 1322\n",
      "[CELL 02-07] n_users: 822\n",
      "[CELL 02-07] gap_minutes=30\n",
      "[CELL 02-07] n_events=3659\n",
      "[CELL 02-07] n_sessions=1322\n",
      "[CELL 02-07] n_users=822\n",
      "[CELL 02-07] elapsed=0.15s\n",
      "[CELL 02-07] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-07] Sessionize with recommended gap (lock + persist) + build event/session views (UPDATED)\n",
    "\n",
    "t0 = cell_start(\"CELL 02-07\", \"Sessionize using recommended gap (lock + persist)\")\n",
    "\n",
    "# Lock the gap decision (from sensitivity analysis)\n",
    "GAP_MIN = int(GAP_RECOMMENDED)  # set in CELL 02-06\n",
    "GAP_SEC = int(GAP_MIN * 60)\n",
    "\n",
    "# Persist choice into CFG + config.json (reproducibility)\n",
    "CFG[\"sessionization\"][\"chosen_gap_minutes\"] = GAP_MIN\n",
    "write_json_atomic(Path(CONFIG_PATH), CFG)\n",
    "print(\"[CELL 02-07] Updated config.json chosen_gap_minutes:\", GAP_MIN)\n",
    "\n",
    "# Output paths (deterministic)\n",
    "events_out = SESS_DIR / f\"events_gap{GAP_MIN}m.parquet\"\n",
    "sessions_out = SESS_DIR / f\"sessions_gap{GAP_MIN}m.parquet\"\n",
    "\n",
    "# Names for internal views (optional; for debugging)\n",
    "events_view = f\"mars_events_sessionized_gap{GAP_MIN}m\"\n",
    "sessions_view = f\"mars_sessions_gap{GAP_MIN}m\"\n",
    "\n",
    "# Drop old views if exist\n",
    "con.execute(f\"DROP VIEW IF EXISTS {events_view};\")\n",
    "con.execute(f\"DROP VIEW IF EXISTS {sessions_view};\")\n",
    "\n",
    "# Build event-level sessionization view\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW {events_view} AS\n",
    "WITH ordered AS (\n",
    "  SELECT\n",
    "    user_id, item_id, ts\n",
    "    {\", rating\" if RATING_COL is not None else \"\"},\n",
    "    ts_raw,\n",
    "    LAG(ts) OVER (PARTITION BY user_id ORDER BY ts, item_id) AS prev_ts\n",
    "  FROM {norm_view}\n",
    "),\n",
    "flags AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    CASE\n",
    "      WHEN prev_ts IS NULL THEN 1\n",
    "      WHEN EXTRACT(EPOCH FROM (ts - prev_ts)) > {GAP_SEC} THEN 1\n",
    "      ELSE 0\n",
    "    END AS new_sess\n",
    "  FROM ordered\n",
    "),\n",
    "sess AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    SUM(new_sess) OVER (\n",
    "      PARTITION BY user_id ORDER BY ts, item_id ROWS UNBOUNDED PRECEDING\n",
    "    ) AS sess_num\n",
    "  FROM flags\n",
    "),\n",
    "with_pos AS (\n",
    "  SELECT\n",
    "    *,\n",
    "    ROW_NUMBER() OVER (PARTITION BY user_id, sess_num ORDER BY ts, item_id) AS pos_in_sess,\n",
    "    COUNT(*) OVER (PARTITION BY user_id, sess_num) AS sess_len\n",
    "  FROM sess\n",
    ")\n",
    "SELECT\n",
    "  user_id,\n",
    "  item_id\n",
    "  {\", rating\" if RATING_COL is not None else \"\"},\n",
    "  ts,\n",
    "  EXTRACT(EPOCH FROM ts)::BIGINT AS ts_epoch,\n",
    "  sess_num,\n",
    "  (CAST(user_id AS VARCHAR) || '_' || LPAD(CAST(sess_num AS VARCHAR), 6, '0')) AS session_id,\n",
    "  pos_in_sess,\n",
    "  sess_len,\n",
    "  ts_raw\n",
    "FROM with_pos\n",
    "\"\"\")\n",
    "\n",
    "# Build session-level view\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW {sessions_view} AS\n",
    "SELECT\n",
    "  session_id,\n",
    "  user_id,\n",
    "  sess_num,\n",
    "  MIN(ts) AS session_start_ts,\n",
    "  MAX(ts) AS session_end_ts,\n",
    "  COUNT(*) AS n_events,\n",
    "  (EXTRACT(EPOCH FROM (MAX(ts) - MIN(ts))))::BIGINT AS duration_sec,\n",
    "  COUNT(DISTINCT item_id) AS n_unique_items\n",
    "FROM {events_view}\n",
    "GROUP BY 1,2,3\n",
    "\"\"\")\n",
    "\n",
    "# Materialize to Parquet (real artifacts)\n",
    "SESS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "events_out_sql = str(events_out).replace(\"'\", \"''\")\n",
    "sessions_out_sql = str(sessions_out).replace(\"'\", \"''\")\n",
    "\n",
    "con.execute(f\"COPY (SELECT * FROM {events_view}) TO '{events_out_sql}' (FORMAT PARQUET);\")\n",
    "con.execute(f\"COPY (SELECT * FROM {sessions_view}) TO '{sessions_out_sql}' (FORMAT PARQUET);\")\n",
    "\n",
    "print(\"[CELL 02-07] wrote:\", events_out)\n",
    "print(\"[CELL 02-07] wrote:\", sessions_out)\n",
    "\n",
    "# Register stable views pointing to the Parquet outputs (repo-wide downstream dependency)\n",
    "con.execute(\"DROP VIEW IF EXISTS mars_events_sessionized;\")\n",
    "con.execute(\"DROP VIEW IF EXISTS mars_sessions;\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW mars_events_sessionized AS\n",
    "SELECT * FROM read_parquet('{events_out_sql}')\n",
    "\"\"\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW mars_sessions AS\n",
    "SELECT * FROM read_parquet('{sessions_out_sql}')\n",
    "\"\"\")\n",
    "\n",
    "# Quick checks\n",
    "n_events = int(con.execute(\"SELECT COUNT(*) FROM mars_events_sessionized\").fetchone()[0])\n",
    "n_sessions = int(con.execute(\"SELECT COUNT(*) FROM mars_sessions\").fetchone()[0])\n",
    "n_users = int(con.execute(\"SELECT COUNT(DISTINCT user_id) FROM mars_events_sessionized\").fetchone()[0])\n",
    "\n",
    "print(\"[CELL 02-07] n_events:\", n_events)\n",
    "print(\"[CELL 02-07] n_sessions:\", n_sessions)\n",
    "print(\"[CELL 02-07] n_users:\", n_users)\n",
    "\n",
    "cell_end(\"CELL 02-07\", t0, gap_minutes=GAP_MIN, n_events=n_events, n_sessions=n_sessions, n_users=n_users)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546486af",
   "metadata": {},
   "source": [
    "Save processed Parquet outputs (events + sessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9faaa959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-08] Write processed parquet (events + sessions)\n",
      "[CELL 02-08] start=2026-01-06T22:14:04\n",
      "[CELL 02-08] wrote: C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\sessions\\events_gap30m.parquet\n",
      "[CELL 02-08] wrote: C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\sessions\\sessions_gap30m.parquet\n",
      "[CELL 02-08] events_parquet=C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\sessions\\events_gap30m.parquet\n",
      "[CELL 02-08] sessions_parquet=C:\\anonymous-users-mooc-session-meta\\data\\processed\\mars\\sessions\\sessions_gap30m.parquet\n",
      "[CELL 02-08] elapsed=0.09s\n",
      "[CELL 02-08] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-08] Save processed Parquet outputs\n",
    "\n",
    "t0 = cell_start(\"CELL 02-08\", \"Write processed parquet (events + sessions)\")\n",
    "\n",
    "events_out = SESS_DIR / f\"events_gap{GAP_MIN}m.parquet\"\n",
    "sessions_out = SESS_DIR / f\"sessions_gap{GAP_MIN}m.parquet\"\n",
    "\n",
    "# Export via DuckDB COPY (fast + consistent)\n",
    "con.execute(f\"COPY (SELECT * FROM {events_view}) TO '{str(events_out)}' (FORMAT PARQUET);\")\n",
    "con.execute(f\"COPY (SELECT * FROM {sessions_view}) TO '{str(sessions_out)}' (FORMAT PARQUET);\")\n",
    "\n",
    "print(\"[CELL 02-08] wrote:\", events_out)\n",
    "print(\"[CELL 02-08] wrote:\", sessions_out)\n",
    "\n",
    "cell_end(\"CELL 02-08\", t0, events_parquet=str(events_out), sessions_parquet=str(sessions_out))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c165fe6d",
   "metadata": {},
   "source": [
    "Create DuckDB views over processed Parquet (processed → duckdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3e0a12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-09] Register processed parquet as DuckDB views\n",
      "[CELL 02-09] start=2026-01-06T22:14:07\n",
      "[CELL 02-09] registered views ok: 3659 1322\n",
      "[CELL 02-09] closed DuckDB connection (avoid Windows lock)\n",
      "[CELL 02-09] elapsed=0.11s\n",
      "[CELL 02-09] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-09] Register processed parquet as views (writeable connection, then close)\n",
    "\n",
    "t0 = cell_start(\"CELL 02-09\", \"Register processed parquet as DuckDB views\")\n",
    "\n",
    "con.close()  # close read-only\n",
    "con = duckdb.connect(str(DUCKDB_PATH), read_only=False)\n",
    "\n",
    "# Views pointing to processed parquet (no duplication)\n",
    "con.execute(f\"DROP VIEW IF EXISTS mars_events_sessionized;\")\n",
    "con.execute(f\"DROP VIEW IF EXISTS mars_sessions;\")\n",
    "\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW mars_events_sessionized AS\n",
    "SELECT * FROM read_parquet('{str(events_out).replace(\"'\", \"''\")}')\n",
    "\"\"\")\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW mars_sessions AS\n",
    "SELECT * FROM read_parquet('{str(sessions_out).replace(\"'\", \"''\")}')\n",
    "\"\"\")\n",
    "\n",
    "# quick check\n",
    "chk = con.execute(\"SELECT COUNT(*) AS n_events FROM mars_events_sessionized\").fetchone()[0]\n",
    "chk2 = con.execute(\"SELECT COUNT(*) AS n_sessions FROM mars_sessions\").fetchone()[0]\n",
    "print(\"[CELL 02-09] registered views ok:\", int(chk), int(chk2))\n",
    "\n",
    "con.close()\n",
    "print(\"[CELL 02-09] closed DuckDB connection (avoid Windows lock)\")\n",
    "\n",
    "cell_end(\"CELL 02-09\", t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4036b38",
   "metadata": {},
   "source": [
    "Plots: sensitivity + session length histogram (Matplotlib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b238bfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-10] Plots: gap sensitivity + session length distribution\n",
      "[CELL 02-10] start=2026-01-06T22:14:46\n",
      "[CELL 02-10] saved: C:\\anonymous-users-mooc-session-meta\\reports\\02_sessionize_mars\\20260106_221127\\plots\\gap_sensitivity_sessions.png\n",
      "[CELL 02-10] saved: C:\\anonymous-users-mooc-session-meta\\reports\\02_sessionize_mars\\20260106_221127\\plots\\session_length_hist_gap30m.png\n",
      "[CELL 02-10] closed DuckDB connection (plots)\n",
      "[CELL 02-10] plots_dir=C:\\anonymous-users-mooc-session-meta\\reports\\02_sessionize_mars\\20260106_221127\\plots\n",
      "[CELL 02-10] elapsed=0.35s\n",
      "[CELL 02-10] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-10] Plots (matplotlib only) + save under run artifacts (re-open DuckDB)\n",
    "\n",
    "t0 = cell_start(\"CELL 02-10\", \"Plots: gap sensitivity + session length distribution\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import duckdb\n",
    "\n",
    "PLOTS_DIR = OUT_DIR / \"plots\"\n",
    "PLOTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Plot 1: sessions vs gap\n",
    "plt.figure()\n",
    "plt.plot(sens[\"gap_min\"], sens[\"n_sessions\"], marker=\"o\")\n",
    "plt.xlabel(\"Gap (minutes)\")\n",
    "plt.ylabel(\"# sessions\")\n",
    "plt.title(\"MARS: session count vs gap threshold\")\n",
    "plt.tight_layout()\n",
    "p1 = PLOTS_DIR / \"gap_sensitivity_sessions.png\"\n",
    "plt.savefig(p1, dpi=200)\n",
    "plt.close()\n",
    "print(\"[CELL 02-10] saved:\", p1)\n",
    "\n",
    "# Plot 2: session length histogram (chosen gap) — open a fresh connection\n",
    "con_plot = duckdb.connect(str(DUCKDB_PATH), read_only=True)\n",
    "\n",
    "lens = con_plot.execute(\n",
    "    \"SELECT sess_len FROM mars_events_sessionized\"\n",
    ").fetchdf()[\"sess_len\"].astype(int)\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(lens, bins=50)\n",
    "plt.xlabel(\"Session length (#events)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(f\"MARS: session length distribution (gap={GAP_MIN}m)\")\n",
    "plt.tight_layout()\n",
    "p2 = PLOTS_DIR / f\"session_length_hist_gap{GAP_MIN}m.png\"\n",
    "plt.savefig(p2, dpi=200)\n",
    "plt.close()\n",
    "print(\"[CELL 02-10] saved:\", p2)\n",
    "\n",
    "con_plot.close()\n",
    "print(\"[CELL 02-10] closed DuckDB connection (plots)\")\n",
    "\n",
    "cell_end(\"CELL 02-10\", t0, plots_dir=str(PLOTS_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7b0512",
   "metadata": {},
   "source": [
    "Update report + manifest + close out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1482176a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 02-11] Write report + manifest\n",
      "[CELL 02-11] start=2026-01-06T22:16:47\n",
      "[CELL 02-11] closed DuckDB connection (report)\n",
      "[CELL 02-11] updated: C:\\anonymous-users-mooc-session-meta\\reports\\02_sessionize_mars\\20260106_221127\\report.json\n",
      "[CELL 02-11] updated: C:\\anonymous-users-mooc-session-meta\\reports\\02_sessionize_mars\\20260106_221127\\manifest.json\n",
      "[CELL 02-11] n_artifacts=4\n",
      "[CELL 02-11] elapsed=0.09s\n",
      "[CELL 02-11] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 02-11] Write report + manifest (self-contained; opens its own DuckDB connection)\n",
    "\n",
    "t0 = cell_start(\"CELL 02-11\", \"Write report + manifest\")\n",
    "\n",
    "import duckdb\n",
    "\n",
    "report = read_json(Path(REPORT_PATH))\n",
    "manifest = read_json(Path(MANIFEST_PATH))\n",
    "\n",
    "# Add artifacts (parquets + plots)\n",
    "manifest[\"artifacts\"].append(safe_artifact_record(events_out))\n",
    "manifest[\"artifacts\"].append(safe_artifact_record(sessions_out))\n",
    "manifest[\"artifacts\"].append(safe_artifact_record(PLOTS_DIR / \"gap_sensitivity_sessions.png\"))\n",
    "manifest[\"artifacts\"].append(safe_artifact_record(PLOTS_DIR / f\"session_length_hist_gap{GAP_MIN}m.png\"))\n",
    "\n",
    "# Key findings / sanity\n",
    "report[\"key_findings\"].append(\n",
    "    f\"Sessionized MARS with gap={GAP_MIN} minutes; wrote processed parquets and registered DuckDB views \"\n",
    "    f\"mars_events_sessionized, mars_sessions.\"\n",
    ")\n",
    "report[\"sanity_samples\"][\"gap_sensitivity_table\"] = sens.to_dict(orient=\"records\")\n",
    "report[\"sanity_samples\"][\"chosen_gap_minutes\"] = int(GAP_MIN)\n",
    "report[\"sanity_samples\"][\"outputs\"] = {\n",
    "    \"events_parquet\": str(events_out),\n",
    "    \"sessions_parquet\": str(sessions_out),\n",
    "}\n",
    "\n",
    "# Open a fresh connection just for this cell\n",
    "con_rep = duckdb.connect(str(DUCKDB_PATH), read_only=True)\n",
    "\n",
    "sample_sessions_df = con_rep.execute(\"\"\"\n",
    "SELECT *\n",
    "FROM mars_sessions\n",
    "ORDER BY n_events DESC\n",
    "LIMIT 5\n",
    "\"\"\").fetchdf()\n",
    "\n",
    "report[\"sanity_samples\"][\"top5_sessions_by_events\"] = sample_sessions_df.to_dict(orient=\"records\")\n",
    "\n",
    "con_rep.close()\n",
    "print(\"[CELL 02-11] closed DuckDB connection (report)\")\n",
    "\n",
    "write_json_atomic(Path(REPORT_PATH), report)\n",
    "write_json_atomic(Path(MANIFEST_PATH), manifest)\n",
    "\n",
    "print(\"[CELL 02-11] updated:\", REPORT_PATH)\n",
    "print(\"[CELL 02-11] updated:\", MANIFEST_PATH)\n",
    "\n",
    "cell_end(\"CELL 02-11\", t0, n_artifacts=len(manifest[\"artifacts\"]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
