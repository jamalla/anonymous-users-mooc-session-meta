{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notebook 08: Warm-Start MAML (XuetangX) - Contribution 1\n\n**Purpose:** Improve MAML by initializing from pre-trained GRU4Rec weights instead of random initialization.\n\n**Research Motivation:**\n- Vanilla MAML (28.66%) underperforms GRU4Rec baseline (33.55%)\n- Root cause: Random initialization + only K=5 pairs is insufficient to learn course patterns\n- Solution: Start from GRU4Rec's learned weights (33.55% accuracy) and adapt for personalization\n\n**Key Insight:**\n```\nWithout Warm-Start: Random init (0.06%) + K=5 adaptation = 28.66%\nWith Warm-Start:    GRU4Rec init (33.55%) + K=5 adaptation = ???%\n```\n\n**Hypothesis:** Warm-Start MAML will outperform both:\n1. Vanilla MAML (28.66%) - because better initialization\n2. GRU4Rec baseline (33.55%) - because of user-specific adaptation\n\n**Inputs:**\n- `data/processed/xuetangx/episodes/episodes_{train|val|test}_K5_Q10.parquet`\n- `models/baselines/gru_global.pth` (pre-trained GRU4Rec: 33.55% Acc@1)\n- `data/processed/xuetangx/vocab/course2id.json` (1,518 courses)\n\n**Outputs:**\n- `models/contributions/warmstart_maml_K5.pth`\n- `results/warmstart_maml_K5_Q10.json`\n- `reports/08_warmstart_maml_xuetangx/<run_tag>/report.json`\n\n**Comparison:**\n| Model | Initialization | Adaptation | Expected Acc@1 |\n|-------|---------------|------------|----------------|\n| GRU4Rec (baseline) | Trained | None | 33.55% |\n| Vanilla MAML | Random | K=5 inner loop | 28.66% |\n| **Warm-Start MAML** | **GRU4Rec weights** | K=5 inner loop | **>33.55%?** |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-00] Bootstrap: repo root + paths + logger\n\nimport os\nimport sys\nimport json\nimport time\nimport uuid\nimport copy\nimport hashlib\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Tuple, Optional\nfrom collections import OrderedDict\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nt0 = datetime.now()\nprint(f\"[CELL 08-00] start={t0.isoformat(timespec='seconds')}\")\nprint(\"[CELL 08-00] CWD:\", Path.cwd().resolve())\n\ndef find_repo_root(start: Path) -> Path:\n    start = start.resolve()\n    for p in [start, *start.parents]:\n        if (p / \"PROJECT_STATE.md\").exists():\n            return p\n    raise RuntimeError(\"Could not find repo root (no PROJECT_STATE.md)\")\n\nREPO_ROOT = find_repo_root(Path.cwd())\nprint(f\"[CELL 08-00] REPO_ROOT: {REPO_ROOT}\")\n\nsys.path.insert(0, str(REPO_ROOT / \"src\"))\n\nMETA_REGISTRY = REPO_ROOT / \"meta.json\"\nDATA_INTERIM = REPO_ROOT / \"data\" / \"interim\"\nDATA_PROCESSED = REPO_ROOT / \"data\" / \"processed\"\nMODELS = REPO_ROOT / \"models\"\nRESULTS = REPO_ROOT / \"results\"\nREPORTS = REPO_ROOT / \"reports\"\n\nPATHS = {\n    \"REPO_ROOT\": REPO_ROOT,\n    \"META_REGISTRY\": META_REGISTRY,\n    \"DATA_INTERIM\": DATA_INTERIM,\n    \"DATA_PROCESSED\": DATA_PROCESSED,\n    \"MODELS\": MODELS,\n    \"RESULTS\": RESULTS,\n    \"REPORTS\": REPORTS,\n}\n\nfor name, path in PATHS.items():\n    print(f\"[CELL 08-00] {name}={path}\")\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"[CELL 08-00] PyTorch device: {DEVICE}\")\n\ndef cell_start(cell_id: str, description: str = \"\") -> datetime:\n    t = datetime.now()\n    msg = f\"[{cell_id}] start={t.isoformat(timespec='seconds')}\"\n    if description:\n        msg += f\" | {description}\"\n    print(msg)\n    return t\n\ndef cell_end(cell_id: str, t_start: datetime, **kv) -> None:\n    elapsed = (datetime.now() - t_start).total_seconds()\n    for k, v in kv.items():\n        print(f\"[{cell_id}] {k}={v}\")\n    print(f\"[{cell_id}] done in {elapsed:.1f}s\")\n\nprint(\"[CELL 08-00] done\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-01] Configuration\n\nt0 = cell_start(\"CELL 08-01\", \"Configuration\")\n\nRUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"_\" + uuid.uuid4().hex[:8]\nprint(f\"[CELL 08-01] RUN_TAG: {RUN_TAG}\")\n\nCFG = {\n    \"notebook\": \"08_warmstart_maml_xuetangx\",\n    \"run_tag\": RUN_TAG,\n    \"dataset\": \"xuetangx\",\n    \"contribution\": \"warm_start_maml\",\n    \n    # Episode config (same as notebook 07)\n    \"episode_config\": {\n        \"K\": 5,   # support set size\n        \"Q\": 10,  # query set size\n    },\n    \n    # Model config (same as GRU4Rec baseline)\n    \"model_config\": {\n        \"embed_dim\": 64,\n        \"hidden_dim\": 64,\n        \"n_layers\": 1,\n        \"dropout\": 0.1,\n    },\n    \n    # MAML config\n    \"maml_config\": {\n        \"inner_lr\": 0.01,           # alpha: learning rate for inner loop\n        \"outer_lr\": 0.001,          # beta: learning rate for outer loop\n        \"inner_steps\": 5,           # gradient steps in inner loop\n        \"meta_batch_size\": 32,      # tasks per meta-batch\n        \"num_meta_iterations\": 3000,\n        \"use_second_order\": False,  # FOMAML\n        \"val_every\": 100,\n        \"checkpoint_every\": 500,\n    },\n    \n    # Warm-Start config (NEW)\n    \"warmstart_config\": {\n        \"pretrained_path\": \"models/baselines/gru_global.pth\",\n        \"freeze_embeddings\": False,  # Whether to freeze embedding layer\n    },\n    \n    \"seed\": 42,\n}\n\n# Set seeds\nnp.random.seed(CFG[\"seed\"])\ntorch.manual_seed(CFG[\"seed\"])\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(CFG[\"seed\"])\n\nprint(f\"[CELL 08-01] Configuration:\")\nprint(f\"  - Contribution: {CFG['contribution']}\")\nprint(f\"  - Pre-trained model: {CFG['warmstart_config']['pretrained_path']}\")\nprint(f\"  - Episode: K={CFG['episode_config']['K']}, Q={CFG['episode_config']['Q']}\")\nprint(f\"  - MAML: inner_lr={CFG['maml_config']['inner_lr']}, outer_lr={CFG['maml_config']['outer_lr']}\")\nprint(f\"  - Meta iterations: {CFG['maml_config']['num_meta_iterations']}\")\nprint(f\"  - FOMAML: {not CFG['maml_config']['use_second_order']}\")\n\ncell_end(\"CELL 08-01\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-02] Setup paths and create directories\n\nt0 = cell_start(\"CELL 08-02\", \"Setup paths\")\n\n# Input paths\nEPISODES_DIR = DATA_PROCESSED / \"xuetangx\" / \"episodes\"\nVOCAB_DIR = DATA_PROCESSED / \"xuetangx\" / \"vocab\"\nPRETRAINED_PATH = REPO_ROOT / CFG[\"warmstart_config\"][\"pretrained_path\"]\n\nK = CFG[\"episode_config\"][\"K\"]\nQ = CFG[\"episode_config\"][\"Q\"]\n\nEPISODES_TRAIN = EPISODES_DIR / f\"episodes_train_K{K}_Q{Q}.parquet\"\nEPISODES_VAL = EPISODES_DIR / f\"episodes_val_K{K}_Q{Q}.parquet\"\nEPISODES_TEST = EPISODES_DIR / f\"episodes_test_K{K}_Q{Q}.parquet\"\nCOURSE2ID_PATH = VOCAB_DIR / \"course2id.json\"\n\n# Output paths\nCONTRIB_MODELS_DIR = MODELS / \"contributions\"\nCONTRIB_MODELS_DIR.mkdir(parents=True, exist_ok=True)\n\nCHECKPOINT_DIR = CONTRIB_MODELS_DIR / \"checkpoints\"\nCHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n\nREPORT_DIR = REPORTS / \"08_warmstart_maml_xuetangx\" / RUN_TAG\nREPORT_DIR.mkdir(parents=True, exist_ok=True)\n\nOUT_MODEL = CONTRIB_MODELS_DIR / \"warmstart_maml_K5.pth\"\nOUT_RESULTS = RESULTS / \"warmstart_maml_K5_Q10.json\"\nREPORT_PATH = REPORT_DIR / \"report.json\"\n\nprint(f\"[CELL 08-02] Input episodes: {EPISODES_TRAIN}\")\nprint(f\"[CELL 08-02] Pre-trained GRU4Rec: {PRETRAINED_PATH}\")\nprint(f\"[CELL 08-02] Pre-trained exists: {PRETRAINED_PATH.exists()}\")\nprint(f\"[CELL 08-02] Output model: {OUT_MODEL}\")\nprint(f\"[CELL 08-02] Output results: {OUT_RESULTS}\")\n\ncell_end(\"CELL 08-02\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-03] Load data\n\nt0 = cell_start(\"CELL 08-03\", \"Load episodes and vocabulary\")\n\n# Load vocabulary\nwith open(COURSE2ID_PATH, \"r\") as f:\n    course2id = json.load(f)\nn_items = len(course2id)\nprint(f\"[CELL 08-03] Vocabulary size: {n_items} courses\")\n\n# Load episodes\nepisodes_train = pd.read_parquet(EPISODES_TRAIN)\nepisodes_val = pd.read_parquet(EPISODES_VAL)\nepisodes_test = pd.read_parquet(EPISODES_TEST)\n\nprint(f\"[CELL 08-03] Train episodes: {len(episodes_train):,}\")\nprint(f\"[CELL 08-03] Val episodes:   {len(episodes_val):,}\")\nprint(f\"[CELL 08-03] Test episodes:  {len(episodes_test):,}\")\n\ncell_end(\"CELL 08-03\", t0, n_items=n_items, n_train=len(episodes_train), n_val=len(episodes_val), n_test=len(episodes_test))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-04] Define GRU4Rec model (same architecture as baseline)\n\nt0 = cell_start(\"CELL 08-04\", \"Define GRU4Rec model\")\n\nclass GRURecommender(nn.Module):\n    \"\"\"GRU4Rec model for sequential recommendation.\n    \n    Same architecture as notebook 06 baseline - required for loading pre-trained weights.\n    \"\"\"\n    def __init__(self, n_items: int, embed_dim: int, hidden_dim: int, n_layers: int = 1, dropout: float = 0.1):\n        super().__init__()\n        self.n_items = n_items\n        self.embed_dim = embed_dim\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        \n        self.embedding = nn.Embedding(n_items, embed_dim, padding_idx=0)\n        self.gru = nn.GRU(\n            input_size=embed_dim,\n            hidden_size=hidden_dim,\n            num_layers=n_layers,\n            batch_first=True,\n            dropout=dropout if n_layers > 1 else 0.0,\n        )\n        self.dropout = nn.Dropout(dropout)\n        self.output = nn.Linear(hidden_dim, n_items)\n        \n    def forward(self, x: torch.Tensor, lengths: torch.Tensor = None) -> torch.Tensor:\n        \"\"\"Forward pass.\n        \n        Args:\n            x: Input sequences [batch, seq_len]\n            lengths: Sequence lengths [batch] (optional)\n            \n        Returns:\n            logits: Output logits [batch, n_items]\n        \"\"\"\n        # Embed input\n        embedded = self.embedding(x)  # [batch, seq_len, embed_dim]\n        \n        # Pack if lengths provided\n        if lengths is not None:\n            packed = nn.utils.rnn.pack_padded_sequence(\n                embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n            )\n            output, hidden = self.gru(packed)\n        else:\n            output, hidden = self.gru(embedded)\n        \n        # Use last hidden state\n        last_hidden = hidden[-1]  # [batch, hidden_dim]\n        \n        # Output projection\n        out = self.dropout(last_hidden)\n        logits = self.output(out)  # [batch, n_items]\n        \n        return logits\n\nprint(f\"[CELL 08-04] GRURecommender defined\")\nprint(f\"  - Architecture: Embedding({n_items}, {CFG['model_config']['embed_dim']}) -> GRU({CFG['model_config']['hidden_dim']}) -> Linear({n_items})\")\n\ncell_end(\"CELL 08-04\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-05] Initialize model with Warm-Start (KEY CONTRIBUTION)\n\nt0 = cell_start(\"CELL 08-05\", \"Initialize model with Warm-Start from GRU4Rec\")\n\n# Create model with same architecture\nmeta_model = GRURecommender(\n    n_items=n_items,\n    embed_dim=CFG[\"model_config\"][\"embed_dim\"],\n    hidden_dim=CFG[\"model_config\"][\"hidden_dim\"],\n    n_layers=CFG[\"model_config\"][\"n_layers\"],\n    dropout=CFG[\"model_config\"][\"dropout\"],\n).to(DEVICE)\n\n# ============================================================\n# KEY CONTRIBUTION: Load pre-trained GRU4Rec weights\n# ============================================================\nprint(f\"[CELL 08-05] Loading pre-trained GRU4Rec from: {PRETRAINED_PATH}\")\n\npretrained_state = torch.load(PRETRAINED_PATH, map_location=DEVICE)\nmeta_model.load_state_dict(pretrained_state)\n\nprint(f\"[CELL 08-05] Successfully loaded pre-trained weights!\")\nprint(f\"[CELL 08-05] Meta-model now starts from GRU4Rec baseline (33.55% Acc@1)\")\n# ============================================================\n\n# Model stats\nn_params = sum(p.numel() for p in meta_model.parameters())\nn_trainable = sum(p.numel() for p in meta_model.parameters() if p.requires_grad)\n\nprint(f\"[CELL 08-05] Model parameters: {n_params:,}\")\nprint(f\"[CELL 08-05] Trainable parameters: {n_trainable:,}\")\n\n# Optionally freeze embeddings\nif CFG[\"warmstart_config\"][\"freeze_embeddings\"]:\n    for param in meta_model.embedding.parameters():\n        param.requires_grad = False\n    n_trainable = sum(p.numel() for p in meta_model.parameters() if p.requires_grad)\n    print(f\"[CELL 08-05] Embeddings frozen. Trainable: {n_trainable:,}\")\n\n# Setup optimizer (outer loop)\nmeta_optimizer = torch.optim.Adam(meta_model.parameters(), lr=CFG[\"maml_config\"][\"outer_lr\"])\n\nprint(f\"[CELL 08-05] Optimizer: Adam (outer_lr={CFG['maml_config']['outer_lr']})\")\n\ncell_end(\"CELL 08-05\", t0, n_params=n_params)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-06] Verify Warm-Start: Test initial accuracy\n\nt0 = cell_start(\"CELL 08-06\", \"Verify Warm-Start initialization accuracy\")\n\ndef prepare_batch(episodes_df: pd.DataFrame, idx: int) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n    \"\"\"Prepare a single episode as tensors.\"\"\"\n    row = episodes_df.iloc[idx]\n    \n    support_x = torch.tensor(row[\"support_prefixes\"], dtype=torch.long)\n    support_y = torch.tensor(row[\"support_labels\"], dtype=torch.long)\n    query_x = torch.tensor(row[\"query_prefixes\"], dtype=torch.long)\n    query_y = torch.tensor(row[\"query_labels\"], dtype=torch.long)\n    \n    return support_x, support_y, query_x, query_y\n\ndef compute_accuracy(logits: torch.Tensor, labels: torch.Tensor) -> float:\n    \"\"\"Compute accuracy@1.\"\"\"\n    preds = logits.argmax(dim=-1)\n    return (preds == labels).float().mean().item()\n\n# Test on a sample of test episodes WITHOUT adaptation (zero-shot)\nmeta_model.eval()\nn_test_sample = min(100, len(episodes_test))\n\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for i in range(n_test_sample):\n        _, _, query_x, query_y = prepare_batch(episodes_test, i)\n        \n        # Pad sequences\n        max_len = max(len(seq) for seq in query_x)\n        padded_x = torch.zeros(len(query_x), max_len, dtype=torch.long)\n        lengths = torch.zeros(len(query_x), dtype=torch.long)\n        \n        for j, seq in enumerate(query_x):\n            padded_x[j, :len(seq)] = torch.tensor(seq)\n            lengths[j] = len(seq)\n        \n        padded_x = padded_x.to(DEVICE)\n        query_y = query_y.to(DEVICE)\n        lengths = lengths.to(DEVICE)\n        \n        logits = meta_model(padded_x, lengths)\n        preds = logits.argmax(dim=-1)\n        \n        correct += (preds == query_y).sum().item()\n        total += len(query_y)\n\nwarmstart_zeroshot_acc = correct / total\n\nprint(f\"[CELL 08-06] Warm-Start Zero-Shot Accuracy: {warmstart_zeroshot_acc:.4f} ({warmstart_zeroshot_acc*100:.2f}%)\")\nprint(f\"[CELL 08-06] Expected (GRU4Rec baseline): ~33.55%\")\nprint(f\"[CELL 08-06] Vanilla MAML zero-shot was: 25.62%\")\nprint(f\"[CELL 08-06] Improvement from Warm-Start: +{(warmstart_zeroshot_acc - 0.2562)*100:.2f} percentage points\")\n\ncell_end(\"CELL 08-06\", t0, warmstart_zeroshot_acc=warmstart_zeroshot_acc)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-07] Helper functions for MAML training\n\nt0 = cell_start(\"CELL 08-07\", \"Define MAML helper functions\")\n\ndef pad_sequences(sequences: List[List[int]], pad_value: int = 0) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Pad variable-length sequences.\"\"\"\n    lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long)\n    max_len = max(lengths).item()\n    \n    padded = torch.full((len(sequences), max_len), pad_value, dtype=torch.long)\n    for i, seq in enumerate(sequences):\n        padded[i, :len(seq)] = torch.tensor(seq, dtype=torch.long)\n    \n    return padded, lengths\n\ndef functional_forward(model: nn.Module, x: torch.Tensor, lengths: torch.Tensor, \n                       params: Dict[str, torch.Tensor]) -> torch.Tensor:\n    \"\"\"Forward pass with external parameters (for MAML inner loop).\"\"\"\n    # Embedding\n    embedded = F.embedding(x, params[\"embedding.weight\"], padding_idx=0)\n    \n    # GRU - need to handle packed sequences\n    if lengths is not None:\n        packed = nn.utils.rnn.pack_padded_sequence(\n            embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n        )\n        \n        # Manual GRU forward with params\n        weight_ih = params[\"gru.weight_ih_l0\"]\n        weight_hh = params[\"gru.weight_hh_l0\"]\n        bias_ih = params[\"gru.bias_ih_l0\"]\n        bias_hh = params[\"gru.bias_hh_l0\"]\n        \n        # Unpack and process\n        unpacked, _ = nn.utils.rnn.pad_packed_sequence(packed, batch_first=True)\n        \n        batch_size = x.size(0)\n        hidden_dim = weight_hh.size(1)\n        h = torch.zeros(batch_size, hidden_dim, device=x.device)\n        \n        for t in range(unpacked.size(1)):\n            inp = unpacked[:, t, :]\n            gates = inp @ weight_ih.t() + bias_ih + h @ weight_hh.t() + bias_hh\n            \n            r, z, n = gates.chunk(3, dim=1)\n            r = torch.sigmoid(r)\n            z = torch.sigmoid(z)\n            n = torch.tanh(n)\n            \n            h = (1 - z) * n + z * h\n        \n        # Mask for actual lengths\n        last_hidden = h\n    else:\n        # Simple case without packing\n        batch_size = x.size(0)\n        hidden_dim = params[\"gru.weight_hh_l0\"].size(1)\n        h = torch.zeros(batch_size, hidden_dim, device=x.device)\n        \n        for t in range(embedded.size(1)):\n            inp = embedded[:, t, :]\n            weight_ih = params[\"gru.weight_ih_l0\"]\n            weight_hh = params[\"gru.weight_hh_l0\"]\n            bias_ih = params[\"gru.bias_ih_l0\"]\n            bias_hh = params[\"gru.bias_hh_l0\"]\n            \n            gates = inp @ weight_ih.t() + bias_ih + h @ weight_hh.t() + bias_hh\n            \n            r, z, n = gates.chunk(3, dim=1)\n            r = torch.sigmoid(r)\n            z = torch.sigmoid(z)\n            n = torch.tanh(n)\n            \n            h = (1 - z) * n + z * h\n        \n        last_hidden = h\n    \n    # Output projection\n    logits = last_hidden @ params[\"output.weight\"].t() + params[\"output.bias\"]\n    \n    return logits\n\nprint(f\"[CELL 08-07] Helper functions defined\")\nprint(f\"  - pad_sequences: Pad variable-length sequences\")\nprint(f\"  - functional_forward: Forward pass with external params (for inner loop)\")\n\ncell_end(\"CELL 08-07\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-08] MAML Training Loop with Warm-Start\n\nt0 = cell_start(\"CELL 08-08\", \"MAML Training with Warm-Start initialization\")\n\n# Training config\ninner_lr = CFG[\"maml_config\"][\"inner_lr\"]\ninner_steps = CFG[\"maml_config\"][\"inner_steps\"]\nmeta_batch_size = CFG[\"maml_config\"][\"meta_batch_size\"]\nnum_iterations = CFG[\"maml_config\"][\"num_meta_iterations\"]\nval_every = CFG[\"maml_config\"][\"val_every\"]\ncheckpoint_every = CFG[\"maml_config\"][\"checkpoint_every\"]\n\nprint(f\"[CELL 08-08] Training config:\")\nprint(f\"  - Inner LR (alpha): {inner_lr}\")\nprint(f\"  - Inner steps: {inner_steps}\")\nprint(f\"  - Meta-batch size: {meta_batch_size}\")\nprint(f\"  - Iterations: {num_iterations}\")\nprint(f\"  - Warm-Start: YES (from GRU4Rec)\")\n\n# Training history\nhistory = {\n    \"train_loss\": [],\n    \"val_acc\": [],\n    \"iteration\": [],\n}\n\nbest_val_acc = 0.0\n\n# Training loop\nmeta_model.train()\n\nfor iteration in range(1, num_iterations + 1):\n    meta_optimizer.zero_grad()\n    \n    # Sample meta-batch of tasks (episodes)\n    task_indices = np.random.choice(len(episodes_train), size=meta_batch_size, replace=False)\n    \n    meta_loss = 0.0\n    \n    for task_idx in task_indices:\n        # Get episode data\n        row = episodes_train.iloc[task_idx]\n        \n        support_x_raw = row[\"support_prefixes\"]\n        support_y = torch.tensor(row[\"support_labels\"], dtype=torch.long, device=DEVICE)\n        query_x_raw = row[\"query_prefixes\"]\n        query_y = torch.tensor(row[\"query_labels\"], dtype=torch.long, device=DEVICE)\n        \n        # Pad sequences\n        support_x, support_lengths = pad_sequences(support_x_raw)\n        support_x = support_x.to(DEVICE)\n        support_lengths = support_lengths.to(DEVICE)\n        \n        query_x, query_lengths = pad_sequences(query_x_raw)\n        query_x = query_x.to(DEVICE)\n        query_lengths = query_lengths.to(DEVICE)\n        \n        # Clone parameters for inner loop\n        params = {name: param.clone() for name, param in meta_model.named_parameters()}\n        \n        # Inner loop: adapt on support set\n        for _ in range(inner_steps):\n            support_logits = functional_forward(meta_model, support_x, support_lengths, params)\n            support_loss = F.cross_entropy(support_logits, support_y)\n            \n            # Compute gradients w.r.t. params\n            grads = torch.autograd.grad(support_loss, params.values(), create_graph=not CFG[\"maml_config\"][\"use_second_order\"])\n            \n            # Update params\n            params = {\n                name: param - inner_lr * grad\n                for (name, param), grad in zip(params.items(), grads)\n            }\n        \n        # Evaluate on query set with adapted params\n        query_logits = functional_forward(meta_model, query_x, query_lengths, params)\n        query_loss = F.cross_entropy(query_logits, query_y)\n        \n        meta_loss += query_loss\n    \n    # Average meta-loss\n    meta_loss = meta_loss / meta_batch_size\n    \n    # Outer loop: meta-update\n    meta_loss.backward()\n    torch.nn.utils.clip_grad_norm_(meta_model.parameters(), max_norm=10.0)\n    meta_optimizer.step()\n    \n    # Logging\n    if iteration % 100 == 0 or iteration == 1:\n        print(f\"[CELL 08-08] Iteration {iteration}/{num_iterations}, Meta-Loss: {meta_loss.item():.4f}\")\n        history[\"train_loss\"].append(meta_loss.item())\n        history[\"iteration\"].append(iteration)\n    \n    # Validation\n    if iteration % val_every == 0:\n        meta_model.eval()\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for val_idx in range(len(episodes_val)):\n                row = episodes_val.iloc[val_idx]\n                \n                support_x_raw = row[\"support_prefixes\"]\n                support_y = torch.tensor(row[\"support_labels\"], dtype=torch.long, device=DEVICE)\n                query_x_raw = row[\"query_prefixes\"]\n                query_y = torch.tensor(row[\"query_labels\"], dtype=torch.long, device=DEVICE)\n                \n                support_x, support_lengths = pad_sequences(support_x_raw)\n                support_x = support_x.to(DEVICE)\n                support_lengths = support_lengths.to(DEVICE)\n                \n                query_x, query_lengths = pad_sequences(query_x_raw)\n                query_x = query_x.to(DEVICE)\n                query_lengths = query_lengths.to(DEVICE)\n                \n                # Clone and adapt\n                params = {name: param.clone() for name, param in meta_model.named_parameters()}\n                \n                for _ in range(inner_steps):\n                    support_logits = functional_forward(meta_model, support_x, support_lengths, params)\n                    support_loss = F.cross_entropy(support_logits, support_y)\n                    grads = torch.autograd.grad(support_loss, params.values())\n                    params = {\n                        name: param - inner_lr * grad\n                        for (name, param), grad in zip(params.items(), grads)\n                    }\n                \n                query_logits = functional_forward(meta_model, query_x, query_lengths, params)\n                preds = query_logits.argmax(dim=-1)\n                \n                val_correct += (preds == query_y).sum().item()\n                val_total += len(query_y)\n        \n        val_acc = val_correct / val_total\n        history[\"val_acc\"].append(val_acc)\n        print(f\"[CELL 08-08] Iteration {iteration}, Val Acc@1: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(meta_model.state_dict(), OUT_MODEL)\n            print(f\"[CELL 08-08] New best model saved! Val Acc: {val_acc*100:.2f}%\")\n        \n        meta_model.train()\n    \n    # Checkpoint\n    if iteration % checkpoint_every == 0:\n        checkpoint_path = CHECKPOINT_DIR / f\"warmstart_checkpoint_iter{iteration}.pth\"\n        torch.save({\n            \"iteration\": iteration,\n            \"model_state_dict\": meta_model.state_dict(),\n            \"optimizer_state_dict\": meta_optimizer.state_dict(),\n            \"best_val_acc\": best_val_acc,\n        }, checkpoint_path)\n        print(f\"[CELL 08-08] Checkpoint saved: {checkpoint_path.name}\")\n\nprint(f\"\\n[CELL 08-08] Training complete!\")\nprint(f\"[CELL 08-08] Best validation accuracy: {best_val_acc*100:.2f}%\")\n\ncell_end(\"CELL 08-08\", t0, best_val_acc=best_val_acc)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-09] Final Evaluation on Test Set\n\nt0 = cell_start(\"CELL 08-09\", \"Final evaluation on test set\")\n\n# Load best model\nmeta_model.load_state_dict(torch.load(OUT_MODEL, map_location=DEVICE))\nmeta_model.eval()\n\nprint(f\"[CELL 08-09] Loaded best model from: {OUT_MODEL}\")\n\n# Evaluate: Zero-shot (no adaptation)\nzeroshot_correct = 0\nzeroshot_total = 0\n\n# Evaluate: Few-shot (with adaptation)\nfewshot_correct = 0\nfewshot_total = 0\n\nwith torch.no_grad():\n    for test_idx in range(len(episodes_test)):\n        row = episodes_test.iloc[test_idx]\n        \n        support_x_raw = row[\"support_prefixes\"]\n        support_y = torch.tensor(row[\"support_labels\"], dtype=torch.long, device=DEVICE)\n        query_x_raw = row[\"query_prefixes\"]\n        query_y = torch.tensor(row[\"query_labels\"], dtype=torch.long, device=DEVICE)\n        \n        support_x, support_lengths = pad_sequences(support_x_raw)\n        support_x = support_x.to(DEVICE)\n        support_lengths = support_lengths.to(DEVICE)\n        \n        query_x, query_lengths = pad_sequences(query_x_raw)\n        query_x = query_x.to(DEVICE)\n        query_lengths = query_lengths.to(DEVICE)\n        \n        # Zero-shot: no adaptation\n        params_zs = {name: param.clone() for name, param in meta_model.named_parameters()}\n        query_logits_zs = functional_forward(meta_model, query_x, query_lengths, params_zs)\n        preds_zs = query_logits_zs.argmax(dim=-1)\n        zeroshot_correct += (preds_zs == query_y).sum().item()\n        zeroshot_total += len(query_y)\n        \n        # Few-shot: adapt on support set\n        params_fs = {name: param.clone() for name, param in meta_model.named_parameters()}\n        \n        for _ in range(inner_steps):\n            support_logits = functional_forward(meta_model, support_x, support_lengths, params_fs)\n            support_loss = F.cross_entropy(support_logits, support_y)\n            grads = torch.autograd.grad(support_loss, params_fs.values())\n            params_fs = {\n                name: param - inner_lr * grad\n                for (name, param), grad in zip(params_fs.items(), grads)\n            }\n        \n        query_logits_fs = functional_forward(meta_model, query_x, query_lengths, params_fs)\n        preds_fs = query_logits_fs.argmax(dim=-1)\n        fewshot_correct += (preds_fs == query_y).sum().item()\n        fewshot_total += len(query_y)\n\nzeroshot_acc = zeroshot_correct / zeroshot_total\nfewshot_acc = fewshot_correct / fewshot_total\n\nprint(f\"\\n[CELL 08-09] ========== RESULTS ==========\")\nprint(f\"[CELL 08-09] Test episodes: {len(episodes_test)}\")\nprint(f\"\\n[CELL 08-09] Warm-Start MAML Zero-shot: {zeroshot_acc:.4f} ({zeroshot_acc*100:.2f}%)\")\nprint(f\"[CELL 08-09] Warm-Start MAML Few-shot:  {fewshot_acc:.4f} ({fewshot_acc*100:.2f}%)\")\nprint(f\"\\n[CELL 08-09] ========== COMPARISON ==========\")\nprint(f\"[CELL 08-09] GRU4Rec baseline:          33.55%\")\nprint(f\"[CELL 08-09] Vanilla MAML Zero-shot:    25.62%\")\nprint(f\"[CELL 08-09] Vanilla MAML Few-shot:     28.66%\")\nprint(f\"[CELL 08-09] Warm-Start MAML Zero-shot: {zeroshot_acc*100:.2f}%\")\nprint(f\"[CELL 08-09] Warm-Start MAML Few-shot:  {fewshot_acc*100:.2f}%\")\nprint(f\"\\n[CELL 08-09] Improvement over Vanilla MAML: +{(fewshot_acc - 0.2866)*100:.2f} pp\")\nprint(f\"[CELL 08-09] Improvement over GRU4Rec:      {(fewshot_acc - 0.3355)*100:+.2f} pp\")\n\ncell_end(\"CELL 08-09\", t0, zeroshot_acc=zeroshot_acc, fewshot_acc=fewshot_acc)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 08-10] Save results and report\n\nt0 = cell_start(\"CELL 08-10\", \"Save results and report\")\n\n# Results\nresults = {\n    \"model\": \"warmstart_maml\",\n    \"contribution\": \"warm_start_initialization\",\n    \"dataset\": \"xuetangx\",\n    \"config\": CFG,\n    \"metrics\": {\n        \"zeroshot\": {\n            \"accuracy@1\": zeroshot_acc,\n        },\n        \"fewshot\": {\n            \"accuracy@1\": fewshot_acc,\n        },\n    },\n    \"comparison\": {\n        \"gru4rec_baseline\": 0.3355,\n        \"vanilla_maml_zeroshot\": 0.2562,\n        \"vanilla_maml_fewshot\": 0.2866,\n        \"warmstart_maml_zeroshot\": zeroshot_acc,\n        \"warmstart_maml_fewshot\": fewshot_acc,\n    },\n    \"improvement\": {\n        \"over_vanilla_maml\": fewshot_acc - 0.2866,\n        \"over_gru4rec\": fewshot_acc - 0.3355,\n    },\n}\n\n# Save results\nwith open(OUT_RESULTS, \"w\") as f:\n    json.dump(results, f, indent=2)\nprint(f\"[CELL 08-10] Results saved: {OUT_RESULTS}\")\n\n# Report\nreport = {\n    \"notebook\": CFG[\"notebook\"],\n    \"run_tag\": RUN_TAG,\n    \"timestamp\": datetime.now().isoformat(),\n    \"config\": CFG,\n    \"results\": results,\n    \"history\": history,\n}\n\nwith open(REPORT_PATH, \"w\") as f:\n    json.dump(report, f, indent=2)\nprint(f\"[CELL 08-10] Report saved: {REPORT_PATH}\")\n\ncell_end(\"CELL 08-10\", t0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Notebook 08 Complete: Warm-Start MAML Results\n\n**Contribution:** Initialize MAML from pre-trained GRU4Rec weights instead of random initialization.\n\n**Key Results:**\n\n| Model | Initialization | Acc@1 | vs Vanilla MAML | vs GRU4Rec |\n|-------|---------------|-------|-----------------|------------|\n| GRU4Rec (baseline) | Trained | 33.55% | - | - |\n| Vanilla MAML Zero-shot | Random | 25.62% | - | -7.93 pp |\n| Vanilla MAML Few-shot | Random | 28.66% | baseline | -4.89 pp |\n| **Warm-Start MAML Zero-shot** | GRU4Rec | **??%** | +?? pp | +?? pp |\n| **Warm-Start MAML Few-shot** | GRU4Rec | **??%** | +?? pp | +?? pp |\n\n**Key Insight:** By starting from GRU4Rec's learned weights (33.55%), the inner loop only needs to learn user-specific adaptations, not the entire course pattern space.\n\n**Next:** Notebook 09 - Recency-Weighted MAML (Contribution 2)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (VENV)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
