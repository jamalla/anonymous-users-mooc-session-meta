{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# Notebook 12: Warm-Start + Reliability-Weighted MAML (XuetangX)\n\n## Combining Contributions 1 + 3\n\n**Purpose:** Combine warm-start initialization (NB08) with reliability-weighted inner loop (NB11) to see if both enhancements stack.\n\n### Approach\n\n| Component | Source | Description |\n|-----------|--------|-------------|\n| Warm-Start | NB08 | Initialize from pre-trained GRU4Rec |\n| Reliability Weighting | NB11 | `weighted_loss = (reliability * per_sample_loss).sum() / reliability.sum()` |\n\n### Results\n\n| Method | Test HR@10 | Test NDCG@10 | Source |\n|--------|------------|--------------|--------|\n| Vanilla MAML | 47.35% | 37.41% | NB07 |\n| Reliability-Weighted MAML | 48.34% | 37.71% | NB11 |\n| **Warm-Start + Reliability** | **55.62%** | **44.80%** | **NB12** |\n\n**Improvement over NB07:** +8.27% HR@10, +7.39% NDCG@10\n\n### Inputs\n- `data/processed/xuetangx/pairs_with_reliability/pairs.parquet`\n- `data/processed/xuetangx/episodes/episodes_*.parquet`\n- `models/baselines/gru_global.pth` (pre-trained GRU for warm-start)\n\n### Outputs\n- `models/maml/warmstart_reliability_maml.pt`\n- `reports/12_warmstart_reliability_maml_xuetangx/20260204_061110/report.json`"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cell-1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL 12-00] start=2026-02-04T06:11:10\n",
      "[CELL 12-00] PyTorch: 2.10.0+cu128\n",
      "[CELL 12-00] CUDA available: True\n",
      "[CELL 12-00] REPO_ROOT: /workspace/anonymous-users-mooc-session-meta\n",
      "[CELL 12-00] Device: cuda\n",
      "[CELL 12-00] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-00] Bootstrap\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import copy\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from collections import OrderedDict\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(f\"[CELL 12-00] start={t0.isoformat(timespec='seconds')}\")\n",
    "print(f\"[CELL 12-00] PyTorch: {torch.__version__}\")\n",
    "print(f\"[CELL 12-00] CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"PROJECT_STATE.md\").exists():\n",
    "            return p\n",
    "    raise RuntimeError(\"Could not find PROJECT_STATE.md.\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "print(f\"[CELL 12-00] REPO_ROOT: {REPO_ROOT}\")\n",
    "\n",
    "PATHS = {\n",
    "    \"DATA_PROCESSED\": REPO_ROOT / \"data\" / \"processed\",\n",
    "    \"MODELS\": REPO_ROOT / \"models\",\n",
    "    \"REPORTS\": REPO_ROOT / \"reports\",\n",
    "}\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[CELL 12-00] Device: {DEVICE}\")\n",
    "\n",
    "def cell_start(cell_id: str, title: str, **kwargs) -> float:\n",
    "    t = time.time()\n",
    "    print(f\"\\n[{cell_id}] {title}\")\n",
    "    print(f\"[{cell_id}] start={datetime.now().isoformat(timespec='seconds')}\")\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    return t\n",
    "\n",
    "def cell_end(cell_id: str, t0: float, **kwargs) -> None:\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    print(f\"[{cell_id}] elapsed={time.time()-t0:.2f}s\")\n",
    "    print(f\"[{cell_id}] done\")\n",
    "\n",
    "print(\"[CELL 12-00] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cell-2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-01] Seed everything\n",
      "[CELL 12-01] start=2026-02-04T06:11:10\n",
      "[CELL 12-01] seed=20260107\n",
      "[CELL 12-01] elapsed=0.00s\n",
      "[CELL 12-01] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-01] Reproducibility + helpers\n",
    "\n",
    "t0 = cell_start(\"CELL 12-01\", \"Seed everything\")\n",
    "\n",
    "GLOBAL_SEED = 20260107\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(GLOBAL_SEED)\n",
    "\n",
    "def write_json_atomic(path: Path, obj: Any, indent: int = 2) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + f\".tmp_{uuid.uuid4().hex}\")\n",
    "    with tmp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=indent)\n",
    "    tmp.replace(path)\n",
    "\n",
    "def read_json(path: Path) -> Any:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "cell_end(\"CELL 12-01\", t0, seed=GLOBAL_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cell-3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-02] Configuration\n",
      "[CELL 12-02] start=2026-02-04T06:11:10\n",
      "[CELL 12-02] K=5, Q=10\n",
      "[CELL 12-02] Warm-Start: True\n",
      "[CELL 12-02] Reliability Weighting: True\n",
      "[CELL 12-02] Meta iterations: 3000\n",
      "[CELL 12-02] Pre-trained model: /workspace/anonymous-users-mooc-session-meta/models/baselines/gru_global.pth\n",
      "[CELL 12-02] Output dir: /workspace/anonymous-users-mooc-session-meta/reports/12_warmstart_reliability_maml_xuetangx/20260204_061110\n",
      "[CELL 12-02] elapsed=0.00s\n",
      "[CELL 12-02] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-02] Configuration\n",
    "\n",
    "t0 = cell_start(\"CELL 12-02\", \"Configuration\")\n",
    "\n",
    "NOTEBOOK_NAME = \"12_warmstart_reliability_maml_xuetangx\"\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_ID = uuid.uuid4().hex\n",
    "\n",
    "OUT_DIR = PATHS[\"REPORTS\"] / NOTEBOOK_NAME / RUN_TAG\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Episode configuration\n",
    "K = 5\n",
    "Q = 10\n",
    "\n",
    "# Paths\n",
    "EPISODES_DIR = PATHS[\"DATA_PROCESSED\"] / \"xuetangx\" / \"episodes\"\n",
    "PAIRS_DIR = PATHS[\"DATA_PROCESSED\"] / \"xuetangx\" / \"pairs_with_reliability\"\n",
    "VOCAB_DIR = PATHS[\"DATA_PROCESSED\"] / \"xuetangx\" / \"vocab\"\n",
    "PRETRAINED_PATH = PATHS[\"MODELS\"] / \"baselines\" / \"gru_global.pth\"\n",
    "\n",
    "CFG = {\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"seed\": GLOBAL_SEED,\n",
    "    \"K\": K,\n",
    "    \"Q\": Q,\n",
    "    \"gru_config\": {\n",
    "        \"embedding_dim\": 64,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 1,\n",
    "        \"dropout\": 0.1,\n",
    "        \"max_seq_len\": 50,\n",
    "    },\n",
    "    \"maml_config\": {\n",
    "        \"inner_lr\": 0.01,\n",
    "        \"outer_lr\": 0.0001,  # Lower for warm-start (from NB08)\n",
    "        \"num_inner_steps\": 3,  # From NB08\n",
    "        \"meta_batch_size\": 32,\n",
    "        \"num_meta_iterations\": 3000,\n",
    "        \"use_second_order\": False,\n",
    "    },\n",
    "    \"warmstart_config\": {\n",
    "        \"use_warmstart\": True,\n",
    "        \"pretrained_path\": str(PRETRAINED_PATH),\n",
    "    },\n",
    "    \"reliability_config\": {\n",
    "        \"use_reliability_weighting\": True,\n",
    "    },\n",
    "    \"eval_config\": {\n",
    "        \"eval_every\": 100,\n",
    "        \"patience\": 10,\n",
    "    },\n",
    "}\n",
    "\n",
    "write_json_atomic(OUT_DIR / \"config.json\", CFG)\n",
    "\n",
    "print(f\"[CELL 12-02] K={K}, Q={Q}\")\n",
    "print(f\"[CELL 12-02] Warm-Start: {CFG['warmstart_config']['use_warmstart']}\")\n",
    "print(f\"[CELL 12-02] Reliability Weighting: {CFG['reliability_config']['use_reliability_weighting']}\")\n",
    "print(f\"[CELL 12-02] Meta iterations: {CFG['maml_config']['num_meta_iterations']}\")\n",
    "print(f\"[CELL 12-02] Pre-trained model: {PRETRAINED_PATH}\")\n",
    "print(f\"[CELL 12-02] Output dir: {OUT_DIR}\")\n",
    "\n",
    "cell_end(\"CELL 12-02\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cell-4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-03] Load data with reliability\n",
      "[CELL 12-03] start=2026-02-04T06:11:10\n",
      "[CELL 12-03] Episodes train: 47,357\n",
      "[CELL 12-03] Episodes val: 341\n",
      "[CELL 12-03] Episodes test: 313\n",
      "[CELL 12-03] Loaded pairs with reliability: 281,979\n",
      "[CELL 12-03] Reliability range: [0.0485, 1.0000]\n",
      "[CELL 12-03] Vocabulary: 1518 items\n",
      "[CELL 12-03] Pre-trained model exists: True\n",
      "[CELL 12-03] has_reliability=True\n",
      "[CELL 12-03] elapsed=0.24s\n",
      "[CELL 12-03] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-03] Load data with reliability scores\n",
    "\n",
    "t0 = cell_start(\"CELL 12-03\", \"Load data with reliability\")\n",
    "\n",
    "# Load episodes\n",
    "episodes_train = pd.read_parquet(EPISODES_DIR / f\"episodes_train_K{K}_Q{Q}.parquet\")\n",
    "episodes_val = pd.read_parquet(EPISODES_DIR / f\"episodes_val_K{K}_Q{Q}.parquet\")\n",
    "episodes_test = pd.read_parquet(EPISODES_DIR / f\"episodes_test_K{K}_Q{Q}.parquet\")\n",
    "\n",
    "print(f\"[CELL 12-03] Episodes train: {len(episodes_train):,}\")\n",
    "print(f\"[CELL 12-03] Episodes val: {len(episodes_val):,}\")\n",
    "print(f\"[CELL 12-03] Episodes test: {len(episodes_test):,}\")\n",
    "\n",
    "# Load pairs with reliability (from NB03b)\n",
    "pairs_path = PAIRS_DIR / \"pairs.parquet\"\n",
    "if pairs_path.exists():\n",
    "    pairs_all = pd.read_parquet(pairs_path)\n",
    "    HAS_RELIABILITY = 'session_reliability' in pairs_all.columns\n",
    "    print(f\"[CELL 12-03] Loaded pairs with reliability: {len(pairs_all):,}\")\n",
    "    if HAS_RELIABILITY:\n",
    "        print(f\"[CELL 12-03] Reliability range: [{pairs_all['session_reliability'].min():.4f}, {pairs_all['session_reliability'].max():.4f}]\")\n",
    "else:\n",
    "    # Fallback\n",
    "    pairs_all = pd.read_parquet(PATHS[\"DATA_PROCESSED\"] / \"xuetangx\" / \"pairs\" / \"pairs.parquet\")\n",
    "    pairs_all['session_reliability'] = 1.0\n",
    "    HAS_RELIABILITY = False\n",
    "\n",
    "# Load vocab\n",
    "course2id = read_json(VOCAB_DIR / \"course2id.json\")\n",
    "n_items = len(course2id)\n",
    "print(f\"[CELL 12-03] Vocabulary: {n_items} items\")\n",
    "\n",
    "# Create pair_id -> reliability mapping\n",
    "pair_reliability_map = pairs_all.set_index('pair_id')['session_reliability'].to_dict()\n",
    "\n",
    "# Check pre-trained model\n",
    "print(f\"[CELL 12-03] Pre-trained model exists: {PRETRAINED_PATH.exists()}\")\n",
    "\n",
    "cell_end(\"CELL 12-03\", t0, has_reliability=HAS_RELIABILITY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cell-5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-04] Define GRU4Rec model\n",
      "[CELL 12-04] start=2026-02-04T06:11:10\n",
      "[CELL 12-04] GRU4Rec model defined (layer names match NB08)\n",
      "[CELL 12-04] elapsed=0.00s\n",
      "[CELL 12-04] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-04] GRU4Rec Model (matching NB08 architecture)\n",
    "\n",
    "t0 = cell_start(\"CELL 12-04\", \"Define GRU4Rec model\")\n",
    "\n",
    "class GRU4Rec(nn.Module):\n",
    "    \"\"\"GRU-based sequential recommendation model.\n",
    "    \n",
    "    NOTE: Layer names match NB08's GRURecommender for weight loading:\n",
    "    - embedding (not item_embedding)\n",
    "    - fc (not output_layer)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n_items: int, embedding_dim: int, hidden_dim: int,\n",
    "                 num_layers: int = 1, dropout: float = 0.0):\n",
    "        super().__init__()\n",
    "        self.n_items = n_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # Layer names match pre-trained model from NB06/NB08\n",
    "        self.embedding = nn.Embedding(n_items, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, n_items)\n",
    "        \n",
    "    def forward(self, x: torch.Tensor, lengths: Optional[torch.Tensor] = None) -> torch.Tensor:\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        if lengths is not None:\n",
    "            packed = nn.utils.rnn.pack_padded_sequence(\n",
    "                embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            _, hidden = self.gru(packed)\n",
    "        else:\n",
    "            _, hidden = self.gru(embedded)\n",
    "        \n",
    "        last_hidden = hidden[-1]\n",
    "        logits = self.fc(last_hidden)\n",
    "        \n",
    "        return logits\n",
    "\n",
    "print(f\"[CELL 12-04] GRU4Rec model defined (layer names match NB08)\")\n",
    "cell_end(\"CELL 12-04\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cell-6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-05] Initialize with warm-start\n",
      "[CELL 12-05] start=2026-02-04T06:11:10\n",
      "[CELL 12-05] Loaded pre-trained weights from /workspace/anonymous-users-mooc-session-meta/models/baselines/gru_global.pth\n",
      "[CELL 12-05] Pre-trained keys: ['embedding.weight', 'gru.weight_ih_l0', 'gru.weight_hh_l0', 'gru.bias_ih_l0', 'gru.bias_hh_l0', 'fc.weight', 'fc.bias']\n",
      "[CELL 12-05] Model parameters: 367,470\n",
      "[CELL 12-05] elapsed=0.28s\n",
      "[CELL 12-05] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-05] Initialize model with warm-start (from NB08)\n",
    "\n",
    "t0 = cell_start(\"CELL 12-05\", \"Initialize with warm-start\")\n",
    "\n",
    "gru_cfg = CFG[\"gru_config\"]\n",
    "\n",
    "# Create model\n",
    "model = GRU4Rec(\n",
    "    n_items=n_items,\n",
    "    embedding_dim=gru_cfg[\"embedding_dim\"],\n",
    "    hidden_dim=gru_cfg[\"hidden_dim\"],\n",
    "    num_layers=gru_cfg[\"num_layers\"],\n",
    "    dropout=gru_cfg[\"dropout\"]\n",
    ").to(DEVICE)\n",
    "\n",
    "# Load pre-trained weights (warm-start)\n",
    "if PRETRAINED_PATH.exists():\n",
    "    pretrained_state = torch.load(PRETRAINED_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(pretrained_state)\n",
    "    print(f\"[CELL 12-05] Loaded pre-trained weights from {PRETRAINED_PATH}\")\n",
    "    print(f\"[CELL 12-05] Pre-trained keys: {list(pretrained_state.keys())}\")\n",
    "else:\n",
    "    print(f\"[CELL 12-05] WARNING: No pre-trained model found, using random init\")\n",
    "\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"[CELL 12-05] Model parameters: {n_params:,}\")\n",
    "\n",
    "cell_end(\"CELL 12-05\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cell-7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-06] Define episode helpers\n",
      "[CELL 12-06] start=2026-02-04T06:11:10\n",
      "[CELL 12-06] Episode helpers defined\n",
      "[CELL 12-06] elapsed=0.00s\n",
      "[CELL 12-06] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-06] Episode helpers with reliability\n",
    "\n",
    "t0 = cell_start(\"CELL 12-06\", \"Define episode helpers\")\n",
    "\n",
    "def get_episode_data_with_reliability(episode_row, pairs_df, pair_reliability_map):\n",
    "    \"\"\"Extract support and query pairs with reliability scores.\"\"\"\n",
    "    support_pair_ids = episode_row[\"support_pair_ids\"]\n",
    "    query_pair_ids = episode_row[\"query_pair_ids\"]\n",
    "    \n",
    "    support_pairs = pairs_df[pairs_df[\"pair_id\"].isin(support_pair_ids)].sort_values(\"label_ts_epoch\")\n",
    "    query_pairs = pairs_df[pairs_df[\"pair_id\"].isin(query_pair_ids)].sort_values(\"label_ts_epoch\")\n",
    "    \n",
    "    # Get reliability scores\n",
    "    support_reliability = [pair_reliability_map.get(pid, 1.0) for pid in support_pairs['pair_id']]\n",
    "    \n",
    "    return support_pairs, query_pairs, support_reliability\n",
    "\n",
    "\n",
    "def prepare_batch(pairs_df, max_seq_len: int):\n",
    "    \"\"\"Prepare batch tensors from pairs DataFrame.\"\"\"\n",
    "    batch_size = len(pairs_df)\n",
    "    sequences = torch.zeros(batch_size, max_seq_len, dtype=torch.long)\n",
    "    lengths = torch.zeros(batch_size, dtype=torch.long)\n",
    "    labels = torch.zeros(batch_size, dtype=torch.long)\n",
    "    \n",
    "    for i, (_, row) in enumerate(pairs_df.iterrows()):\n",
    "        prefix = row[\"prefix\"]\n",
    "        seq_len = min(len(prefix), max_seq_len)\n",
    "        \n",
    "        if len(prefix) > max_seq_len:\n",
    "            prefix = prefix[-max_seq_len:]\n",
    "        \n",
    "        sequences[i, :seq_len] = torch.tensor(prefix[:seq_len])\n",
    "        lengths[i] = seq_len\n",
    "        labels[i] = row[\"label\"]\n",
    "    \n",
    "    return sequences, lengths, labels\n",
    "\n",
    "print(f\"[CELL 12-06] Episode helpers defined\")\n",
    "cell_end(\"CELL 12-06\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cell-8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-07] Define Reliability-Weighted inner loop\n",
      "[CELL 12-07] start=2026-02-04T06:11:10\n",
      "[CELL 12-07] Reliability-Weighted inner loop defined\n",
      "[CELL 12-07] elapsed=0.00s\n",
      "[CELL 12-07] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-07] Reliability-Weighted Inner Loop (from NB11)\n",
    "\n",
    "t0 = cell_start(\"CELL 12-07\", \"Define Reliability-Weighted inner loop\")\n",
    "\n",
    "def reliability_weighted_inner_loop(\n",
    "    model: nn.Module,\n",
    "    support_seqs: torch.Tensor,\n",
    "    support_lengths: torch.Tensor,\n",
    "    support_labels: torch.Tensor,\n",
    "    support_reliability: torch.Tensor,\n",
    "    inner_lr: float,\n",
    "    num_inner_steps: int,\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    MAML inner loop with reliability-weighted loss.\n",
    "    Updates model parameters IN-PLACE.\n",
    "    \n",
    "    Key: weighted_loss = (reliability * per_sample_loss).sum() / reliability.sum()\n",
    "    \"\"\"\n",
    "    criterion_none = nn.CrossEntropyLoss(reduction='none')\n",
    "    \n",
    "    for step in range(num_inner_steps):\n",
    "        logits = model(support_seqs, support_lengths)\n",
    "        per_sample_loss = criterion_none(logits, support_labels)\n",
    "        \n",
    "        # RELIABILITY-WEIGHTED LOSS (from NB11)\n",
    "        weighted_loss = (support_reliability * per_sample_loss).sum() / (support_reliability.sum() + 1e-8)\n",
    "        \n",
    "        grads = torch.autograd.grad(\n",
    "            weighted_loss,\n",
    "            model.parameters(),\n",
    "            create_graph=False,\n",
    "            allow_unused=True\n",
    "        )\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for param, grad in zip(model.parameters(), grads):\n",
    "                if grad is not None:\n",
    "                    param.sub_(inner_lr * grad)\n",
    "\n",
    "print(f\"[CELL 12-07] Reliability-Weighted inner loop defined\")\n",
    "cell_end(\"CELL 12-07\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cell-9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-08] Define evaluation\n",
      "[CELL 12-08] start=2026-02-04T06:11:10\n",
      "[CELL 12-08] Evaluation function defined\n",
      "[CELL 12-08] elapsed=0.00s\n",
      "[CELL 12-08] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-08] Evaluation function\n",
    "\n",
    "t0 = cell_start(\"CELL 12-08\", \"Define evaluation\")\n",
    "\n",
    "def evaluate_model(\n",
    "    model: nn.Module,\n",
    "    episodes_df: pd.DataFrame,\n",
    "    pairs_df: pd.DataFrame,\n",
    "    pair_reliability_map: dict,\n",
    "    inner_lr: float,\n",
    "    num_inner_steps: int,\n",
    "    max_seq_len: int,\n",
    "    max_episodes: int = 100,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"\n",
    "    Evaluate model with reliability-weighted adaptation.\n",
    "    \"\"\"\n",
    "    all_hr10 = []\n",
    "    all_ndcg10 = []\n",
    "    \n",
    "    episodes_sample = episodes_df.sample(min(max_episodes, len(episodes_df)), random_state=GLOBAL_SEED)\n",
    "    \n",
    "    for _, episode in tqdm(episodes_sample.iterrows(), total=len(episodes_sample), desc=\"Evaluating\", leave=False):\n",
    "        # Save original weights\n",
    "        original_state = copy.deepcopy(model.state_dict())\n",
    "        \n",
    "        # Get episode data\n",
    "        support_pairs, query_pairs, support_reliability = get_episode_data_with_reliability(\n",
    "            episode, pairs_df, pair_reliability_map\n",
    "        )\n",
    "        \n",
    "        if len(support_pairs) == 0 or len(query_pairs) == 0:\n",
    "            model.load_state_dict(original_state)\n",
    "            continue\n",
    "        \n",
    "        # Prepare support batch\n",
    "        support_seqs, support_lengths, support_labels = prepare_batch(support_pairs, max_seq_len)\n",
    "        support_seqs = support_seqs.to(DEVICE)\n",
    "        support_lengths = support_lengths.to(DEVICE)\n",
    "        support_labels = support_labels.to(DEVICE)\n",
    "        support_reliability_tensor = torch.tensor(support_reliability, dtype=torch.float32).to(DEVICE)\n",
    "        \n",
    "        # Inner loop adaptation with reliability weighting\n",
    "        model.train()\n",
    "        reliability_weighted_inner_loop(\n",
    "            model, support_seqs, support_lengths, support_labels,\n",
    "            support_reliability_tensor, inner_lr, num_inner_steps\n",
    "        )\n",
    "        model.eval()\n",
    "        \n",
    "        # Evaluate on query set\n",
    "        query_seqs, query_lengths, query_labels = prepare_batch(query_pairs, max_seq_len)\n",
    "        query_seqs = query_seqs.to(DEVICE)\n",
    "        query_lengths = query_lengths.to(DEVICE)\n",
    "        query_labels = query_labels.to(DEVICE)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            query_logits = model(query_seqs, query_lengths)\n",
    "            _, top10_indices = query_logits.topk(10, dim=1)\n",
    "            \n",
    "            for i, label in enumerate(query_labels):\n",
    "                hit = (top10_indices[i] == label).any().item()\n",
    "                all_hr10.append(float(hit))\n",
    "                \n",
    "                if hit:\n",
    "                    rank = (top10_indices[i] == label).nonzero(as_tuple=True)[0].item() + 1\n",
    "                    ndcg = 1.0 / np.log2(rank + 1)\n",
    "                else:\n",
    "                    ndcg = 0.0\n",
    "                all_ndcg10.append(ndcg)\n",
    "        \n",
    "        # Restore original weights\n",
    "        model.load_state_dict(original_state)\n",
    "    \n",
    "    return {\n",
    "        \"HR@10\": np.mean(all_hr10) * 100 if all_hr10 else 0.0,\n",
    "        \"NDCG@10\": np.mean(all_ndcg10) * 100 if all_ndcg10 else 0.0,\n",
    "        \"n_queries\": len(all_hr10),\n",
    "    }\n",
    "\n",
    "print(f\"[CELL 12-08] Evaluation function defined\")\n",
    "cell_end(\"CELL 12-08\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cell-10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-09] Meta-training setup\n",
      "[CELL 12-09] start=2026-02-04T06:11:10\n",
      "[CELL 12-09] Inner LR: 0.01\n",
      "[CELL 12-09] Outer LR: 0.0001 (lowered for warm-start)\n",
      "[CELL 12-09] Inner steps: 3\n",
      "[CELL 12-09] Meta batch size: 32\n",
      "[CELL 12-09] Meta iterations: 3000\n",
      "[CELL 12-09] elapsed=0.72s\n",
      "[CELL 12-09] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-09] Meta-training setup\n",
    "\n",
    "t0 = cell_start(\"CELL 12-09\", \"Meta-training setup\")\n",
    "\n",
    "maml_cfg = CFG[\"maml_config\"]\n",
    "\n",
    "# Lower outer LR for warm-start (from NB08)\n",
    "meta_optimizer = torch.optim.Adam(model.parameters(), lr=maml_cfg[\"outer_lr\"])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "inner_lr = maml_cfg[\"inner_lr\"]\n",
    "num_inner_steps = maml_cfg[\"num_inner_steps\"]\n",
    "meta_batch_size = maml_cfg[\"meta_batch_size\"]\n",
    "num_meta_iterations = maml_cfg[\"num_meta_iterations\"]\n",
    "max_seq_len = CFG[\"gru_config\"][\"max_seq_len\"]\n",
    "\n",
    "print(f\"[CELL 12-09] Inner LR: {inner_lr}\")\n",
    "print(f\"[CELL 12-09] Outer LR: {maml_cfg['outer_lr']} (lowered for warm-start)\")\n",
    "print(f\"[CELL 12-09] Inner steps: {num_inner_steps}\")\n",
    "print(f\"[CELL 12-09] Meta batch size: {meta_batch_size}\")\n",
    "print(f\"[CELL 12-09] Meta iterations: {num_meta_iterations}\")\n",
    "\n",
    "cell_end(\"CELL 12-09\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cell-11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-10] Meta-training (Warm-Start + Reliability-Weighted)\n",
      "[CELL 12-10] start=2026-02-04T06:11:11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac4d05e67634e10a537244bb5c13bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Meta-training:   0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e4d8993a3e4539a89f4c85656eecbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 100] Loss: 2.7937 | Val HR@10: 60.00% | Val NDCG@10: 49.18%\n",
      "  -> New best! Saved model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9b8e358abc404cb784ee1e5808cc75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 200] Loss: 2.6867 | Val HR@10: 59.80% | Val NDCG@10: 49.13%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62247b96688946a98cbfd58d4f85afaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 300] Loss: 2.8684 | Val HR@10: 60.20% | Val NDCG@10: 49.08%\n",
      "  -> New best! Saved model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa45450f93d4f248d71566993719226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 400] Loss: 3.4820 | Val HR@10: 59.80% | Val NDCG@10: 48.80%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c86d57abb33b4227aa12c199ec09a41b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 500] Loss: 3.7085 | Val HR@10: 59.80% | Val NDCG@10: 48.91%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "089a8d8e47214d8aa8ad8c5e34dbe407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 600] Loss: 3.4141 | Val HR@10: 60.40% | Val NDCG@10: 48.92%\n",
      "  -> New best! Saved model.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58487ca24bc4e4eb57d6b47abac49b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 700] Loss: 2.9767 | Val HR@10: 60.20% | Val NDCG@10: 49.06%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4b36dc83cc49789cd79dbf3bd20d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 800] Loss: 2.7475 | Val HR@10: 60.20% | Val NDCG@10: 48.91%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0dc9d2ceb7e49c98f94a8c318416d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 900] Loss: 3.3865 | Val HR@10: 59.80% | Val NDCG@10: 48.94%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83ba0b07d3d24bea99c9e2cc17cae7fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 1000] Loss: 3.0792 | Val HR@10: 59.80% | Val NDCG@10: 48.84%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b946b19ac22140ffa699d388f7bf97e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 1100] Loss: 3.5377 | Val HR@10: 60.00% | Val NDCG@10: 48.80%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbbb5c58973d460fbbf76c80456ef4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 1200] Loss: 3.0569 | Val HR@10: 60.20% | Val NDCG@10: 48.67%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6e67025287490fbb25ce2adae23ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 1300] Loss: 2.9498 | Val HR@10: 59.80% | Val NDCG@10: 48.82%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93e0cab6137a4c6087f2d07f476b78c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 1400] Loss: 3.0483 | Val HR@10: 59.40% | Val NDCG@10: 48.53%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8d9d08bb4c84e3abdbe5ce222979ea6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 1500] Loss: 2.5673 | Val HR@10: 59.20% | Val NDCG@10: 48.54%\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a1c9bb013c24e35ac19a9137c7b2aef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Iter 1600] Loss: 2.2218 | Val HR@10: 59.20% | Val NDCG@10: 48.46%\n",
      "\n",
      "Early stopping at iteration 1600\n",
      "\n",
      "[CELL 12-10] Training complete!\n",
      "[CELL 12-10] Best Val HR@10: 60.40% at iteration 600\n",
      "[CELL 12-10] best_val_hr10=60.40%\n",
      "[CELL 12-10] elapsed=1003.46s\n",
      "[CELL 12-10] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-10] Meta-training loop (FOMAML with Warm-Start + Reliability)\n",
    "\n",
    "t0 = cell_start(\"CELL 12-10\", \"Meta-training (Warm-Start + Reliability-Weighted)\")\n",
    "\n",
    "# Filter warnings\n",
    "warnings.filterwarnings('ignore', message='RNN module weights are not part of single contiguous chunk of memory')\n",
    "\n",
    "train_users = episodes_train[\"user_id\"].unique()\n",
    "eval_every = CFG[\"eval_config\"][\"eval_every\"]\n",
    "patience = CFG[\"eval_config\"][\"patience\"]\n",
    "\n",
    "best_val_hr10 = 0.0\n",
    "best_iteration = 0\n",
    "patience_counter = 0\n",
    "\n",
    "training_log = []\n",
    "MODEL_SAVE_PATH = PATHS[\"MODELS\"] / \"maml\" / \"warmstart_reliability_maml.pt\"\n",
    "MODEL_SAVE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model.train()\n",
    "\n",
    "for meta_iter in tqdm(range(num_meta_iterations), desc=\"Meta-training\"):\n",
    "    # Sample meta-batch\n",
    "    meta_batch_users = np.random.choice(train_users, size=min(meta_batch_size, len(train_users)), replace=False)\n",
    "    meta_batch_episodes = episodes_train[episodes_train[\"user_id\"].isin(meta_batch_users)]\n",
    "    \n",
    "    if len(meta_batch_episodes) == 0:\n",
    "        continue\n",
    "    \n",
    "    meta_batch_episodes = meta_batch_episodes.sample(min(meta_batch_size, len(meta_batch_episodes)))\n",
    "    \n",
    "    meta_optimizer.zero_grad()\n",
    "    \n",
    "    # Zero gradients\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            p.grad.zero_()\n",
    "    \n",
    "    total_query_loss = 0.0\n",
    "    n_valid = 0\n",
    "    \n",
    "    for _, episode in meta_batch_episodes.iterrows():\n",
    "        support_pairs, query_pairs, support_reliability = get_episode_data_with_reliability(\n",
    "            episode, pairs_all, pair_reliability_map\n",
    "        )\n",
    "        \n",
    "        if len(support_pairs) == 0 or len(query_pairs) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Prepare batches\n",
    "        support_seqs, support_lengths, support_labels = prepare_batch(support_pairs, max_seq_len)\n",
    "        support_seqs = support_seqs.to(DEVICE)\n",
    "        support_lengths = support_lengths.to(DEVICE)\n",
    "        support_labels = support_labels.to(DEVICE)\n",
    "        support_reliability_tensor = torch.tensor(support_reliability, dtype=torch.float32).to(DEVICE)\n",
    "        \n",
    "        query_seqs, query_lengths, query_labels = prepare_batch(query_pairs, max_seq_len)\n",
    "        query_seqs = query_seqs.to(DEVICE)\n",
    "        query_lengths = query_lengths.to(DEVICE)\n",
    "        query_labels = query_labels.to(DEVICE)\n",
    "        \n",
    "        # FOMAML: Deep copy model\n",
    "        adapted_model = copy.deepcopy(model)\n",
    "        adapted_model.train()\n",
    "        adapted_model.gru.flatten_parameters()\n",
    "        \n",
    "        # Inner loop with RELIABILITY WEIGHTING\n",
    "        reliability_weighted_inner_loop(\n",
    "            adapted_model, support_seqs, support_lengths, support_labels,\n",
    "            support_reliability_tensor, inner_lr, num_inner_steps\n",
    "        )\n",
    "        \n",
    "        # Query loss\n",
    "        query_logits = adapted_model(query_seqs, query_lengths)\n",
    "        query_loss = criterion(query_logits, query_labels)\n",
    "        \n",
    "        query_loss.backward()\n",
    "        \n",
    "        # Transfer gradients\n",
    "        with torch.no_grad():\n",
    "            for meta_p, adapted_p in zip(model.parameters(), adapted_model.parameters()):\n",
    "                if adapted_p.grad is not None:\n",
    "                    if meta_p.grad is None:\n",
    "                        meta_p.grad = adapted_p.grad.clone()\n",
    "                    else:\n",
    "                        meta_p.grad.add_(adapted_p.grad)\n",
    "        \n",
    "        total_query_loss += query_loss.item()\n",
    "        n_valid += 1\n",
    "        \n",
    "        del adapted_model\n",
    "    \n",
    "    if n_valid > 0:\n",
    "        # Average gradients\n",
    "        for p in model.parameters():\n",
    "            if p.grad is not None:\n",
    "                p.grad.div_(n_valid)\n",
    "        \n",
    "        # Gradient clipping (helps with warm-start)\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=10.0)\n",
    "        \n",
    "        meta_optimizer.step()\n",
    "        avg_loss = total_query_loss / n_valid\n",
    "    else:\n",
    "        avg_loss = 0.0\n",
    "    \n",
    "    # Evaluation\n",
    "    if (meta_iter + 1) % eval_every == 0:\n",
    "        val_metrics = evaluate_model(\n",
    "            model, episodes_val, pairs_all, pair_reliability_map,\n",
    "            inner_lr, num_inner_steps, max_seq_len,\n",
    "            max_episodes=50\n",
    "        )\n",
    "        \n",
    "        log_entry = {\n",
    "            \"iteration\": meta_iter + 1,\n",
    "            \"train_loss\": avg_loss,\n",
    "            \"val_HR@10\": val_metrics[\"HR@10\"],\n",
    "            \"val_NDCG@10\": val_metrics[\"NDCG@10\"],\n",
    "        }\n",
    "        training_log.append(log_entry)\n",
    "        \n",
    "        print(f\"\\n[Iter {meta_iter+1}] Loss: {avg_loss:.4f} | Val HR@10: {val_metrics['HR@10']:.2f}% | Val NDCG@10: {val_metrics['NDCG@10']:.2f}%\")\n",
    "        \n",
    "        if val_metrics[\"HR@10\"] > best_val_hr10:\n",
    "            best_val_hr10 = val_metrics[\"HR@10\"]\n",
    "            best_iteration = meta_iter + 1\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "            print(f\"  -> New best! Saved model.\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"\\nEarly stopping at iteration {meta_iter+1}\")\n",
    "                break\n",
    "        \n",
    "        model.train()\n",
    "\n",
    "print(f\"\\n[CELL 12-10] Training complete!\")\n",
    "print(f\"[CELL 12-10] Best Val HR@10: {best_val_hr10:.2f}% at iteration {best_iteration}\")\n",
    "\n",
    "cell_end(\"CELL 12-10\", t0, best_val_hr10=f\"{best_val_hr10:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cell-12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-11] Final test evaluation\n",
      "[CELL 12-11] start=2026-02-04T06:27:55\n",
      "[CELL 12-11] Loaded best model from /workspace/anonymous-users-mooc-session-meta/models/maml/warmstart_reliability_maml.pt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3de524539f3149709cf32f6212070b34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-11] ===== TEST RESULTS =====\n",
      "[CELL 12-11] Test HR@10:   55.62%\n",
      "[CELL 12-11] Test NDCG@10: 44.80%\n",
      "[CELL 12-11] N queries:    3130\n",
      "[CELL 12-11] ===========================\n",
      "[CELL 12-11] test_HR10=55.62%\n",
      "[CELL 12-11] elapsed=5.61s\n",
      "[CELL 12-11] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-11] Final evaluation on test set\n",
    "\n",
    "t0 = cell_start(\"CELL 12-11\", \"Final test evaluation\")\n",
    "\n",
    "# Load best model\n",
    "if MODEL_SAVE_PATH.exists():\n",
    "    model.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=DEVICE))\n",
    "    print(f\"[CELL 12-11] Loaded best model from {MODEL_SAVE_PATH}\")\n",
    "\n",
    "# Evaluate on test set\n",
    "test_metrics = evaluate_model(\n",
    "    model, episodes_test, pairs_all, pair_reliability_map,\n",
    "    inner_lr, num_inner_steps, max_seq_len,\n",
    "    max_episodes=len(episodes_test)\n",
    ")\n",
    "\n",
    "print(f\"\\n[CELL 12-11] ===== TEST RESULTS =====\")\n",
    "print(f\"[CELL 12-11] Test HR@10:   {test_metrics['HR@10']:.2f}%\")\n",
    "print(f\"[CELL 12-11] Test NDCG@10: {test_metrics['NDCG@10']:.2f}%\")\n",
    "print(f\"[CELL 12-11] N queries:    {test_metrics['n_queries']}\")\n",
    "print(f\"[CELL 12-11] ===========================\")\n",
    "\n",
    "cell_end(\"CELL 12-11\", t0, test_HR10=f\"{test_metrics['HR@10']:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cell-13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 12-12] Save report\n",
      "[CELL 12-12] start=2026-02-04T06:28:00\n",
      "[CELL 12-12] Report saved to /workspace/anonymous-users-mooc-session-meta/reports/12_warmstart_reliability_maml_xuetangx/20260204_061110/report.json\n",
      "\n",
      "[CELL 12-12] ===== COMPARISON =====\n",
      "  Vanilla MAML (NB07):              47.35% HR@10\n",
      "  Reliability MAML (NB11):          48.34% HR@10\n",
      "  Warm-Start + Reliability (NB12):  55.62% HR@10\n",
      "\n",
      "  Improvement over NB07: +8.27%\n",
      "  Improvement over NB11: +7.28%\n",
      "[CELL 12-12] ===========================\n",
      "[CELL 12-12] elapsed=0.00s\n",
      "[CELL 12-12] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 12-12] Save report\n",
    "\n",
    "t0 = cell_start(\"CELL 12-12\", \"Save report\")\n",
    "\n",
    "report = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"config\": CFG,\n",
    "    \"results\": {\n",
    "        \"best_val_HR@10\": best_val_hr10,\n",
    "        \"best_iteration\": best_iteration,\n",
    "        \"test_HR@10\": test_metrics[\"HR@10\"],\n",
    "        \"test_NDCG@10\": test_metrics[\"NDCG@10\"],\n",
    "        \"test_n_queries\": test_metrics[\"n_queries\"],\n",
    "    },\n",
    "    \"comparison\": {\n",
    "        \"vanilla_maml_NB07\": {\"HR@10\": 47.35, \"NDCG@10\": 37.41},\n",
    "        \"reliability_maml_NB11\": {\"HR@10\": 48.34, \"NDCG@10\": 37.71},\n",
    "        \"warmstart_reliability_NB12\": {\"HR@10\": test_metrics[\"HR@10\"], \"NDCG@10\": test_metrics[\"NDCG@10\"]},\n",
    "    },\n",
    "    \"training_log\": training_log,\n",
    "}\n",
    "\n",
    "write_json_atomic(OUT_DIR / \"report.json\", report)\n",
    "\n",
    "print(f\"[CELL 12-12] Report saved to {OUT_DIR / 'report.json'}\")\n",
    "\n",
    "# Print comparison\n",
    "print(f\"\\n[CELL 12-12] ===== COMPARISON =====\")\n",
    "print(f\"  Vanilla MAML (NB07):              47.35% HR@10\")\n",
    "print(f\"  Reliability MAML (NB11):          48.34% HR@10\")\n",
    "print(f\"  Warm-Start + Reliability (NB12):  {test_metrics['HR@10']:.2f}% HR@10\")\n",
    "print(f\"\\n  Improvement over NB07: {test_metrics['HR@10'] - 47.35:+.2f}%\")\n",
    "print(f\"  Improvement over NB11: {test_metrics['HR@10'] - 48.34:+.2f}%\")\n",
    "print(f\"[CELL 12-12] ===========================\")\n",
    "\n",
    "cell_end(\"CELL 12-12\", t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": "## Notebook 12 Complete\n\n### Experiment: Warm-Start + Reliability-Weighted MAML\n\n**Combined Approach:**\n1. **Warm-Start (from NB08):** Initialize from pre-trained GRU4Rec (`models/baselines/gru_global.pth`)\n2. **Reliability Weighting (from NB11):** Weight inner loop loss by session reliability\n\n### Results Comparison\n\n| Method | Test HR@10 | Test NDCG@10 | Source |\n|--------|------------|--------------|--------|\n| Vanilla MAML | 47.35% | 37.41% | NB07 |\n| Reliability-Weighted MAML | 48.34% | 37.71% | NB11 |\n| **Warm-Start + Reliability** | **55.62%** | **44.80%** | **NB12** |\n\n### Improvements\n- **Over Vanilla MAML (NB07):** +8.27% HR@10, +7.39% NDCG@10\n- **Over Reliability MAML (NB11):** +7.28% HR@10, +7.09% NDCG@10\n\n### Key Findings\n1. **Warm-start + reliability weighting stack effectively** - The combination significantly outperforms either enhancement alone\n2. **Faster convergence** - Best model at iteration 600 (vs 3000 for vanilla MAML)\n3. **Substantial gains in both metrics** - Both HR@10 and NDCG@10 improved, indicating better ranking quality\n\n### Key Configuration\n- Outer LR: 0.0001 (lowered for warm-start)\n- Inner steps: 3 (from NB08)\n- Gradient clipping: max_norm=10.0\n\n### Outputs\n- Model: `models/maml/warmstart_reliability_maml.pt`\n- Report: `reports/12_warmstart_reliability_maml_xuetangx/20260204_061110/report.json`"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (VENV)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}