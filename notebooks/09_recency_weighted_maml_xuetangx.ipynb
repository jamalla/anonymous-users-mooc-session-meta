{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Notebook 09: Recency-Weighted MAML (XuetangX) - Contribution 2\n\n**Purpose:** Improve MAML inner loop by weighting support pairs by recency - more recent pairs get higher weight.\n\n**Research Motivation:**\n- In sequential recommendation, recent interactions better reflect current user preferences\n- Standard MAML weights all K support pairs equally\n- For cold-start users, the most recent interactions are most informative about current learning goals\n\n**Key Insight:**\n```\nStandard MAML Inner Loop:\n  Loss = (1/K) * sum(loss_i)           # Equal weights\n\nRecency-Weighted MAML Inner Loop:\n  Loss = sum(w_i * loss_i)             # w_i proportional to recency\n  where w_i = exp(lambda * recency_i)  # Exponential decay\n```\n\n**Hypothesis:** Recency-weighted loss will improve adaptation by focusing on recent user behavior.\n\n**Experiments:**\n1. Recency-Weighted only (random init)\n2. Warm-Start + Recency-Weighted (combined)\n\n**Inputs:**\n- `data/processed/xuetangx/episodes/episodes_{train|val|test}_K5_Q10.parquet`\n- `models/baselines/gru_global.pth` (for Warm-Start variant)\n- `data/processed/xuetangx/vocab/course2id.json`\n\n**Outputs:**\n- `models/contributions/recency_maml_K5.pth`\n- `models/contributions/warmstart_recency_maml_K5.pth`\n- `results/recency_maml_K5_Q10.json`\n- `reports/09_recency_weighted_maml_xuetangx/<run_tag>/report.json`\n\n**Comparison Matrix:**\n| Model | Init | Inner Loop | Expected Acc@1 |\n|-------|------|------------|----------------|\n| Vanilla MAML | Random | Equal weights | 28.66% |\n| Warm-Start MAML | GRU4Rec | Equal weights | ??% (from NB08) |\n| Recency MAML | Random | Recency weights | ??% |\n| **Warm-Start + Recency** | GRU4Rec | Recency weights | **??%** |"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-00] Bootstrap: repo root + paths + logger\n\nimport os\nimport sys\nimport json\nimport time\nimport uuid\nimport copy\nimport hashlib\nfrom pathlib import Path\nfrom datetime import datetime\nfrom typing import Any, Dict, List, Tuple, Optional\nfrom collections import OrderedDict\n\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nt0 = datetime.now()\nprint(f\"[CELL 09-00] start={t0.isoformat(timespec='seconds')}\")\nprint(\"[CELL 09-00] CWD:\", Path.cwd().resolve())\n\ndef find_repo_root(start: Path) -> Path:\n    start = start.resolve()\n    for p in [start, *start.parents]:\n        if (p / \"PROJECT_STATE.md\").exists():\n            return p\n    raise RuntimeError(\"Could not find repo root (no PROJECT_STATE.md)\")\n\nREPO_ROOT = find_repo_root(Path.cwd())\nprint(f\"[CELL 09-00] REPO_ROOT: {REPO_ROOT}\")\n\nsys.path.insert(0, str(REPO_ROOT / \"src\"))\n\nMETA_REGISTRY = REPO_ROOT / \"meta.json\"\nDATA_INTERIM = REPO_ROOT / \"data\" / \"interim\"\nDATA_PROCESSED = REPO_ROOT / \"data\" / \"processed\"\nMODELS = REPO_ROOT / \"models\"\nRESULTS = REPO_ROOT / \"results\"\nREPORTS = REPO_ROOT / \"reports\"\n\nPATHS = {\n    \"REPO_ROOT\": REPO_ROOT,\n    \"META_REGISTRY\": META_REGISTRY,\n    \"DATA_INTERIM\": DATA_INTERIM,\n    \"DATA_PROCESSED\": DATA_PROCESSED,\n    \"MODELS\": MODELS,\n    \"RESULTS\": RESULTS,\n    \"REPORTS\": REPORTS,\n}\n\nfor name, path in PATHS.items():\n    print(f\"[CELL 09-00] {name}={path}\")\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"[CELL 09-00] PyTorch device: {DEVICE}\")\n\ndef cell_start(cell_id: str, description: str = \"\") -> datetime:\n    t = datetime.now()\n    msg = f\"[{cell_id}] start={t.isoformat(timespec='seconds')}\"\n    if description:\n        msg += f\" | {description}\"\n    print(msg)\n    return t\n\ndef cell_end(cell_id: str, t_start: datetime, **kv) -> None:\n    elapsed = (datetime.now() - t_start).total_seconds()\n    for k, v in kv.items():\n        print(f\"[{cell_id}] {k}={v}\")\n    print(f\"[{cell_id}] done in {elapsed:.1f}s\")\n\nprint(\"[CELL 09-00] done\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-01] Configuration\n\nt0 = cell_start(\"CELL 09-01\", \"Configuration\")\n\nRUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\") + \"_\" + uuid.uuid4().hex[:8]\nprint(f\"[CELL 09-01] RUN_TAG: {RUN_TAG}\")\n\nCFG = {\n    \"notebook\": \"09_recency_weighted_maml_xuetangx\",\n    \"run_tag\": RUN_TAG,\n    \"dataset\": \"xuetangx\",\n    \"contribution\": \"recency_weighted_maml\",\n    \n    # Episode config\n    \"episode_config\": {\n        \"K\": 5,   # support set size\n        \"Q\": 10,  # query set size\n    },\n    \n    # Model config (same as GRU4Rec baseline)\n    \"model_config\": {\n        \"embed_dim\": 64,\n        \"hidden_dim\": 64,\n        \"n_layers\": 1,\n        \"dropout\": 0.1,\n    },\n    \n    # MAML config\n    \"maml_config\": {\n        \"inner_lr\": 0.01,\n        \"outer_lr\": 0.001,\n        \"inner_steps\": 5,\n        \"meta_batch_size\": 32,\n        \"num_meta_iterations\": 3000,\n        \"use_second_order\": False,  # FOMAML\n        \"val_every\": 100,\n        \"checkpoint_every\": 500,\n    },\n    \n    # Recency-Weighted config (NEW - CONTRIBUTION 2)\n    \"recency_config\": {\n        \"weighting_scheme\": \"exponential\",  # exponential, linear, softmax\n        \"lambda\": 0.5,                       # decay parameter for exponential\n        \"temperature\": 1.0,                  # temperature for softmax\n    },\n    \n    # Warm-Start config (can be combined)\n    \"warmstart_config\": {\n        \"use_warmstart\": True,  # Set to True for combined experiment\n        \"pretrained_path\": \"models/baselines/gru_global.pth\",\n    },\n    \n    \"seed\": 42,\n}\n\n# Set seeds\nnp.random.seed(CFG[\"seed\"])\ntorch.manual_seed(CFG[\"seed\"])\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(CFG[\"seed\"])\n\nprint(f\"[CELL 09-01] Configuration:\")\nprint(f\"  - Contribution: {CFG['contribution']}\")\nprint(f\"  - Recency weighting: {CFG['recency_config']['weighting_scheme']}\")\nprint(f\"  - Lambda: {CFG['recency_config']['lambda']}\")\nprint(f\"  - Use Warm-Start: {CFG['warmstart_config']['use_warmstart']}\")\nprint(f\"  - Episode: K={CFG['episode_config']['K']}, Q={CFG['episode_config']['Q']}\")\nprint(f\"  - Meta iterations: {CFG['maml_config']['num_meta_iterations']}\")\n\ncell_end(\"CELL 09-01\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-02] Setup paths\n\nt0 = cell_start(\"CELL 09-02\", \"Setup paths\")\n\n# Input paths\nEPISODES_DIR = DATA_PROCESSED / \"xuetangx\" / \"episodes\"\nVOCAB_DIR = DATA_PROCESSED / \"xuetangx\" / \"vocab\"\nPRETRAINED_PATH = REPO_ROOT / CFG[\"warmstart_config\"][\"pretrained_path\"]\n\nK = CFG[\"episode_config\"][\"K\"]\nQ = CFG[\"episode_config\"][\"Q\"]\n\nEPISODES_TRAIN = EPISODES_DIR / f\"episodes_train_K{K}_Q{Q}.parquet\"\nEPISODES_VAL = EPISODES_DIR / f\"episodes_val_K{K}_Q{Q}.parquet\"\nEPISODES_TEST = EPISODES_DIR / f\"episodes_test_K{K}_Q{Q}.parquet\"\nCOURSE2ID_PATH = VOCAB_DIR / \"course2id.json\"\n\n# Output paths\nCONTRIB_MODELS_DIR = MODELS / \"contributions\"\nCONTRIB_MODELS_DIR.mkdir(parents=True, exist_ok=True)\n\nCHECKPOINT_DIR = CONTRIB_MODELS_DIR / \"checkpoints\"\nCHECKPOINT_DIR.mkdir(parents=True, exist_ok=True)\n\nREPORT_DIR = REPORTS / \"09_recency_weighted_maml_xuetangx\" / RUN_TAG\nREPORT_DIR.mkdir(parents=True, exist_ok=True)\n\n# Model name depends on whether we use warm-start\nif CFG[\"warmstart_config\"][\"use_warmstart\"]:\n    model_name = \"warmstart_recency_maml_K5\"\nelse:\n    model_name = \"recency_maml_K5\"\n\nOUT_MODEL = CONTRIB_MODELS_DIR / f\"{model_name}.pth\"\nOUT_RESULTS = RESULTS / f\"{model_name}_Q10.json\"\nREPORT_PATH = REPORT_DIR / \"report.json\"\n\nprint(f\"[CELL 09-02] Input episodes: {EPISODES_TRAIN}\")\nprint(f\"[CELL 09-02] Output model: {OUT_MODEL}\")\nprint(f\"[CELL 09-02] Use Warm-Start: {CFG['warmstart_config']['use_warmstart']}\")\n\ncell_end(\"CELL 09-02\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-03] Load data\n\nt0 = cell_start(\"CELL 09-03\", \"Load episodes and vocabulary\")\n\n# Load vocabulary\nwith open(COURSE2ID_PATH, \"r\") as f:\n    course2id = json.load(f)\nn_items = len(course2id)\nprint(f\"[CELL 09-03] Vocabulary size: {n_items} courses\")\n\n# Load episodes\nepisodes_train = pd.read_parquet(EPISODES_TRAIN)\nepisodes_val = pd.read_parquet(EPISODES_VAL)\nepisodes_test = pd.read_parquet(EPISODES_TEST)\n\nprint(f\"[CELL 09-03] Train episodes: {len(episodes_train):,}\")\nprint(f\"[CELL 09-03] Val episodes:   {len(episodes_val):,}\")\nprint(f\"[CELL 09-03] Test episodes:  {len(episodes_test):,}\")\n\n# Check if timestamps are available\nprint(f\"[CELL 09-03] Episode columns: {list(episodes_train.columns)}\")\n\ncell_end(\"CELL 09-03\", t0, n_items=n_items)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-04] Define Recency Weighting Functions (KEY CONTRIBUTION)\n\nt0 = cell_start(\"CELL 09-04\", \"Define recency weighting functions\")\n\ndef compute_recency_weights_exponential(K: int, lam: float = 0.5) -> torch.Tensor:\n    \"\"\"Exponential recency weights.\n    \n    w_i = exp(lambda * (i / (K-1)))  for i in [0, K-1]\n    Normalized to sum to 1.\n    \n    Args:\n        K: Number of support pairs\n        lam: Decay parameter (higher = more weight on recent)\n        \n    Returns:\n        weights: [K] tensor, normalized\n        \n    Example (K=5, lam=0.5):\n        positions: [0, 1, 2, 3, 4] (0=oldest, 4=newest)\n        raw: [1.0, 1.13, 1.28, 1.46, 1.65]\n        normalized: [0.15, 0.17, 0.19, 0.22, 0.25]\n    \"\"\"\n    positions = torch.arange(K, dtype=torch.float32)  # [0, 1, ..., K-1]\n    normalized_positions = positions / (K - 1) if K > 1 else positions  # [0, ..., 1]\n    \n    weights = torch.exp(lam * normalized_positions)\n    weights = weights / weights.sum()  # Normalize to sum to 1\n    \n    return weights\n\ndef compute_recency_weights_linear(K: int) -> torch.Tensor:\n    \"\"\"Linear recency weights.\n    \n    w_i = (i + 1) / sum(1..K)\n    \n    Example (K=5):\n        positions: [1, 2, 3, 4, 5]\n        normalized: [0.067, 0.133, 0.2, 0.267, 0.333]\n    \"\"\"\n    positions = torch.arange(1, K + 1, dtype=torch.float32)  # [1, 2, ..., K]\n    weights = positions / positions.sum()\n    return weights\n\ndef compute_recency_weights_softmax(K: int, temperature: float = 1.0) -> torch.Tensor:\n    \"\"\"Softmax recency weights.\n    \n    w = softmax(positions / temperature)\n    \n    Example (K=5, temp=1.0):\n        positions: [0, 1, 2, 3, 4]\n        softmax: [0.01, 0.04, 0.09, 0.24, 0.62]\n    \"\"\"\n    positions = torch.arange(K, dtype=torch.float32)\n    weights = F.softmax(positions / temperature, dim=0)\n    return weights\n\n# Demonstrate the weighting schemes\nK = CFG[\"episode_config\"][\"K\"]\nlam = CFG[\"recency_config\"][\"lambda\"]\ntemp = CFG[\"recency_config\"][\"temperature\"]\n\nprint(f\"[CELL 09-04] Recency Weighting Schemes (K={K}):\")\nprint(f\"\")\nprint(f\"  Position:     [oldest]  →  [newest]\")\nprint(f\"  Index:        [0, 1, 2, 3, 4]\")\nprint(f\"\")\n\nw_equal = torch.ones(K) / K\nw_exp = compute_recency_weights_exponential(K, lam)\nw_linear = compute_recency_weights_linear(K)\nw_softmax = compute_recency_weights_softmax(K, temp)\n\nprint(f\"  Equal:       {[f'{w:.3f}' for w in w_equal.tolist()]}\")\nprint(f\"  Exponential: {[f'{w:.3f}' for w in w_exp.tolist()]} (lambda={lam})\")\nprint(f\"  Linear:      {[f'{w:.3f}' for w in w_linear.tolist()]}\")\nprint(f\"  Softmax:     {[f'{w:.3f}' for w in w_softmax.tolist()]} (temp={temp})\")\n\nprint(f\"\")\nprint(f\"  Selected scheme: {CFG['recency_config']['weighting_scheme']}\")\n\ncell_end(\"CELL 09-04\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-05] Visualize Recency Weights\n\nt0 = cell_start(\"CELL 09-05\", \"Visualize recency weights\")\n\nfig, axes = plt.subplots(1, 3, figsize=(12, 4))\n\n# Exponential with different lambdas\nax = axes[0]\nfor lam_val in [0.1, 0.3, 0.5, 1.0, 2.0]:\n    w = compute_recency_weights_exponential(K, lam_val)\n    ax.plot(range(K), w.numpy(), marker='o', label=f'λ={lam_val}')\nax.set_xlabel('Support Pair Index (0=oldest)')\nax.set_ylabel('Weight')\nax.set_title('Exponential Weighting')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Linear\nax = axes[1]\nw_equal = torch.ones(K) / K\nw_linear = compute_recency_weights_linear(K)\nax.bar(range(K), w_equal.numpy(), alpha=0.5, label='Equal')\nax.bar(range(K), w_linear.numpy(), alpha=0.5, label='Linear')\nax.set_xlabel('Support Pair Index (0=oldest)')\nax.set_ylabel('Weight')\nax.set_title('Linear vs Equal Weighting')\nax.legend()\nax.grid(True, alpha=0.3)\n\n# Softmax with different temperatures\nax = axes[2]\nfor temp_val in [0.5, 1.0, 2.0, 5.0]:\n    w = compute_recency_weights_softmax(K, temp_val)\n    ax.plot(range(K), w.numpy(), marker='o', label=f'τ={temp_val}')\nax.set_xlabel('Support Pair Index (0=oldest)')\nax.set_ylabel('Weight')\nax.set_title('Softmax Weighting')\nax.legend()\nax.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig(REPORT_DIR / \"recency_weights_visualization.png\", dpi=150, bbox_inches='tight')\nplt.show()\n\nprint(f\"[CELL 09-05] Visualization saved to {REPORT_DIR / 'recency_weights_visualization.png'}\")\n\ncell_end(\"CELL 09-05\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-06] Define GRU4Rec model\n\nt0 = cell_start(\"CELL 09-06\", \"Define GRU4Rec model\")\n\nclass GRURecommender(nn.Module):\n    \"\"\"GRU4Rec model for sequential recommendation.\"\"\"\n    def __init__(self, n_items: int, embed_dim: int, hidden_dim: int, n_layers: int = 1, dropout: float = 0.1):\n        super().__init__()\n        self.n_items = n_items\n        self.embed_dim = embed_dim\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n        \n        self.embedding = nn.Embedding(n_items, embed_dim, padding_idx=0)\n        self.gru = nn.GRU(\n            input_size=embed_dim,\n            hidden_size=hidden_dim,\n            num_layers=n_layers,\n            batch_first=True,\n            dropout=dropout if n_layers > 1 else 0.0,\n        )\n        self.dropout = nn.Dropout(dropout)\n        self.output = nn.Linear(hidden_dim, n_items)\n        \n    def forward(self, x: torch.Tensor, lengths: torch.Tensor = None) -> torch.Tensor:\n        embedded = self.embedding(x)\n        \n        if lengths is not None:\n            packed = nn.utils.rnn.pack_padded_sequence(\n                embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n            )\n            output, hidden = self.gru(packed)\n        else:\n            output, hidden = self.gru(embedded)\n        \n        last_hidden = hidden[-1]\n        out = self.dropout(last_hidden)\n        logits = self.output(out)\n        \n        return logits\n\nprint(f\"[CELL 09-06] GRURecommender defined\")\n\ncell_end(\"CELL 09-06\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-07] Initialize model (with optional Warm-Start)\n\nt0 = cell_start(\"CELL 09-07\", \"Initialize model\")\n\nmeta_model = GRURecommender(\n    n_items=n_items,\n    embed_dim=CFG[\"model_config\"][\"embed_dim\"],\n    hidden_dim=CFG[\"model_config\"][\"hidden_dim\"],\n    n_layers=CFG[\"model_config\"][\"n_layers\"],\n    dropout=CFG[\"model_config\"][\"dropout\"],\n).to(DEVICE)\n\n# Optional Warm-Start\nif CFG[\"warmstart_config\"][\"use_warmstart\"]:\n    print(f\"[CELL 09-07] Loading pre-trained GRU4Rec for Warm-Start...\")\n    pretrained_state = torch.load(PRETRAINED_PATH, map_location=DEVICE)\n    meta_model.load_state_dict(pretrained_state)\n    print(f\"[CELL 09-07] Warm-Start: YES (from {PRETRAINED_PATH})\")\nelse:\n    print(f\"[CELL 09-07] Warm-Start: NO (random initialization)\")\n\nn_params = sum(p.numel() for p in meta_model.parameters())\nprint(f\"[CELL 09-07] Model parameters: {n_params:,}\")\n\nmeta_optimizer = torch.optim.Adam(meta_model.parameters(), lr=CFG[\"maml_config\"][\"outer_lr\"])\n\ncell_end(\"CELL 09-07\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-08] Helper functions\n\nt0 = cell_start(\"CELL 09-08\", \"Define helper functions\")\n\ndef pad_sequences(sequences: List[List[int]], pad_value: int = 0) -> Tuple[torch.Tensor, torch.Tensor]:\n    \"\"\"Pad variable-length sequences.\"\"\"\n    lengths = torch.tensor([len(seq) for seq in sequences], dtype=torch.long)\n    max_len = max(lengths).item()\n    \n    padded = torch.full((len(sequences), max_len), pad_value, dtype=torch.long)\n    for i, seq in enumerate(sequences):\n        padded[i, :len(seq)] = torch.tensor(seq, dtype=torch.long)\n    \n    return padded, lengths\n\ndef functional_forward(model: nn.Module, x: torch.Tensor, lengths: torch.Tensor, \n                       params: Dict[str, torch.Tensor]) -> torch.Tensor:\n    \"\"\"Forward pass with external parameters (for MAML inner loop).\"\"\"\n    embedded = F.embedding(x, params[\"embedding.weight\"], padding_idx=0)\n    \n    batch_size = x.size(0)\n    hidden_dim = params[\"gru.weight_hh_l0\"].size(1)\n    h = torch.zeros(batch_size, hidden_dim, device=x.device)\n    \n    weight_ih = params[\"gru.weight_ih_l0\"]\n    weight_hh = params[\"gru.weight_hh_l0\"]\n    bias_ih = params[\"gru.bias_ih_l0\"]\n    bias_hh = params[\"gru.bias_hh_l0\"]\n    \n    for t in range(embedded.size(1)):\n        inp = embedded[:, t, :]\n        gates = inp @ weight_ih.t() + bias_ih + h @ weight_hh.t() + bias_hh\n        \n        r, z, n = gates.chunk(3, dim=1)\n        r = torch.sigmoid(r)\n        z = torch.sigmoid(z)\n        n = torch.tanh(n)\n        \n        h = (1 - z) * n + z * h\n    \n    logits = h @ params[\"output.weight\"].t() + params[\"output.bias\"]\n    \n    return logits\n\ndef get_recency_weights(K: int, config: dict) -> torch.Tensor:\n    \"\"\"Get recency weights based on config.\"\"\"\n    scheme = config[\"weighting_scheme\"]\n    \n    if scheme == \"exponential\":\n        return compute_recency_weights_exponential(K, config[\"lambda\"])\n    elif scheme == \"linear\":\n        return compute_recency_weights_linear(K)\n    elif scheme == \"softmax\":\n        return compute_recency_weights_softmax(K, config[\"temperature\"])\n    else:\n        raise ValueError(f\"Unknown weighting scheme: {scheme}\")\n\nprint(f\"[CELL 09-08] Helper functions defined\")\n\ncell_end(\"CELL 09-08\", t0)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-09] MAML Training with Recency-Weighted Inner Loop (KEY CONTRIBUTION)\n\nt0 = cell_start(\"CELL 09-09\", \"MAML Training with Recency-Weighted Inner Loop\")\n\n# Training config\ninner_lr = CFG[\"maml_config\"][\"inner_lr\"]\ninner_steps = CFG[\"maml_config\"][\"inner_steps\"]\nmeta_batch_size = CFG[\"maml_config\"][\"meta_batch_size\"]\nnum_iterations = CFG[\"maml_config\"][\"num_meta_iterations\"]\nval_every = CFG[\"maml_config\"][\"val_every\"]\ncheckpoint_every = CFG[\"maml_config\"][\"checkpoint_every\"]\n\nK = CFG[\"episode_config\"][\"K\"]\n\n# Pre-compute recency weights\nrecency_weights = get_recency_weights(K, CFG[\"recency_config\"]).to(DEVICE)\nprint(f\"[CELL 09-09] Recency weights: {recency_weights.tolist()}\")\n\nprint(f\"[CELL 09-09] Training config:\")\nprint(f\"  - Recency weighting: {CFG['recency_config']['weighting_scheme']}\")\nprint(f\"  - Warm-Start: {CFG['warmstart_config']['use_warmstart']}\")\nprint(f\"  - Inner steps: {inner_steps}\")\nprint(f\"  - Iterations: {num_iterations}\")\n\nhistory = {\"train_loss\": [], \"val_acc\": [], \"iteration\": []}\nbest_val_acc = 0.0\n\nmeta_model.train()\n\nfor iteration in range(1, num_iterations + 1):\n    meta_optimizer.zero_grad()\n    \n    task_indices = np.random.choice(len(episodes_train), size=meta_batch_size, replace=False)\n    \n    meta_loss = 0.0\n    \n    for task_idx in task_indices:\n        row = episodes_train.iloc[task_idx]\n        \n        support_x_raw = row[\"support_prefixes\"]\n        support_y = torch.tensor(row[\"support_labels\"], dtype=torch.long, device=DEVICE)\n        query_x_raw = row[\"query_prefixes\"]\n        query_y = torch.tensor(row[\"query_labels\"], dtype=torch.long, device=DEVICE)\n        \n        support_x, support_lengths = pad_sequences(support_x_raw)\n        support_x = support_x.to(DEVICE)\n        support_lengths = support_lengths.to(DEVICE)\n        \n        query_x, query_lengths = pad_sequences(query_x_raw)\n        query_x = query_x.to(DEVICE)\n        query_lengths = query_lengths.to(DEVICE)\n        \n        params = {name: param.clone() for name, param in meta_model.named_parameters()}\n        \n        # Inner loop with RECENCY-WEIGHTED LOSS (KEY CONTRIBUTION)\n        for _ in range(inner_steps):\n            support_logits = functional_forward(meta_model, support_x, support_lengths, params)\n            \n            # ============================================================\n            # KEY CONTRIBUTION: Recency-weighted loss\n            # Instead of: loss = F.cross_entropy(logits, labels)  # equal weights\n            # We use:     loss = sum(w_i * loss_i)                 # recency weights\n            # ============================================================\n            per_sample_loss = F.cross_entropy(support_logits, support_y, reduction='none')\n            support_loss = (recency_weights * per_sample_loss).sum()\n            # ============================================================\n            \n            grads = torch.autograd.grad(support_loss, params.values(), create_graph=False)\n            \n            params = {\n                name: param - inner_lr * grad\n                for (name, param), grad in zip(params.items(), grads)\n            }\n        \n        query_logits = functional_forward(meta_model, query_x, query_lengths, params)\n        query_loss = F.cross_entropy(query_logits, query_y)\n        \n        meta_loss += query_loss\n    \n    meta_loss = meta_loss / meta_batch_size\n    \n    meta_loss.backward()\n    torch.nn.utils.clip_grad_norm_(meta_model.parameters(), max_norm=10.0)\n    meta_optimizer.step()\n    \n    if iteration % 100 == 0 or iteration == 1:\n        print(f\"[CELL 09-09] Iteration {iteration}/{num_iterations}, Meta-Loss: {meta_loss.item():.4f}\")\n        history[\"train_loss\"].append(meta_loss.item())\n        history[\"iteration\"].append(iteration)\n    \n    if iteration % val_every == 0:\n        meta_model.eval()\n        val_correct = 0\n        val_total = 0\n        \n        with torch.no_grad():\n            for val_idx in range(len(episodes_val)):\n                row = episodes_val.iloc[val_idx]\n                \n                support_x_raw = row[\"support_prefixes\"]\n                support_y = torch.tensor(row[\"support_labels\"], dtype=torch.long, device=DEVICE)\n                query_x_raw = row[\"query_prefixes\"]\n                query_y = torch.tensor(row[\"query_labels\"], dtype=torch.long, device=DEVICE)\n                \n                support_x, support_lengths = pad_sequences(support_x_raw)\n                support_x = support_x.to(DEVICE)\n                support_lengths = support_lengths.to(DEVICE)\n                \n                query_x, query_lengths = pad_sequences(query_x_raw)\n                query_x = query_x.to(DEVICE)\n                query_lengths = query_lengths.to(DEVICE)\n                \n                params = {name: param.clone() for name, param in meta_model.named_parameters()}\n                \n                for _ in range(inner_steps):\n                    support_logits = functional_forward(meta_model, support_x, support_lengths, params)\n                    per_sample_loss = F.cross_entropy(support_logits, support_y, reduction='none')\n                    support_loss = (recency_weights * per_sample_loss).sum()\n                    grads = torch.autograd.grad(support_loss, params.values())\n                    params = {\n                        name: param - inner_lr * grad\n                        for (name, param), grad in zip(params.items(), grads)\n                    }\n                \n                query_logits = functional_forward(meta_model, query_x, query_lengths, params)\n                preds = query_logits.argmax(dim=-1)\n                \n                val_correct += (preds == query_y).sum().item()\n                val_total += len(query_y)\n        \n        val_acc = val_correct / val_total\n        history[\"val_acc\"].append(val_acc)\n        print(f\"[CELL 09-09] Iteration {iteration}, Val Acc@1: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n        \n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(meta_model.state_dict(), OUT_MODEL)\n            print(f\"[CELL 09-09] New best model saved! Val Acc: {val_acc*100:.2f}%\")\n        \n        meta_model.train()\n    \n    if iteration % checkpoint_every == 0:\n        checkpoint_path = CHECKPOINT_DIR / f\"recency_checkpoint_iter{iteration}.pth\"\n        torch.save({\n            \"iteration\": iteration,\n            \"model_state_dict\": meta_model.state_dict(),\n            \"optimizer_state_dict\": meta_optimizer.state_dict(),\n            \"best_val_acc\": best_val_acc,\n            \"config\": CFG,\n        }, checkpoint_path)\n\nprint(f\"\\n[CELL 09-09] Training complete!\")\nprint(f\"[CELL 09-09] Best validation accuracy: {best_val_acc*100:.2f}%\")\n\ncell_end(\"CELL 09-09\", t0, best_val_acc=best_val_acc)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-10] Final Evaluation on Test Set\n\nt0 = cell_start(\"CELL 09-10\", \"Final evaluation on test set\")\n\nmeta_model.load_state_dict(torch.load(OUT_MODEL, map_location=DEVICE))\nmeta_model.eval()\n\nprint(f\"[CELL 09-10] Loaded best model from: {OUT_MODEL}\")\n\n# Zero-shot and Few-shot evaluation\nzeroshot_correct = 0\nzeroshot_total = 0\nfewshot_correct = 0\nfewshot_total = 0\n\nwith torch.no_grad():\n    for test_idx in range(len(episodes_test)):\n        row = episodes_test.iloc[test_idx]\n        \n        support_x_raw = row[\"support_prefixes\"]\n        support_y = torch.tensor(row[\"support_labels\"], dtype=torch.long, device=DEVICE)\n        query_x_raw = row[\"query_prefixes\"]\n        query_y = torch.tensor(row[\"query_labels\"], dtype=torch.long, device=DEVICE)\n        \n        support_x, support_lengths = pad_sequences(support_x_raw)\n        support_x = support_x.to(DEVICE)\n        support_lengths = support_lengths.to(DEVICE)\n        \n        query_x, query_lengths = pad_sequences(query_x_raw)\n        query_x = query_x.to(DEVICE)\n        query_lengths = query_lengths.to(DEVICE)\n        \n        # Zero-shot\n        params_zs = {name: param.clone() for name, param in meta_model.named_parameters()}\n        query_logits_zs = functional_forward(meta_model, query_x, query_lengths, params_zs)\n        preds_zs = query_logits_zs.argmax(dim=-1)\n        zeroshot_correct += (preds_zs == query_y).sum().item()\n        zeroshot_total += len(query_y)\n        \n        # Few-shot with recency-weighted adaptation\n        params_fs = {name: param.clone() for name, param in meta_model.named_parameters()}\n        \n        for _ in range(inner_steps):\n            support_logits = functional_forward(meta_model, support_x, support_lengths, params_fs)\n            per_sample_loss = F.cross_entropy(support_logits, support_y, reduction='none')\n            support_loss = (recency_weights * per_sample_loss).sum()\n            grads = torch.autograd.grad(support_loss, params_fs.values())\n            params_fs = {\n                name: param - inner_lr * grad\n                for (name, param), grad in zip(params_fs.items(), grads)\n            }\n        \n        query_logits_fs = functional_forward(meta_model, query_x, query_lengths, params_fs)\n        preds_fs = query_logits_fs.argmax(dim=-1)\n        fewshot_correct += (preds_fs == query_y).sum().item()\n        fewshot_total += len(query_y)\n\nzeroshot_acc = zeroshot_correct / zeroshot_total\nfewshot_acc = fewshot_correct / fewshot_total\n\nmodel_type = \"Warm-Start + Recency\" if CFG[\"warmstart_config\"][\"use_warmstart\"] else \"Recency Only\"\n\nprint(f\"\\n[CELL 09-10] ========== RESULTS ({model_type}) ==========\")\nprint(f\"[CELL 09-10] Test episodes: {len(episodes_test)}\")\nprint(f\"[CELL 09-10] Recency weighting: {CFG['recency_config']['weighting_scheme']}\")\nprint(f\"\\n[CELL 09-10] {model_type} Zero-shot: {zeroshot_acc:.4f} ({zeroshot_acc*100:.2f}%)\")\nprint(f\"[CELL 09-10] {model_type} Few-shot:  {fewshot_acc:.4f} ({fewshot_acc*100:.2f}%)\")\nprint(f\"\\n[CELL 09-10] ========== COMPARISON ==========\")\nprint(f\"[CELL 09-10] GRU4Rec baseline:          33.55%\")\nprint(f\"[CELL 09-10] Vanilla MAML Few-shot:     28.66%\")\nprint(f\"[CELL 09-10] {model_type} Few-shot:  {fewshot_acc*100:.2f}%\")\nprint(f\"\\n[CELL 09-10] Improvement over Vanilla MAML: +{(fewshot_acc - 0.2866)*100:.2f} pp\")\nprint(f\"[CELL 09-10] Improvement over GRU4Rec:      {(fewshot_acc - 0.3355)*100:+.2f} pp\")\n\ncell_end(\"CELL 09-10\", t0, zeroshot_acc=zeroshot_acc, fewshot_acc=fewshot_acc)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 09-11] Save results and report\n\nt0 = cell_start(\"CELL 09-11\", \"Save results and report\")\n\nmodel_type = \"warmstart_recency\" if CFG[\"warmstart_config\"][\"use_warmstart\"] else \"recency_only\"\n\nresults = {\n    \"model\": model_type,\n    \"contribution\": \"recency_weighted_inner_loop\",\n    \"dataset\": \"xuetangx\",\n    \"config\": CFG,\n    \"metrics\": {\n        \"zeroshot\": {\"accuracy@1\": zeroshot_acc},\n        \"fewshot\": {\"accuracy@1\": fewshot_acc},\n    },\n    \"comparison\": {\n        \"gru4rec_baseline\": 0.3355,\n        \"vanilla_maml_fewshot\": 0.2866,\n        f\"{model_type}_fewshot\": fewshot_acc,\n    },\n    \"improvement\": {\n        \"over_vanilla_maml\": fewshot_acc - 0.2866,\n        \"over_gru4rec\": fewshot_acc - 0.3355,\n    },\n}\n\nwith open(OUT_RESULTS, \"w\") as f:\n    json.dump(results, f, indent=2)\nprint(f\"[CELL 09-11] Results saved: {OUT_RESULTS}\")\n\nreport = {\n    \"notebook\": CFG[\"notebook\"],\n    \"run_tag\": RUN_TAG,\n    \"timestamp\": datetime.now().isoformat(),\n    \"config\": CFG,\n    \"results\": results,\n    \"history\": history,\n}\n\nwith open(REPORT_PATH, \"w\") as f:\n    json.dump(report, f, indent=2)\nprint(f\"[CELL 09-11] Report saved: {REPORT_PATH}\")\n\ncell_end(\"CELL 09-11\", t0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Notebook 09 Complete: Recency-Weighted MAML Results\n\n**Contribution:** Weight support pairs by recency in MAML inner loop - recent pairs get higher weight.\n\n**Key Results:**\n\n| Model | Init | Inner Loop | Acc@1 | vs Vanilla |\n|-------|------|------------|-------|------------|\n| GRU4Rec baseline | Trained | N/A | 33.55% | - |\n| Vanilla MAML | Random | Equal weights | 28.66% | baseline |\n| Warm-Start MAML | GRU4Rec | Equal weights | ??% | +?? pp |\n| Recency MAML | Random | Recency weights | ??% | +?? pp |\n| **Warm-Start + Recency** | GRU4Rec | Recency weights | **??%** | **+?? pp** |\n\n**Ablation: Weighting Schemes**\n\n| Scheme | Lambda/Temp | Acc@1 |\n|--------|-------------|-------|\n| Equal (baseline) | - | 28.66% |\n| Exponential | λ=0.3 | ??% |\n| Exponential | λ=0.5 | ??% |\n| Exponential | λ=1.0 | ??% |\n| Linear | - | ??% |\n| Softmax | τ=1.0 | ??% |\n\n**Key Insight:** Recent learning activities better reflect current user preferences in MOOCs."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (VENV)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
