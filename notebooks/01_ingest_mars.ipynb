{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59960c04",
   "metadata": {},
   "source": [
    "Bootstrap: repo root + fixed paths + basic logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d07a6d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CELL 01-00] start=2026-01-06T21:23:21\n",
      "[CELL 01-00] CWD: C:\\anonymous-users-mooc-session-meta\\notebooks\n",
      "[CELL 01-00] REPO_ROOT: C:\\anonymous-users-mooc-session-meta\n",
      "[CELL 01-00] PROJECT_STATE=C:\\anonymous-users-mooc-session-meta\\PROJECT_STATE.md\n",
      "[CELL 01-00] META_REGISTRY=C:\\anonymous-users-mooc-session-meta\\meta.json\n",
      "[CELL 01-00] DATA_RAW=C:\\anonymous-users-mooc-session-meta\\data\\raw\n",
      "[CELL 01-00] DATA_INTERIM=C:\\anonymous-users-mooc-session-meta\\data\\interim\n",
      "[CELL 01-00] DATA_PROCESSED=C:\\anonymous-users-mooc-session-meta\\data\\processed\n",
      "[CELL 01-00] REPORTS=C:\\anonymous-users-mooc-session-meta\\reports\n",
      "[CELL 01-00] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-00] Bootstrap: repo root + fixed paths + basic logger\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(f\"[CELL 01-00] start={t0.isoformat(timespec='seconds')}\")\n",
    "print(\"[CELL 01-00] CWD:\", Path.cwd().resolve())\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for p in [start, *start.parents]:\n",
    "        if (p / \"PROJECT_STATE.md\").exists():\n",
    "            return p\n",
    "    raise RuntimeError(\"Could not find PROJECT_STATE.md. Open notebook from within the repo.\")\n",
    "\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "print(\"[CELL 01-00] REPO_ROOT:\", REPO_ROOT)\n",
    "\n",
    "PATHS = {\n",
    "    \"PROJECT_STATE\": REPO_ROOT / \"PROJECT_STATE.md\",\n",
    "    \"META_REGISTRY\": REPO_ROOT / \"meta.json\",\n",
    "    \"DATA_RAW\": REPO_ROOT / \"data\" / \"raw\",\n",
    "    \"DATA_INTERIM\": REPO_ROOT / \"data\" / \"interim\",\n",
    "    \"DATA_PROCESSED\": REPO_ROOT / \"data\" / \"processed\",\n",
    "    \"REPORTS\": REPO_ROOT / \"reports\",\n",
    "}\n",
    "for k, v in PATHS.items():\n",
    "    print(f\"[CELL 01-00] {k}={v}\")\n",
    "\n",
    "def cell_start(cell_id: str, title: str, **kwargs: Any) -> float:\n",
    "    t = time.time()\n",
    "    print(f\"\\n[{cell_id}] {title}\")\n",
    "    print(f\"[{cell_id}] start={datetime.now().isoformat(timespec='seconds')}\")\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    return t\n",
    "\n",
    "def cell_end(cell_id: str, t0: float, **kwargs: Any) -> None:\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    print(f\"[{cell_id}] elapsed={time.time()-t0:.2f}s\")\n",
    "    print(f\"[{cell_id}] done\")\n",
    "\n",
    "print(\"[CELL 01-00] done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f84f57",
   "metadata": {},
   "source": [
    "Reproducibility: seed everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97f74ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-01] Seed everything\n",
      "[CELL 01-01] start=2026-01-06T21:23:21\n",
      "[CELL 01-01] seed=20260106\n",
      "[CELL 01-01] elapsed=0.00s\n",
      "[CELL 01-01] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-01] Reproducibility: seed everything\n",
    "\n",
    "t0 = cell_start(\"CELL 01-01\", \"Seed everything\")\n",
    "\n",
    "GLOBAL_SEED = 20260106\n",
    "\n",
    "def seed_everything(seed: int) -> None:\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "seed_everything(GLOBAL_SEED)\n",
    "\n",
    "cell_end(\"CELL 01-01\", t0, seed=GLOBAL_SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab5b7f",
   "metadata": {},
   "source": [
    "JSON IO (atomic) + hashing helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f948a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-02] JSON IO + hashing\n",
      "[CELL 01-02] start=2026-01-06T21:23:21\n",
      "[CELL 01-02] elapsed=0.00s\n",
      "[CELL 01-02] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-02] JSON IO (atomic) + hashing helpers\n",
    "\n",
    "t0 = cell_start(\"CELL 01-02\", \"JSON IO + hashing\")\n",
    "\n",
    "def write_json_atomic(path: Path, obj: Any, indent: int = 2) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + f\".tmp_{uuid.uuid4().hex}\")\n",
    "    with tmp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=indent)\n",
    "    tmp.replace(path)\n",
    "\n",
    "def read_json(path: Path) -> Any:\n",
    "    if not path.exists():\n",
    "        raise RuntimeError(f\"Missing JSON file: {path}\")\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def sha256_file(path: Path, chunk_size: int = 1024 * 1024) -> str:\n",
    "    h = hashlib.sha256()\n",
    "    with path.open(\"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def assert_nonempty_df(df: pd.DataFrame, name: str) -> None:\n",
    "    if df is None or not isinstance(df, pd.DataFrame) or df.shape[0] == 0:\n",
    "        raise RuntimeError(f\"{name} is empty or invalid DataFrame\")\n",
    "\n",
    "cell_end(\"CELL 01-02\", t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301b72fb",
   "metadata": {},
   "source": [
    "Run tagging + report/config/manifest + meta.json append-only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4358e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-03] Start run + init run files + meta.json\n",
      "[CELL 01-03] start=2026-01-06T21:23:21\n",
      "[CELL 01-03] out_dir=C:\\anonymous-users-mooc-session-meta\\reports\\01_ingest_mars\\20260106_212321\n",
      "[CELL 01-03] report=C:\\anonymous-users-mooc-session-meta\\reports\\01_ingest_mars\\20260106_212321\\report.json\n",
      "[CELL 01-03] config=C:\\anonymous-users-mooc-session-meta\\reports\\01_ingest_mars\\20260106_212321\\config.json\n",
      "[CELL 01-03] manifest=C:\\anonymous-users-mooc-session-meta\\reports\\01_ingest_mars\\20260106_212321\\manifest.json\n",
      "[CELL 01-03] meta=C:\\anonymous-users-mooc-session-meta\\meta.json\n",
      "[CELL 01-03] elapsed=0.01s\n",
      "[CELL 01-03] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-03] Run tagging + report/config/manifest + meta.json registry\n",
    "\n",
    "t0 = cell_start(\"CELL 01-03\", \"Start run + init run files + meta.json\")\n",
    "\n",
    "NOTEBOOK_NAME = \"01_ingest_mars\"\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_ID = uuid.uuid4().hex\n",
    "\n",
    "OUT_DIR = PATHS[\"REPORTS\"] / NOTEBOOK_NAME / RUN_TAG\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "REPORT_PATH = OUT_DIR / \"report.json\"\n",
    "CONFIG_PATH = OUT_DIR / \"config.json\"\n",
    "MANIFEST_PATH = OUT_DIR / \"manifest.json\"\n",
    "\n",
    "RAW_DIR = PATHS[\"DATA_RAW\"] / \"mars\"\n",
    "OUT_PARQUET = PATHS[\"DATA_INTERIM\"] / \"mars_events_raw.parquet\"\n",
    "OUT_DUCKDB = PATHS[\"DATA_INTERIM\"] / \"mars.duckdb\"\n",
    "\n",
    "CFG = {\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"seed\": GLOBAL_SEED,\n",
    "    \"paths\": {\n",
    "        \"raw_dir\": str(RAW_DIR),\n",
    "        \"out_parquet\": str(OUT_PARQUET),\n",
    "        \"out_duckdb\": str(OUT_DUCKDB),\n",
    "        \"out_dir\": str(OUT_DIR),\n",
    "    },\n",
    "    \"ingest\": {\n",
    "        \"accepted_ext\": [\".json\", \".jsonl\", \".csv\", \".parquet\"],\n",
    "        \"parquet_compression\": \"zstd\",\n",
    "        \"duckdb_view\": \"mars_events_raw\",\n",
    "    }\n",
    "}\n",
    "\n",
    "write_json_atomic(CONFIG_PATH, CFG)\n",
    "\n",
    "report = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"repo_root\": str(REPO_ROOT),\n",
    "    \"metrics\": {},\n",
    "    \"key_findings\": [],\n",
    "    \"sanity_samples\": {},\n",
    "    \"data_fingerprints\": {},\n",
    "    \"notes\": [],\n",
    "}\n",
    "write_json_atomic(REPORT_PATH, report)\n",
    "\n",
    "manifest = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"artifacts\": [],\n",
    "}\n",
    "write_json_atomic(MANIFEST_PATH, manifest)\n",
    "\n",
    "# meta.json append-only\n",
    "META_PATH = PATHS[\"META_REGISTRY\"]\n",
    "if not META_PATH.exists():\n",
    "    write_json_atomic(META_PATH, {\"schema_version\": 1, \"runs\": []})\n",
    "\n",
    "meta = read_json(META_PATH)\n",
    "if \"runs\" not in meta or not isinstance(meta[\"runs\"], list):\n",
    "    raise RuntimeError(\"meta.json invalid: missing 'runs' list\")\n",
    "\n",
    "meta[\"runs\"].append({\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"out_dir\": str(OUT_DIR),\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "})\n",
    "write_json_atomic(META_PATH, meta)\n",
    "\n",
    "cell_end(\"CELL 01-03\", t0,\n",
    "         out_dir=str(OUT_DIR),\n",
    "         report=str(REPORT_PATH),\n",
    "         config=str(CONFIG_PATH),\n",
    "         manifest=str(MANIFEST_PATH),\n",
    "         meta=str(META_PATH))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b8482",
   "metadata": {},
   "source": [
    "DuckDB dependency check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6e2538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-04] Import duckdb\n",
      "[CELL 01-04] start=2026-01-06T21:23:21\n",
      "[CELL 01-04] duckdb_version: 1.4.3\n",
      "[CELL 01-04] elapsed=0.04s\n",
      "[CELL 01-04] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-04] DuckDB dependency check\n",
    "\n",
    "t0 = cell_start(\"CELL 01-04\", \"Import duckdb\")\n",
    "\n",
    "try:\n",
    "    import duckdb\n",
    "except Exception as e:\n",
    "    raise RuntimeError(\n",
    "        \"Missing duckdb. Install via:\\n\"\n",
    "        \"  conda install -c conda-forge duckdb\\n\"\n",
    "        \"or\\n\"\n",
    "        \"  pip install duckdb\\n\"\n",
    "    ) from e\n",
    "\n",
    "print(\"[CELL 01-04] duckdb_version:\", duckdb.__version__)\n",
    "cell_end(\"CELL 01-04\", t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b6cf64",
   "metadata": {},
   "source": [
    "Enumerate raw files + fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2054eed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-05] Select explicit_ratings_en.csv only\n",
      "[CELL 01-05] start=2026-01-06T21:23:21\n",
      "[CELL 01-05] raw_dir=C:\\anonymous-users-mooc-session-meta\\data\\raw\\mars\n",
      "[CELL 01-05] using: explicit_ratings_en.csv\n",
      "{\n",
      "  \"name\": \"explicit_ratings_en.csv\",\n",
      "  \"relpath\": \"explicit_ratings_en.csv\",\n",
      "  \"bytes\": 145724,\n",
      "  \"sha256\": \"8190b9f10afcb44b7542616648ee3c7825f42f7bed832784a57e083b53773708\",\n",
      "  \"suffix\": \".csv\"\n",
      "}\n",
      "[CELL 01-05] elapsed=0.00s\n",
      "[CELL 01-05] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-05] Select explicit_ratings_en.csv only + fingerprint\n",
    "\n",
    "t0 = cell_start(\"CELL 01-05\", \"Select explicit_ratings_en.csv only\", raw_dir=str(RAW_DIR))\n",
    "\n",
    "target_name = \"explicit_ratings_en.csv\"\n",
    "target_path = RAW_DIR / target_name\n",
    "\n",
    "if not target_path.exists():\n",
    "    # show what exists to avoid guessing\n",
    "    existing = sorted([p.name for p in RAW_DIR.rglob(\"*\") if p.is_file()])\n",
    "    raise RuntimeError(\n",
    "        f\"Required file not found: {target_path}\\n\"\n",
    "        f\"Files under {RAW_DIR} (first 50): {existing[:50]}\"\n",
    "    )\n",
    "\n",
    "raw_fp = {\n",
    "    \"root\": str(RAW_DIR),\n",
    "    \"n_files\": 1,\n",
    "    \"files\": [{\n",
    "        \"name\": target_path.name,\n",
    "        \"relpath\": str(target_path.relative_to(RAW_DIR)),\n",
    "        \"bytes\": int(target_path.stat().st_size),\n",
    "        \"sha256\": sha256_file(target_path),\n",
    "        \"suffix\": target_path.suffix.lower(),\n",
    "    }]\n",
    "}\n",
    "\n",
    "print(\"[CELL 01-05] using:\", target_path.name)\n",
    "print(json.dumps(raw_fp[\"files\"][0], indent=2))\n",
    "\n",
    "cell_end(\"CELL 01-05\", t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4eceb0a",
   "metadata": {},
   "source": [
    "Load raw → DataFrame (auto by extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250f3c3f",
   "metadata": {},
   "source": [
    "Load explicit_ratings_en.csv only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbe6e6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-06] Load explicit_ratings_en.csv\n",
      "[CELL 01-06] start=2026-01-06T21:23:21\n",
      "[CELL 01-06] shape: (3659, 6)\n",
      "[CELL 01-06] columns: ['user_id', 'item_id', 'watch_percentage', 'created_at', 'rating', '__source_file']\n",
      "[CELL 01-06] head(3):\n",
      " user_id  item_id  watch_percentage          created_at  rating           __source_file\n",
      "  224557      510               100 2018-09-28 16:18:29      10 explicit_ratings_en.csv\n",
      "  224557      615               100 2018-09-28 16:22:22      10 explicit_ratings_en.csv\n",
      "  224557     7680               100 2018-09-28 16:23:34      10 explicit_ratings_en.csv\n",
      "[CELL 01-06] rows=3659\n",
      "[CELL 01-06] cols=6\n",
      "[CELL 01-06] elapsed=0.01s\n",
      "[CELL 01-06] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-06] Load explicit_ratings_en.csv only\n",
    "\n",
    "t0 = cell_start(\"CELL 01-06\", \"Load explicit_ratings_en.csv\")\n",
    "\n",
    "events = pd.read_csv(RAW_DIR / \"explicit_ratings_en.csv\")\n",
    "assert_nonempty_df(events, \"events\")\n",
    "\n",
    "events[\"__source_file\"] = \"explicit_ratings_en.csv\"\n",
    "\n",
    "print(\"[CELL 01-06] shape:\", events.shape)\n",
    "print(\"[CELL 01-06] columns:\", list(events.columns))\n",
    "\n",
    "# minimal preview\n",
    "print(\"[CELL 01-06] head(3):\")\n",
    "print(events.head(3).to_string(index=False))\n",
    "\n",
    "cell_end(\"CELL 01-06\", t0, rows=int(events.shape[0]), cols=int(events.shape[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b29df3f",
   "metadata": {},
   "source": [
    "Save canonical Parquet (raw → parquet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1dea173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-07] Save canonical raw table as Parquet\n",
      "[CELL 01-07] start=2026-01-06T21:23:21\n",
      "[CELL 01-07] out_parquet=C:\\anonymous-users-mooc-session-meta\\data\\interim\\mars_events_raw.parquet\n",
      "[CELL 01-07] saved: C:\\anonymous-users-mooc-session-meta\\data\\interim\\mars_events_raw.parquet\n",
      "[CELL 01-07] bytes: 43047\n",
      "[CELL 01-07] sha256: 3e261bffc99b67cd75a4b03b71785b5dbb854a6aea5db131f4763cb57d51fc9d\n",
      "[CELL 01-07] elapsed=0.02s\n",
      "[CELL 01-07] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-07] Save canonical Parquet (raw → parquet)\n",
    "\n",
    "t0 = cell_start(\"CELL 01-07\", \"Save canonical raw table as Parquet\", out_parquet=str(OUT_PARQUET))\n",
    "\n",
    "OUT_PARQUET.parent.mkdir(parents=True, exist_ok=True)\n",
    "events.to_parquet(OUT_PARQUET, index=False, compression=CFG[\"ingest\"][\"parquet_compression\"])\n",
    "\n",
    "parq_bytes = int(OUT_PARQUET.stat().st_size)\n",
    "parq_sha = sha256_file(OUT_PARQUET)\n",
    "\n",
    "print(\"[CELL 01-07] saved:\", OUT_PARQUET)\n",
    "print(\"[CELL 01-07] bytes:\", parq_bytes)\n",
    "print(\"[CELL 01-07] sha256:\", parq_sha)\n",
    "\n",
    "cell_end(\"CELL 01-07\", t0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e168730",
   "metadata": {},
   "source": [
    "DuckDB: create DB + view from Parquet (parquet → duckdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d971f7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-08] Create DuckDB and VIEW from Parquet\n",
      "[CELL 01-08] start=2026-01-06T21:23:21\n",
      "[CELL 01-08] out_duckdb=C:\\anonymous-users-mooc-session-meta\\data\\interim\\mars.duckdb\n",
      "[CELL 01-08] view: mars_events_raw\n",
      "[CELL 01-08] rows: 3659\n",
      "[CELL 01-08] schema_head:\n",
      "     column_name column_type null  key default extra\n",
      "         user_id      BIGINT  YES None    None  None\n",
      "         item_id      BIGINT  YES None    None  None\n",
      "watch_percentage      BIGINT  YES None    None  None\n",
      "      created_at     VARCHAR  YES None    None  None\n",
      "          rating      BIGINT  YES None    None  None\n",
      "   __source_file     VARCHAR  YES None    None  None\n",
      "[CELL 01-08] rows=3659\n",
      "[CELL 01-08] elapsed=0.03s\n",
      "[CELL 01-08] done\n"
     ]
    }
   ],
   "source": [
    "# [CELL 01-08] DuckDB DB + view from Parquet\n",
    "\n",
    "t0 = cell_start(\"CELL 01-08\", \"Create DuckDB and VIEW from Parquet\", out_duckdb=str(OUT_DUCKDB))\n",
    "\n",
    "OUT_DUCKDB.parent.mkdir(parents=True, exist_ok=True)\n",
    "con = duckdb.connect(str(OUT_DUCKDB))\n",
    "\n",
    "view = CFG[\"ingest\"][\"duckdb_view\"]\n",
    "con.execute(f\"DROP VIEW IF EXISTS {view};\")\n",
    "con.execute(f\"\"\"\n",
    "CREATE VIEW {view} AS\n",
    "SELECT * FROM read_parquet('{str(OUT_PARQUET).replace(\"'\", \"''\")}')\n",
    "\"\"\")\n",
    "\n",
    "n = con.execute(f\"SELECT COUNT(*) FROM {view}\").fetchone()[0]\n",
    "schema_df = con.execute(f\"DESCRIBE {view}\").fetchdf()\n",
    "\n",
    "print(\"[CELL 01-08] view:\", view)\n",
    "print(\"[CELL 01-08] rows:\", int(n))\n",
    "print(\"[CELL 01-08] schema_head:\")\n",
    "print(schema_df.head(40).to_string(index=False))\n",
    "\n",
    "cell_end(\"CELL 01-08\", t0, rows=int(n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ed4d24",
   "metadata": {},
   "source": [
    "Update report + manifest (fingerprints + sanity sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f90317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CELL 01-09] Write fingerprints + sanity sample to report + manifest\n",
      "[CELL 01-09] start=2026-01-06T21:25:08\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'C:\\\\anonymous-users-mooc-session-meta\\\\data\\\\interim\\\\mars.duckdb'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mPermissionError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     27\u001b[39m     manifest[\u001b[33m\"\u001b[39m\u001b[33martifacts\u001b[39m\u001b[33m\"\u001b[39m].append({\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(path),\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(path.stat().st_size),\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msha256\u001b[39m\u001b[33m\"\u001b[39m: sha256_file(path),\n\u001b[32m     31\u001b[39m     })\n\u001b[32m     33\u001b[39m add_artifact(OUT_PARQUET)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m \u001b[43madd_artifact\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOUT_DUCKDB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     36\u001b[39m write_json_atomic(MANIFEST_PATH, manifest)\n\u001b[32m     38\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[CELL 01-09] updated_report:\u001b[39m\u001b[33m\"\u001b[39m, REPORT_PATH)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36madd_artifact\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34madd_artifact\u001b[39m(path: Path) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m     manifest[\u001b[33m\"\u001b[39m\u001b[33martifacts\u001b[39m\u001b[33m\"\u001b[39m].append({\n\u001b[32m     28\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mstr\u001b[39m(path),\n\u001b[32m     29\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mbytes\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m(path.stat().st_size),\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msha256\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43msha256_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     31\u001b[39m     })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 20\u001b[39m, in \u001b[36msha256_file\u001b[39m\u001b[34m(path, chunk_size)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msha256_file\u001b[39m(path: Path, chunk_size: \u001b[38;5;28mint\u001b[39m = \u001b[32m1024\u001b[39m * \u001b[32m1024\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m     19\u001b[39m     h = hashlib.sha256()\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mpath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     21\u001b[39m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m     22\u001b[39m             b = f.read(chunk_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\anonymous-users-mooc-session-meta\\venv\\Lib\\pathlib.py:1044\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1043\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m io.open(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
      "\u001b[31mPermissionError\u001b[39m: [Errno 13] Permission denied: 'C:\\\\anonymous-users-mooc-session-meta\\\\data\\\\interim\\\\mars.duckdb'"
     ]
    }
   ],
   "source": [
    "# [CELL 01-09] Update report + manifest\n",
    "\n",
    "t0 = cell_start(\"CELL 01-09\", \"Write fingerprints + sanity sample to report + manifest\")\n",
    "\n",
    "report = read_json(REPORT_PATH)\n",
    "manifest = read_json(MANIFEST_PATH)\n",
    "\n",
    "sample_cols = list(events.columns)[:20]\n",
    "head3 = events.loc[:2, sample_cols].to_dict(orient=\"records\")\n",
    "\n",
    "report[\"data_fingerprints\"][\"mars_raw_files\"] = {\n",
    "    \"root\": raw_fp[\"root\"],\n",
    "    \"n_files\": raw_fp[\"n_files\"],\n",
    "    \"files_first3\": raw_fp[\"files\"][:3],\n",
    "}\n",
    "report[\"data_fingerprints\"][\"mars_events_raw_parquet\"] = {\n",
    "    \"path\": str(OUT_PARQUET),\n",
    "    \"bytes\": parq_bytes,\n",
    "    \"sha256\": parq_sha,\n",
    "}\n",
    "report[\"sanity_samples\"][\"mars_events_raw_head3\"] = head3\n",
    "report[\"notes\"].append(\"Storage rule enforced: raw -> parquet -> duckdb (VIEW mars_events_raw)\")\n",
    "\n",
    "write_json_atomic(REPORT_PATH, report)\n",
    "\n",
    "def add_artifact(path: Path) -> None:\n",
    "    manifest[\"artifacts\"].append({\n",
    "        \"path\": str(path),\n",
    "        \"bytes\": int(path.stat().st_size),\n",
    "        \"sha256\": sha256_file(path),\n",
    "    })\n",
    "\n",
    "add_artifact(OUT_PARQUET)\n",
    "add_artifact(OUT_DUCKDB)\n",
    "\n",
    "write_json_atomic(MANIFEST_PATH, manifest)\n",
    "\n",
    "print(\"[CELL 01-09] updated_report:\", REPORT_PATH)\n",
    "print(\"[CELL 01-09] updated_manifest:\", MANIFEST_PATH)\n",
    "\n",
    "cell_end(\"CELL 01-09\", t0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
