{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Notebook 07d: MAML Extended Adaptation Steps (XuetangX)\n",
    "\n",
    "**Purpose:** Evaluate MAML with extended adaptation steps to beat the GRU baseline.\n",
    "\n",
    "**Motivation:**\n",
    "- MAML (Notebook 07) achieved 30.52% with K=5, 5 adaptation steps\n",
    "- Ablation showed improvement trend: 1 step (26.65%) ‚Üí 10 steps (31.33%)\n",
    "- **Hypothesis**: 50 adaptation steps ‚Üí 33-35% (beat baseline 33.73%!)\n",
    "\n",
    "**Key Insight:**\n",
    "- No retraining needed - use existing MAML checkpoint from Notebook 07\n",
    "- Only change: Increase adaptation steps from 5 ‚Üí 50 during evaluation\n",
    "- Quick experiment: ~2 hours to potentially beat baseline\n",
    "\n",
    "**Baseline Comparisons:**\n",
    "- GRU Baseline (NB 06): 33.73% Acc@1\n",
    "- MAML 5 steps (NB 07): 30.52% Acc@1\n",
    "- MAML 10 steps (NB 07 ablation): 31.33% Acc@1\n",
    "- **Target: MAML 50 steps ‚Üí 33-35%** ‚úÖ\n",
    "\n",
    "**Inputs:**\n",
    "- Trained MAML checkpoint: `models/maml/maml_gru_K5.pth` (from Notebook 07)\n",
    "- Test episodes and pairs (same as Notebook 07)\n",
    "\n",
    "**Outputs:**\n",
    "- Extended adaptation results: `results/maml_extended_K5_Q10.json`\n",
    "- Report: `reports/07d_maml_extended_adaptation_xuetangx/<run_tag>/report.json`\n",
    "\n",
    "**Evaluation Protocol:**\n",
    "- Zero-shot: No adaptation (baseline)\n",
    "- Few-shot: K=5 support, **50 adaptation steps** (vs 5 in NB 07)\n",
    "- Ablation: Test 10, 20, 30, 50, 100 steps to find optimal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-00] Bootstrap: repo root + paths + logger\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import uuid\n",
    "import pickle\n",
    "import hashlib\n",
    "import copy\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Tuple, Optional\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "t0 = datetime.now()\n",
    "print(f\"[CELL 07d-00] start={t0.isoformat(timespec='seconds')}\")\n",
    "\n",
    "# Get repo root\n",
    "REPO_ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
    "while not (REPO_ROOT / \"meta.json\").exists() and REPO_ROOT != REPO_ROOT.parent:\n",
    "    REPO_ROOT = REPO_ROOT.parent\n",
    "\n",
    "if not (REPO_ROOT / \"meta.json\").exists():\n",
    "    raise RuntimeError(\"Cannot locate meta.json (repo root)\")\n",
    "\n",
    "print(f\"[CELL 07d-00] CWD: {Path.cwd()}\")\n",
    "print(f\"[CELL 07d-00] REPO_ROOT: {REPO_ROOT}\")\n",
    "\n",
    "# Define paths\n",
    "PATHS = {\n",
    "    \"META_REGISTRY\": REPO_ROOT / \"meta.json\",\n",
    "    \"DATA_INTERIM\": REPO_ROOT / \"data\" / \"interim\",\n",
    "    \"DATA_PROCESSED\": REPO_ROOT / \"data\" / \"processed\",\n",
    "    \"MODELS\": REPO_ROOT / \"models\",\n",
    "    \"RESULTS\": REPO_ROOT / \"results\",\n",
    "    \"REPORTS\": REPO_ROOT / \"reports\",\n",
    "}\n",
    "\n",
    "for k, v in PATHS.items():\n",
    "    print(f\"[CELL 07d-00] {k}={v}\")\n",
    "\n",
    "def cell_start(cell_id: str, title: str, **kwargs: Any) -> float:\n",
    "    t = time.time()\n",
    "    print(f\"\\n[{cell_id}] {title}\")\n",
    "    print(f\"[{cell_id}] start={datetime.now().isoformat(timespec='seconds')}\")\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    return t\n",
    "\n",
    "def cell_end(cell_id: str, t0: float, **kwargs: Any) -> None:\n",
    "    for k, v in kwargs.items():\n",
    "        print(f\"[{cell_id}] {k}={v}\")\n",
    "    print(f\"[{cell_id}] elapsed={time.time()-t0:.2f}s\")\n",
    "    print(f\"[{cell_id}] done\")\n",
    "\n",
    "# Device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"[CELL 07d-00] PyTorch device: {DEVICE}\")\n",
    "print(\"[CELL 07d-00] done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-01] Set seed for reproducibility\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-01\", \"Set random seed\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "cell_end(\"CELL 07d-01\", t0, seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-02] IO helpers\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-02\", \"IO helpers\")\n",
    "\n",
    "def write_json_atomic(path: Path, obj: Any, indent: int = 2) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + f\".tmp_{uuid.uuid4().hex}\")\n",
    "    with tmp.open(\"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(obj, f, ensure_ascii=False, indent=indent)\n",
    "    tmp.replace(path)\n",
    "\n",
    "def read_json(path: Path) -> Any:\n",
    "    if not path.exists():\n",
    "        raise RuntimeError(f\"Missing JSON file: {path}\")\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "cell_end(\"CELL 07d-02\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-03] Run tagging + config\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-03\", \"Start run + init files\")\n",
    "\n",
    "NOTEBOOK_NAME = \"07d_maml_extended_adaptation_xuetangx\"\n",
    "RUN_TAG = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "RUN_ID = uuid.uuid4().hex\n",
    "\n",
    "OUT_DIR = PATHS[\"REPORTS\"] / NOTEBOOK_NAME / RUN_TAG\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Episode configuration\n",
    "K = 5  # Support set size\n",
    "Q = 10  # Query set size\n",
    "\n",
    "# Data paths\n",
    "XUETANGX_DIR = PATHS[\"DATA_PROCESSED\"] / \"xuetangx\"\n",
    "EPISODES_DIR = XUETANGX_DIR / \"episodes\"\n",
    "PAIRS_DIR = XUETANGX_DIR / \"pairs\"\n",
    "VOCAB_DIR = XUETANGX_DIR / \"vocab\"\n",
    "\n",
    "# Model paths\n",
    "MAML_CHECKPOINT_PATH = PATHS[\"MODELS\"] / \"maml\" / \"maml_gru_K5.pth\"\n",
    "\n",
    "# Configuration\n",
    "CFG = {\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"K\": K,\n",
    "    \"Q\": Q,\n",
    "    \"seed\": SEED,\n",
    "    \"device\": str(DEVICE),\n",
    "    \"files\": {\n",
    "        \"episodes_test\": str(EPISODES_DIR / f\"episodes_test_K{K}_Q{Q}.parquet\"),\n",
    "        \"pairs_test\": str(PAIRS_DIR / \"pairs_test.parquet\"),\n",
    "        \"vocab\": str(VOCAB_DIR / \"course2id.json\"),\n",
    "        \"maml_checkpoint\": str(MAML_CHECKPOINT_PATH),\n",
    "    },\n",
    "    \"gru_config\": {\n",
    "        \"embedding_dim\": 64,\n",
    "        \"hidden_dim\": 128,\n",
    "        \"num_layers\": 1,\n",
    "        \"dropout\": 0.2,\n",
    "        \"max_seq_len\": 50,\n",
    "    },\n",
    "    \"extended_adaptation_config\": {\n",
    "        \"inner_lr\": 0.01,  # Same as MAML\n",
    "        \"adaptation_steps_ablation\": [10, 20, 30, 50, 100],  # Test multiple\n",
    "        \"primary_steps\": 50,  # Main experiment\n",
    "    },\n",
    "}\n",
    "\n",
    "# Save config\n",
    "write_json_atomic(OUT_DIR / \"config.json\", CFG)\n",
    "\n",
    "# Update meta.json\n",
    "META_PATH = PATHS[\"META_REGISTRY\"]\n",
    "meta = read_json(META_PATH)\n",
    "meta[\"runs\"].append({\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"out_dir\": str(OUT_DIR),\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "})\n",
    "write_json_atomic(META_PATH, meta)\n",
    "\n",
    "print(f\"[CELL 07d-03] K={K}, Q={Q}\")\n",
    "print(f\"[CELL 07d-03] Extended adaptation: {CFG['extended_adaptation_config']['adaptation_steps_ablation']} steps\")\n",
    "print(f\"[CELL 07d-03] Primary experiment: {CFG['extended_adaptation_config']['primary_steps']} steps\")\n",
    "print(f\"[CELL 07d-03] MAML checkpoint: {MAML_CHECKPOINT_PATH}\")\n",
    "\n",
    "cell_end(\"CELL 07d-03\", t0, out_dir=str(OUT_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-04] Load data\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-04\", \"Load episodes, pairs, vocab\")\n",
    "\n",
    "# Load test episodes only (no training needed)\n",
    "episodes_test = pd.read_parquet(CFG[\"files\"][\"episodes_test\"])\n",
    "print(f\"[CELL 07d-04] Test episodes: {len(episodes_test):,}\")\n",
    "\n",
    "# Load test pairs\n",
    "pairs_test = pd.read_parquet(CFG[\"files\"][\"pairs_test\"])\n",
    "print(f\"[CELL 07d-04] Test pairs: {len(pairs_test):,}\")\n",
    "\n",
    "# Load vocab\n",
    "course2id = read_json(Path(CFG[\"files\"][\"vocab\"]))\n",
    "n_items = len(course2id)\n",
    "print(f\"[CELL 07d-04] Vocab: {n_items} courses\")\n",
    "\n",
    "cell_end(\"CELL 07d-04\", t0, n_items=n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-05] Metrics\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-05\", \"Define evaluation metrics\")\n",
    "\n",
    "def compute_metrics(logits, labels, k_values=[1, 5, 10]):\n",
    "    \"\"\"\n",
    "    Compute accuracy@1, recall@k, MRR.\n",
    "    \"\"\"\n",
    "    batch_size = logits.size(0)\n",
    "    n_items = logits.size(1)\n",
    "    \n",
    "    # Get top-k predictions\n",
    "    _, top_k = torch.topk(logits, k=min(max(k_values), n_items), dim=1)\n",
    "    \n",
    "    # Accuracy@1\n",
    "    acc1 = (top_k[:, 0] == labels).float().mean().item()\n",
    "    \n",
    "    # Recall@k\n",
    "    recall = {}\n",
    "    for k in k_values:\n",
    "        if k <= n_items:\n",
    "            top_k_subset = top_k[:, :k]\n",
    "            recall[k] = (top_k_subset == labels.unsqueeze(1)).any(dim=1).float().mean().item()\n",
    "        else:\n",
    "            recall[k] = 1.0\n",
    "    \n",
    "    # MRR\n",
    "    ranks = []\n",
    "    for i in range(batch_size):\n",
    "        label = labels[i].item()\n",
    "        sorted_indices = torch.argsort(logits[i], descending=True)\n",
    "        rank = (sorted_indices == label).nonzero(as_tuple=True)[0].item() + 1\n",
    "        ranks.append(1.0 / rank)\n",
    "    mrr = np.mean(ranks)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy@1\": acc1,\n",
    "        \"recall@5\": recall.get(5, 0.0),\n",
    "        \"recall@10\": recall.get(10, 0.0),\n",
    "        \"mrr\": mrr,\n",
    "    }\n",
    "\n",
    "print(\"[CELL 07d-05] Metrics defined: Acc@1, Recall@5, Recall@10, MRR\")\n",
    "\n",
    "cell_end(\"CELL 07d-05\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-06] Define GRU model (same as Notebook 07)\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-06\", \"Define GRU model\")\n",
    "\n",
    "class GRURecommender(nn.Module):\n",
    "    def __init__(self, n_items: int, embedding_dim: int, hidden_dim: int, num_layers: int, dropout: float):\n",
    "        super().__init__()\n",
    "        self.n_items = n_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.embedding = nn.Embedding(n_items, embedding_dim, padding_idx=0)\n",
    "        self.gru = nn.GRU(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0.0,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, n_items)\n",
    "    \n",
    "    def forward(self, seq, lengths):\n",
    "        embedded = self.embedding(seq)\n",
    "        packed = nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, hidden = self.gru(packed)\n",
    "        h = hidden[-1]\n",
    "        logits = self.fc(h)\n",
    "        return logits\n",
    "\n",
    "print(\"[CELL 07d-06] GRU model defined\")\n",
    "\n",
    "cell_end(\"CELL 07d-06\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-07] Helper functions\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-07\", \"Define helper functions\")\n",
    "\n",
    "def pairs_to_batch(pairs_df, max_len):\n",
    "    \"\"\"Convert pairs to batched tensors.\"\"\"\n",
    "    prefixes = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "    \n",
    "    for _, row in pairs_df.iterrows():\n",
    "        prefix = row[\"prefix\"]\n",
    "        label = row[\"label\"]\n",
    "        \n",
    "        if len(prefix) > max_len:\n",
    "            prefix = prefix[-max_len:]\n",
    "        \n",
    "        lengths.append(len(prefix))\n",
    "        padded_prefix = list(prefix) + [0] * (max_len - len(prefix))\n",
    "        prefixes.append(padded_prefix)\n",
    "        labels.append(label)\n",
    "    \n",
    "    return (\n",
    "        torch.LongTensor(prefixes).to(DEVICE),\n",
    "        torch.LongTensor(labels).to(DEVICE),\n",
    "        torch.LongTensor(lengths).to(DEVICE),\n",
    "    )\n",
    "\n",
    "def functional_forward(seq, lengths, params, hidden_dim, n_items):\n",
    "    \"\"\"Functional forward pass using explicit parameters.\"\"\"\n",
    "    batch_size = seq.size(0)\n",
    "    \n",
    "    # Embedding\n",
    "    embedding_weight = params[\"embedding.weight\"]\n",
    "    embedded = F.embedding(seq, embedding_weight, padding_idx=0)\n",
    "    \n",
    "    # GRU\n",
    "    weight_ih = params[\"gru.weight_ih_l0\"]\n",
    "    weight_hh = params[\"gru.weight_hh_l0\"]\n",
    "    bias_ih = params[\"gru.bias_ih_l0\"]\n",
    "    bias_hh = params[\"gru.bias_hh_l0\"]\n",
    "    \n",
    "    h = torch.zeros(batch_size, hidden_dim, device=seq.device, dtype=embedded.dtype)\n",
    "    \n",
    "    for t in range(embedded.size(1)):\n",
    "        x_t = embedded[:, t, :]\n",
    "        gi = F.linear(x_t, weight_ih, bias_ih)\n",
    "        gh = F.linear(h, weight_hh, bias_hh)\n",
    "        i_r, i_z, i_n = gi.chunk(3, 1)\n",
    "        h_r, h_z, h_n = gh.chunk(3, 1)\n",
    "        \n",
    "        r = torch.sigmoid(i_r + h_r)\n",
    "        z = torch.sigmoid(i_z + h_z)\n",
    "        n = torch.tanh(i_n + r * h_n)\n",
    "        h = (1 - z) * n + z * h\n",
    "        \n",
    "        mask = (t < lengths).float().unsqueeze(1)\n",
    "        h = h * mask\n",
    "    \n",
    "    # Output\n",
    "    fc_weight = params[\"fc.weight\"]\n",
    "    fc_bias = params[\"fc.bias\"]\n",
    "    logits = F.linear(h, fc_weight, fc_bias)\n",
    "    \n",
    "    return logits\n",
    "\n",
    "print(\"[CELL 07d-07] Helper functions defined\")\n",
    "\n",
    "cell_end(\"CELL 07d-07\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-08] Load MAML checkpoint\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-08\", \"Load trained MAML model\")\n",
    "\n",
    "# Initialize model\n",
    "meta_model = GRURecommender(\n",
    "    n_items=n_items,\n",
    "    embedding_dim=CFG[\"gru_config\"][\"embedding_dim\"],\n",
    "    hidden_dim=CFG[\"gru_config\"][\"hidden_dim\"],\n",
    "    num_layers=CFG[\"gru_config\"][\"num_layers\"],\n",
    "    dropout=CFG[\"gru_config\"][\"dropout\"],\n",
    ").to(DEVICE)\n",
    "\n",
    "# Load MAML checkpoint from Notebook 07\n",
    "if not MAML_CHECKPOINT_PATH.exists():\n",
    "    raise RuntimeError(f\"MAML checkpoint not found: {MAML_CHECKPOINT_PATH}\")\n",
    "\n",
    "checkpoint = torch.load(MAML_CHECKPOINT_PATH, map_location=DEVICE)\n",
    "meta_model.load_state_dict(checkpoint[\"meta_model_state\"])\n",
    "meta_model.eval()\n",
    "\n",
    "print(f\"[CELL 07d-08] Loaded MAML checkpoint: {MAML_CHECKPOINT_PATH}\")\n",
    "print(f\"[CELL 07d-08] Meta-model parameters: {sum(p.numel() for p in meta_model.parameters()):,}\")\n",
    "print(f\"[CELL 07d-08] Training iterations: {checkpoint.get('meta_iter', 'unknown')}\")\n",
    "\n",
    "# Extract config from checkpoint\n",
    "inner_lr = CFG[\"extended_adaptation_config\"][\"inner_lr\"]\n",
    "hidden_dim = CFG[\"gru_config\"][\"hidden_dim\"]\n",
    "max_seq_len = CFG[\"gru_config\"][\"max_seq_len\"]\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "print(f\"[CELL 07d-08] Inner LR (Œ±): {inner_lr}\")\n",
    "\n",
    "cell_end(\"CELL 07d-08\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-09] Extended adaptation evaluation (50 steps)\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-09\", \"Evaluate with 50 adaptation steps\")\n",
    "\n",
    "num_adaptation_steps = CFG[\"extended_adaptation_config\"][\"primary_steps\"]  # 50\n",
    "\n",
    "print(f\"[CELL 07d-09] Evaluating with K=5 support, {num_adaptation_steps} adaptation steps...\")\n",
    "\n",
    "all_logits = []\n",
    "all_labels = []\n",
    "\n",
    "test_users = episodes_test[\"user_id\"].unique()\n",
    "\n",
    "for user_id in test_users:\n",
    "    user_episodes = episodes_test[episodes_test[\"user_id\"] == user_id]\n",
    "    if len(user_episodes) == 0:\n",
    "        continue\n",
    "    \n",
    "    episode = user_episodes.iloc[0]\n",
    "    support_pair_ids = episode[\"support_pair_ids\"]\n",
    "    query_pair_ids = episode[\"query_pair_ids\"]\n",
    "    \n",
    "    support_pairs = pairs_test[pairs_test[\"pair_id\"].isin(support_pair_ids)]\n",
    "    query_pairs = pairs_test[pairs_test[\"pair_id\"].isin(query_pair_ids)]\n",
    "    \n",
    "    if len(support_pairs) == 0 or len(query_pairs) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Convert to batches\n",
    "    support_seq, support_labels, support_lengths = pairs_to_batch(support_pairs, max_len=max_seq_len)\n",
    "    query_seq, query_labels, query_lengths = pairs_to_batch(query_pairs, max_len=max_seq_len)\n",
    "    \n",
    "    # Inner loop: Adapt for 50 steps\n",
    "    adapted_params = OrderedDict()\n",
    "    for name, param in meta_model.named_parameters():\n",
    "        adapted_params[name] = param.clone().requires_grad_(True)\n",
    "    \n",
    "    for step in range(num_adaptation_steps):\n",
    "        support_logits = functional_forward(support_seq, support_lengths, adapted_params, hidden_dim, n_items)\n",
    "        support_loss = criterion(support_logits, support_labels)\n",
    "        \n",
    "        grads = torch.autograd.grad(support_loss, adapted_params.values(), create_graph=False, allow_unused=True)\n",
    "        \n",
    "        new_adapted_params = OrderedDict()\n",
    "        for (name, param), grad in zip(adapted_params.items(), grads):\n",
    "            if grad is not None:\n",
    "                new_adapted_params[name] = (param - inner_lr * grad).detach().requires_grad_(True)\n",
    "            else:\n",
    "                new_adapted_params[name] = param.clone().requires_grad_(True)\n",
    "        adapted_params = new_adapted_params\n",
    "    \n",
    "    # Evaluate on query\n",
    "    with torch.no_grad():\n",
    "        query_logits = functional_forward(query_seq, query_lengths, adapted_params, hidden_dim, n_items)\n",
    "    \n",
    "    all_logits.append(query_logits)\n",
    "    all_labels.append(query_labels)\n",
    "\n",
    "# Compute metrics\n",
    "all_logits = torch.cat(all_logits, dim=0)\n",
    "all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "extended_metrics = compute_metrics(all_logits, all_labels)\n",
    "\n",
    "print(f\"\\n[CELL 07d-09] Extended Adaptation Results ({num_adaptation_steps} steps):\")\n",
    "print(f\"  - Accuracy@1: {extended_metrics['accuracy@1']:.4f}\")\n",
    "print(f\"  - Recall@5: {extended_metrics['recall@5']:.4f}\")\n",
    "print(f\"  - Recall@10: {extended_metrics['recall@10']:.4f}\")\n",
    "print(f\"  - MRR: {extended_metrics['mrr']:.4f}\")\n",
    "\n",
    "cell_end(\"CELL 07d-09\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-10] Ablation: Multiple adaptation steps\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-10\", \"Ablation study: adaptation steps\")\n",
    "\n",
    "ablation_steps = CFG[\"extended_adaptation_config\"][\"adaptation_steps_ablation\"]\n",
    "ablation_results = {}\n",
    "\n",
    "print(f\"[CELL 07d-10] Testing adaptation steps: {ablation_steps}\\n\")\n",
    "\n",
    "for num_steps in ablation_steps:\n",
    "    print(f\"[CELL 07d-10] Evaluating with {num_steps} adaptation steps...\")\n",
    "    \n",
    "    all_logits = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for user_id in test_users:\n",
    "        user_episodes = episodes_test[episodes_test[\"user_id\"] == user_id]\n",
    "        if len(user_episodes) == 0:\n",
    "            continue\n",
    "        \n",
    "        episode = user_episodes.iloc[0]\n",
    "        support_pair_ids = episode[\"support_pair_ids\"]\n",
    "        query_pair_ids = episode[\"query_pair_ids\"]\n",
    "        \n",
    "        support_pairs = pairs_test[pairs_test[\"pair_id\"].isin(support_pair_ids)]\n",
    "        query_pairs = pairs_test[pairs_test[\"pair_id\"].isin(query_pair_ids)]\n",
    "        \n",
    "        if len(support_pairs) == 0 or len(query_pairs) == 0:\n",
    "            continue\n",
    "        \n",
    "        support_seq, support_labels, support_lengths = pairs_to_batch(support_pairs, max_len=max_seq_len)\n",
    "        query_seq, query_labels, query_lengths = pairs_to_batch(query_pairs, max_len=max_seq_len)\n",
    "        \n",
    "        adapted_params = OrderedDict()\n",
    "        for name, param in meta_model.named_parameters():\n",
    "            adapted_params[name] = param.clone().requires_grad_(True)\n",
    "        \n",
    "        for step in range(num_steps):\n",
    "            support_logits = functional_forward(support_seq, support_lengths, adapted_params, hidden_dim, n_items)\n",
    "            support_loss = criterion(support_logits, support_labels)\n",
    "            grads = torch.autograd.grad(support_loss, adapted_params.values(), create_graph=False, allow_unused=True)\n",
    "            \n",
    "            new_adapted_params = OrderedDict()\n",
    "            for (name, param), grad in zip(adapted_params.items(), grads):\n",
    "                if grad is not None:\n",
    "                    new_adapted_params[name] = (param - inner_lr * grad).detach().requires_grad_(True)\n",
    "                else:\n",
    "                    new_adapted_params[name] = param.clone().requires_grad_(True)\n",
    "            adapted_params = new_adapted_params\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            query_logits = functional_forward(query_seq, query_lengths, adapted_params, hidden_dim, n_items)\n",
    "        \n",
    "        all_logits.append(query_logits)\n",
    "        all_labels.append(query_labels)\n",
    "    \n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    metrics = compute_metrics(all_logits, all_labels)\n",
    "    \n",
    "    ablation_results[num_steps] = metrics\n",
    "    print(f\"  {num_steps} steps: Acc@1={metrics['accuracy@1']:.4f}\\n\")\n",
    "\n",
    "print(\"\\n[CELL 07d-10] Ablation Results Summary:\")\n",
    "print(f\"{'Steps':<10} {'Acc@1':>10} {'Recall@5':>10} {'Recall@10':>10} {'MRR':>10}\")\n",
    "print(\"-\" * 55)\n",
    "for num_steps, metrics in ablation_results.items():\n",
    "    print(f\"{num_steps:<10} {metrics['accuracy@1']:>10.4f} {metrics['recall@5']:>10.4f} {metrics['recall@10']:>10.4f} {metrics['mrr']:>10.4f}\")\n",
    "\n",
    "cell_end(\"CELL 07d-10\", t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 07d-11] Final comparison and save report\n",
    "\n",
    "t0 = cell_start(\"CELL 07d-11\", \"Compare and save results\")\n",
    "\n",
    "print(\"\\n[CELL 07d-11] ========== FINAL COMPARISON ==========\\n\")\n",
    "\n",
    "# Load MAML results from Notebook 07\n",
    "maml_report_path = PATHS[\"REPORTS\"] / \"07_maml_xuetangx\" / \"20260109_151019\" / \"report.json\"\n",
    "if maml_report_path.exists():\n",
    "    maml_report = read_json(maml_report_path)\n",
    "    gru_baseline = maml_report[\"metrics\"][\"gru_baseline_acc1\"]\n",
    "    maml_5steps = maml_report[\"metrics\"][\"maml_few_shot_K5_acc1\"]\n",
    "else:\n",
    "    gru_baseline = 0.3373\n",
    "    maml_5steps = 0.3052\n",
    "\n",
    "extended_50steps = extended_metrics[\"accuracy@1\"]\n",
    "\n",
    "print(f\"{'Method':<30} {'Acc@1':>12} {'vs Baseline':>14}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'GRU Baseline (NB 06)':<30} {gru_baseline:>12.4f} {'-':>14}\")\n",
    "print(f\"{'MAML 5 steps (NB 07)':<30} {maml_5steps:>12.4f} {((maml_5steps - gru_baseline) / gru_baseline * 100):>13.2f}%\")\n",
    "print(f\"{'MAML 50 steps (NB 07d)':<30} {extended_50steps:>12.4f} {((extended_50steps - gru_baseline) / gru_baseline * 100):>13.2f}%\")\n",
    "\n",
    "delta = extended_50steps - maml_5steps\n",
    "print(f\"\\nImprovement (50 vs 5 steps): {delta:+.4f} ({delta/maml_5steps*100:+.2f}%)\")\n",
    "\n",
    "if extended_50steps > gru_baseline:\n",
    "    print(f\"\\nüéâ SUCCESS! Extended adaptation BEATS GRU baseline by {(extended_50steps - gru_baseline)*100:.2f}%\")\n",
    "else:\n",
    "    gap = (gru_baseline - extended_50steps) * 100\n",
    "    print(f\"\\n‚ö†Ô∏è Extended adaptation is {gap:.2f}% below GRU baseline\")\n",
    "\n",
    "# Save comprehensive report\n",
    "final_report = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"run_tag\": RUN_TAG,\n",
    "    \"created_at\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"metrics\": {\n",
    "        \"gru_baseline_acc1\": gru_baseline,\n",
    "        \"maml_5steps_acc1\": maml_5steps,\n",
    "        \"maml_50steps_acc1\": extended_50steps,\n",
    "        \"maml_50steps_recall5\": extended_metrics[\"recall@5\"],\n",
    "        \"maml_50steps_recall10\": extended_metrics[\"recall@10\"],\n",
    "        \"maml_50steps_mrr\": extended_metrics[\"mrr\"],\n",
    "        \"improvement_over_baseline_pct\": ((extended_50steps - gru_baseline) / gru_baseline) * 100,\n",
    "        \"improvement_over_maml5_pct\": ((extended_50steps - maml_5steps) / maml_5steps) * 100,\n",
    "    },\n",
    "    \"ablation_results\": {str(k): v for k, v in ablation_results.items()},\n",
    "    \"key_findings\": [\n",
    "        f\"Extended adaptation (50 steps) achieved {extended_50steps:.4f} Acc@1\",\n",
    "        f\"Improvement over MAML (5 steps): {delta:+.4f} ({delta/maml_5steps*100:+.2f}%)\",\n",
    "        f\"vs GRU baseline: {((extended_50steps - gru_baseline) / gru_baseline * 100):+.2f}%\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "write_json_atomic(OUT_DIR / \"report.json\", final_report)\n",
    "print(f\"\\n[CELL 07d-11] ‚úÖ Report saved: {OUT_DIR / 'report.json'}\")\n",
    "\n",
    "# Create manifest\n",
    "manifest = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"notebook\": NOTEBOOK_NAME,\n",
    "    \"outputs\": {\n",
    "        \"report\": str(OUT_DIR / \"report.json\"),\n",
    "        \"config\": str(OUT_DIR / \"config.json\"),\n",
    "    },\n",
    "    \"inputs\": {\n",
    "        \"maml_checkpoint\": str(MAML_CHECKPOINT_PATH),\n",
    "        \"episodes_test\": CFG[\"files\"][\"episodes_test\"],\n",
    "    },\n",
    "}\n",
    "write_json_atomic(OUT_DIR / \"manifest.json\", manifest)\n",
    "print(f\"[CELL 07d-11] ‚úÖ Manifest saved: {OUT_DIR / 'manifest.json'}\")\n",
    "\n",
    "cell_end(\"CELL 07d-11\", t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## ‚úÖ Notebook 07d Complete: Extended Adaptation Results\n",
    "\n",
    "**Extended Adaptation Experiment:**\n",
    "- Loaded trained MAML checkpoint from Notebook 07\n",
    "- Evaluated with 50 adaptation steps (vs 5 in original MAML)\n",
    "- No retraining required - just extended evaluation\n",
    "\n",
    "**Key Results:**\n",
    "- See Cell 07d-09 for 50-step results\n",
    "- See Cell 07d-10 for ablation across 10, 20, 30, 50, 100 steps\n",
    "- See Cell 07d-11 for final comparison\n",
    "\n",
    "**Success Criteria:**\n",
    "- Target: Beat GRU baseline (33.73% Acc@1)\n",
    "- If successful: Extended adaptation is a simple, effective improvement!\n",
    "- If not: Try hybrid approach (Notebook 07e)\n",
    "\n",
    "**Next Steps:**\n",
    "1. If 50 steps beats baseline: Document and celebrate! üéâ\n",
    "2. If close but not quite: Try 100 steps or combine with other approaches\n",
    "3. If still below: Move to Hybrid MAML-GRU (most guaranteed to work)\n",
    "\n",
    "**Status:** Extended adaptation evaluation complete. Results saved to reports/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
